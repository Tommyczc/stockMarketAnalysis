{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1.0 本文的研究目的是 <code>情感分析</code>, 通过一些已经定义好的词典来给句子向量化\n",
    "## 1.1 读取情感词库 boson nlp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getSentimentWords(url):\n",
    "    with open(url,'r',encoding='utf8') as f:\n",
    "        sentiWord = f.readlines()\n",
    "    eachLine=[i.replace('\\n','') for i in sentiWord]\n",
    "    sentiDict={}\n",
    "    for line in eachLine:\n",
    "        twoCom=line.split(\" \")\n",
    "        if len(twoCom)==2:\n",
    "            sentiDict[twoCom[0]]=float(twoCom[1])\n",
    "    return sentiDict\n",
    "\n",
    "BosonWords=getSentimentWords(\"NLP/Dictionary/BosonNLP/BosonNLP_sentiment_score.txt\")\n",
    "BosonWords"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 读取同义词库，因为boson情感词库的词语太少了，难免遇到情感词不够或者匹配不到的情况"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import json\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "def findSyn(w):\n",
    "    return [e.lemma_names('cmn') for e in wn.synsets(w, lang='cmn')]\n",
    "\n",
    "def iniSynonym():\n",
    "    path = 'NLP/Dictionary/拓展同义词典/cow-not-full.txt'\n",
    "    words = [l.split('\\t')[-1].strip() for l in open(path).readlines()]\n",
    "    syn_wn = {}\n",
    "    for w in words:\n",
    "        try:\n",
    "            w_ = w.replace('+', '')\n",
    "            added = []\n",
    "            syn_lst = findSyn(w)\n",
    "            for l in syn_lst:\n",
    "                l_ = l.copy()\n",
    "                l_.remove(w_)\n",
    "                added.extend([i.replace('+', '') for i in l_])\n",
    "            if added:\n",
    "                syn_wn[w_] = added\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    with open('NLP/Dictionary/拓展同义词典/wordnetSyn.json', 'w') as f:\n",
    "        json.dump(syn_wn, f)\n",
    "\n",
    "    for k,v in syn_wn.items():\n",
    "        syn_wn[k]=list(np.unique(v))\n",
    "    return syn_wn\n",
    "\n",
    "\n",
    "syn_wn=iniSynonym()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "syn_wn['抛弃']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
