{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1.0 本文的研究目的是 <code>情感分析</code>, 通过一些已经定义好的词典来给句子向量化\n",
    "## 1.1 读取情感词库 boson nlp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "def getSentimentWords(url):\n",
    "    with open(url,'r',encoding='utf8') as f:\n",
    "        sentiWord = f.readlines()\n",
    "    eachLine=[i.replace('\\n','') for i in sentiWord]\n",
    "    sentiDict={}\n",
    "    for line in eachLine:\n",
    "        twoCom=line.split(\" \")\n",
    "        if len(twoCom)==2:\n",
    "            sentiDict[twoCom[0]]=float(twoCom[1])\n",
    "    return sentiDict\n",
    "\n",
    "BosonWords=getSentimentWords(\"NLP/Dictionary/BosonNLP/BosonNLP_sentiment_score.txt\")\n",
    "iniLen=len(BosonWords)\n",
    "print(\"the length of boson dictionary: \",iniLen)\n",
    "BosonWords"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-06T12:38:57.194269Z",
     "start_time": "2023-07-06T12:38:57.091278Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 读取同义词库，因为boson情感词库的词语太少了，难免遇到情感词不够或者匹配不到的情况,需要拓展一下情感词"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import json\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "def findSyn(w):\n",
    "    return [e.lemma_names('cmn') for e in wn.synsets(w, lang='cmn')]\n",
    "\n",
    "def iniSynonym():\n",
    "    path = 'NLP/Dictionary/拓展同义词典/cow-not-full.txt'\n",
    "    words = [l.split('\\t')[-1].strip() for l in open(path).readlines()]\n",
    "    syn_wn = {}\n",
    "    for w in words:\n",
    "        try:\n",
    "            w_ = w.replace('+', '')\n",
    "            added = []\n",
    "            syn_lst = findSyn(w)\n",
    "            for l in syn_lst:\n",
    "                l_ = l.copy()\n",
    "                l_.remove(w_)\n",
    "                added.extend([i.replace('+', '') for i in l_])\n",
    "            if added:\n",
    "                syn_wn[w_] = added\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    with open('NLP/Dictionary/拓展同义词典/wordnetSyn.json', 'w') as f:\n",
    "        json.dump(syn_wn, f)\n",
    "\n",
    "    for k,v in syn_wn.items():\n",
    "        syn_wn[k]=list(np.unique(v))\n",
    "\n",
    "    print(\"the length of Synonym dictionary: \",len(syn_wn))\n",
    "    print(\"the increased number of words in Boson: \", len(syn_wn)-iniLen)\n",
    "    return syn_wn\n",
    "\n",
    "\n",
    "syn_wn=iniSynonym()\n",
    "syn_wn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "findSyn('抛弃'),findSyn('驱逐')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "syn_wn['抛弃'],syn_wn['驱逐']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "###todo 整理同义词典，把同义词加到情感词典里面并赋值\n",
    "for k in list(BosonWords.keys()):\n",
    "    if k in syn_wn:\n",
    "        synWordList=syn_wn[k]\n",
    "        for word in synWordList:\n",
    "            if word not in BosonWords:\n",
    "                BosonWords[word]=BosonWords[k]\n",
    "\n",
    "print(\"The final length of Boson dictionary: \",len(BosonWords))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.3 加载程度副词"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.4 给结巴分词加载停用词,情感词,程度副词"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "###stop word\n",
    "def getStopWords(url):\n",
    "    with open(url,'r',encoding='utf8') as f:\n",
    "        stopword = f.readlines()\n",
    "    return [i.replace('\\n','') for i in stopword]\n",
    "\n",
    "cn_stopwords=getStopWords(\"NLP/stopwords/cn_stopwords.txt\")\n",
    "baidu_stopword=getStopWords(\"NLP/stopwords/baidu_stopwords.txt\")\n",
    "hit_stopword=getStopWords(\"NLP/stopwords/hit_stopwords.txt\")\n",
    "scu_stopword=getStopWords(\"NLP/stopwords/scu_stopwords.txt\")\n",
    "\n",
    "stopword_list=cn_stopwords+hit_stopword+baidu_stopword+scu_stopword\n",
    "for stopword in stopword_list:\n",
    "    jieba.add_word(stopword, freq=None, tag=None)\n",
    "for k,v in BosonWords.items():\n",
    "    jieba.add_word(k, freq=None, tag=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\n",
    "testSentence=['我今天很开心',\n",
    "              '我今天不开心',\n",
    "              '他觉得这个产品一点也不好用',\n",
    "              '他觉得这个产品']\n",
    "\n",
    "def getSentiScoreOfSentence(sentence:str)->float:\n",
    "    ex=\"///\".join(jieba.cut(sentence,cut_all=False))\n",
    "    cutSentences=ex.split('///')\n",
    "\n",
    "for sentence in testSentence:\n",
    "    sentence.split(\"\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
