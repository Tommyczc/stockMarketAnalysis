{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 合并表格"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ### 读取\n",
    "# trd_dalyr0=pd.read_excel(\"stockData/furtherInformation/日个股回报率文件185043337(仅供中央财经大学使用)/TRD_Dalyr.xlsx\")\n",
    "# trd_dalyr0=trd_dalyr0.drop([0,1],axis=0)\n",
    "# trd_dalyr1=pd.read_excel(\"stockData/furtherInformation/日个股回报率文件185043337(仅供中央财经大学使用)/TRD_Dalyr1.xlsx\")\n",
    "# trd_dalyr1=trd_dalyr1.drop([0,1],axis=0)\n",
    "# trd_dalyr2=pd.read_excel(\"stockData/furtherInformation/日个股回报率文件185043337(仅供中央财经大学使用)/TRD_Dalyr2.xlsx\")\n",
    "# trd_dalyr2=trd_dalyr2.drop([0,1],axis=0)\n",
    "# trd_dalyr3=pd.read_excel(\"stockData/furtherInformation/日个股回报率文件185043337(仅供中央财经大学使用)/TRD_Dalyr3.xlsx\")\n",
    "# trd_dalyr3=trd_dalyr3.drop([0,1],axis=0)\n",
    "# trd_dalyr4=pd.read_excel(\"stockData/furtherInformation/日个股回报率文件185043337(仅供中央财经大学使用)/TRD_Dalyr4.xlsx\")\n",
    "# trd_dalyr4=trd_dalyr4.drop([0,1],axis=0)\n",
    "# diaryData=[trd_dalyr0,trd_dalyr1,trd_dalyr2,trd_dalyr3,trd_dalyr4]\n",
    "# finalDF=pd.concat(diaryData)\n",
    "# finalDF"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T14:17:54.444824Z",
     "start_time": "2023-08-28T14:17:54.442717Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# companyData=pd.read_excel(\"stockData/furtherInformation/公司文件184301535(仅供中央财经大学使用)/TRD_Co.xlsx\")\n",
    "# companyData=companyData.drop([0,1],axis=0)\n",
    "# companyData"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T14:17:54.450314Z",
     "start_time": "2023-08-28T14:17:54.445264Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# companyAssetData=pd.read_excel(\"stockData/furtherInformation/资产负债表(联表查询)181028530/FS_Combas(Merge Query).xlsx\")\n",
    "# companyAssetData=companyAssetData.drop([0,1],axis=0)\n",
    "# companyAssetData"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T14:17:54.450514Z",
     "start_time": "2023-08-28T14:17:54.448424Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# ### 去除b部分\n",
    "# companyAssetData=companyAssetData[companyAssetData[\"FS_Combas.Typrep\"]!=\"B\"]\n",
    "# companyAssetData=companyAssetData.reindex()\n",
    "# ### 去除12-31，因为与1-1有重复\n",
    "# companyAssetData=companyAssetData[companyAssetData['FS_Combas.Accper'].str.contains(\"01-01|03-31|06-30|09-30\")]\n",
    "# companyAssetData['FS_Combas.Accper']=pd.to_datetime(companyAssetData['FS_Combas.Accper'], format=\"%Y-%m-%d\")\n",
    "# \n",
    "# companyAssetData=companyAssetData.rename(columns={\"FS_Combas.Stkcd\":\"Stkcd\",\"FS_Combas.Accper\":\"Trddt_quarter\"})\n",
    "# companyAssetData"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T14:17:54.455854Z",
     "start_time": "2023-08-28T14:17:54.451346Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# ### todo：开始合并 日个股回报与公司信息\n",
    "# df=pd.merge(finalDF,companyData,on='Stkcd')\n",
    "# df['Trddt']=pd.to_datetime(df[\"Trddt\"], format=\"%Y-%m-%d\")\n",
    "# df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T14:17:54.455981Z",
     "start_time": "2023-08-28T14:17:54.453811Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "###转换时间为季度\n",
    "def dateToQuarter(date):\n",
    "        # print(\"time: \",date)\n",
    "        quarter_date={1:\"01-01\",2:\"03-31\",3:\"06-30\",4:\"09-30\"}\n",
    "        year=date.astype('datetime64[Y]').astype(int) + 1970\n",
    "        month = date.astype('datetime64[M]').astype(int) % 12 + 1\n",
    "        the_quarter = (month - 1) // 3 + 1                  #计算季度\n",
    "        quarter_name = str(year) + '年' + str(the_quarter) + '季度'\n",
    "        quarter_name_short = str(year) + 'Q' + str(the_quarter)\n",
    "        # print(\"quarter time: \",quarter_name)\n",
    "        return [str(year)+\"-\"+quarter_date[the_quarter],the_quarter]\n",
    "\n",
    "# dateToQuarter(numpy.datetime64(\"2020-04-30\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T14:17:54.461117Z",
     "start_time": "2023-08-28T14:17:54.457674Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# df[\"Trddt_quarter\"]=[dateToQuarter(i)[0] for i in df['Trddt'].values]\n",
    "# df[\"Trddt_quarter\"]=pd.to_datetime(df[\"Trddt_quarter\"], format=\"%Y-%m-%d\")\n",
    "# df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T14:17:54.462419Z",
     "start_time": "2023-08-28T14:17:54.460416Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# ###todo：根据季度与股票代码合并之前的总表与资产负债表\n",
    "# allData=pd.merge(df,companyAssetData,on=[\"Stkcd\",'Trddt_quarter'],how='outer')\n",
    "# # allData['Stkcd']=allData['Stkcd'].astype(str)\n",
    "# allData"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T14:17:54.466919Z",
     "start_time": "2023-08-28T14:17:54.462777Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# allData.to_csv(\"stockData/furtherInformation/AllData.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T14:17:54.472284Z",
     "start_time": "2023-08-28T14:17:54.465288Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 数据去重，并且删除部分缺失值"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# allData=pd.read_csv(\"stockData/furtherInformation/AllData.csv\",index_col=0,dtype=object)\n",
    "# allData['Trddt']=pd.to_datetime(allData[\"Trddt\"], format=\"%Y-%m-%d\")\n",
    "# allData"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T14:17:54.473220Z",
     "start_time": "2023-08-28T14:17:54.467528Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# ###todo：要删除的重复列名\n",
    "# deleteColumns=[\"Trddt_quarter\",\"FS_Combas.Typrep\",\"FS_Combas.ShortName\",\"csmar_listedcoinfo.Stknme\",\"csmar_listedcoinfo.Conme\",\"FS_Comscfd.ShortName\",\"FS_Comins.ShortName\",\"csmar_listedcoinfo.Conme_en\",\"csmar_listedcoinfo.Nnindcd\",\"csmar_listedcoinfo.PROVINCECD\",\"csmar_listedcoinfo.CITY\",\"csmar_listedcoinfo.Nnindnme\"]\n",
    "# afterDeleteData=allData[[i for i in allData.columns if i not in deleteColumns]]\n",
    "# afterDeleteData"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T14:17:54.473294Z",
     "start_time": "2023-08-28T14:17:54.470073Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# afterDeleteData.to_csv(\"stockData/furtherInformation/afterDeleteData.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T14:17:54.475623Z",
     "start_time": "2023-08-28T14:17:54.473984Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# ### 检查是否有缺失值达到50%的，有的话就删除\n",
    "# totalNumRows=5000412\n",
    "# num = afterDeleteData.isna().sum()\n",
    "# indexs=[]\n",
    "# nullNums=[]\n",
    "# nullPerc=[]\n",
    "# for index in num.index:\n",
    "#     indexs.append(index)\n",
    "#     nullNums.append(num[index])\n",
    "#     nullPerc.append(str(round(float(num[index]/totalNumRows),3)*100)+\" %\")\n",
    "# \n",
    "# num=pd.DataFrame.from_dict({\"Variance\":indexs,\"Number Of Null\":nullNums,\"Percentage Of Null\":nullPerc})\n",
    "# num"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T14:17:54.481390Z",
     "start_time": "2023-08-28T14:17:54.476284Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# ###todo：删除和处理回归不能输入的数据,删除回报率为null的行,同时删除缺失值过多的 [FS_Combas.A001127000,FS_Combas.A001220000,FS_Combas.A001219000,FS_Combas.A001109000] 列\n",
    "# uselessColumns=[\"FS_Combas.A001127000\",\"FS_Combas.A001220000\",\"FS_Combas.A001219000\",\"FS_Combas.A001109000\",\"Stknme\",\"Listdt\",\"csmar_listedcoinfo.BUSSINESSRANGE\",\"Conme_en\",\"PROVINCECODE\",\"Parvcur\",\"csmar_listedcoinfo.MAINBUSSINESS\",\"CITYCODE\",\"PROVINCE\",\"Cuntrycd\",\"Conme\",\"Nindcd\",\"Nindcd\",\"Nnindcd\",\"OWNERSHIPTYPECODE\",\"Opnprc\",\"Hiprc\",\"Loprc\",\"Clsprc\",\"Indcd\",\"csmar_listedcoinfo.OWNERSHIPTYPE\",\"Markettype\",\"Sctcd\"]\n",
    "# \n",
    "# uselessDeletedDf=allData[[i for i in allData.columns if i not in deleteColumns and i not in uselessColumns]]\n",
    "# uselessDeletedDf=uselessDeletedDf.dropna()\n",
    "# uselessDeletedDf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T14:17:54.481510Z",
     "start_time": "2023-08-28T14:17:54.478564Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "###查看并确定目前的数据类型\n",
    "# print(\"占有类型： \",uselessDeletedDf[\"OWNERSHIPTYPE\"].unique())\n",
    "# print(\"财产类型：\",uselessDeletedDf[\"csmar_listedcoinfo.EquityNature\"].unique())\n",
    "# print(\"产业类型：\",uselessDeletedDf[\"Indnme\"].unique())\n",
    "# print(\"产业细分1：\",uselessDeletedDf[\"Nindnme\"].unique())\n",
    "# print(\"产业细分2：\",uselessDeletedDf[\"Nnindnme\"].unique())\n",
    "# print(\"公司所在地区：\",uselessDeletedDf[\"CITY\"].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T14:17:54.483246Z",
     "start_time": "2023-08-28T14:17:54.481219Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# uselessDeletedDf.to_csv(\"stockData/furtherInformation/Input.csv\",index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T14:17:54.487740Z",
     "start_time": "2023-08-28T14:17:54.483578Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 数据转换 与 回归"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "uselessDeletedDf=pd.read_csv(\"stockData/furtherInformation/Input.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T14:18:07.187640Z",
     "start_time": "2023-08-28T14:17:54.486377Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/czc/anaconda3/envs/DataAnalysis/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/czc/anaconda3/envs/DataAnalysis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/czc/anaconda3/envs/DataAnalysis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/czc/anaconda3/envs/DataAnalysis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/czc/anaconda3/envs/DataAnalysis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/czc/anaconda3/envs/DataAnalysis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/czc/anaconda3/envs/DataAnalysis/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### 使用onehot 与 lable转换一些数据\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder\n",
    "uselessDeletedDf['Trddt']=pd.to_datetime(uselessDeletedDf[\"Trddt\"], format=\"%Y-%m-%d\")\n",
    "start = datetime(2019, 1, 1)\n",
    "end = datetime(2020, 1, 1)\n",
    "uselessDeletedDf=uselessDeletedDf[(uselessDeletedDf['Trddt'] < end) | (uselessDeletedDf['Trddt'] > start)]\n",
    "###增加一个季度变量\n",
    "lableEncoder=LabelEncoder()\n",
    "uselessDeletedDf['Quarter']=[dateToQuarter(i)[1] for i in uselessDeletedDf['Trddt'].values]\n",
    "Trddt_lable=lableEncoder.fit_transform([[x] for x in uselessDeletedDf['Trddt'].values])\n",
    "uselessDeletedDf['Trddt']=Trddt_lable\n",
    "# Stkcd_lable=lableEncoder.fit_transform([[x] for x in uselessDeletedDf['Stkcd'].values])\n",
    "# uselessDeletedDf['Stkcd']=Trddt_lable\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "OWNERSHIPTYPE_onehot = encoder.fit_transform([[x] for x in uselessDeletedDf['OWNERSHIPTYPE'].values])\n",
    "EquityNature_onehot = encoder.fit_transform([[x] for x in uselessDeletedDf['csmar_listedcoinfo.EquityNature'].values])\n",
    "Indnme_onehot = encoder.fit_transform([[x] for x in uselessDeletedDf['Indnme'].values])\n",
    "Nindnme_onehot = encoder.fit_transform([[x] for x in uselessDeletedDf['Nindnme'].values])\n",
    "Nnindnme_onehot = encoder.fit_transform([[x] for x in uselessDeletedDf['Nnindnme'].values])\n",
    "CITY_onehot = encoder.fit_transform([[x] for x in uselessDeletedDf['CITY'].values])\n",
    "# uselessDeletedDf['Stkcd']=uselessDeletedDf['Stkcd'].astype(int)\n",
    "# Stkcd_onehot = encoder.fit_transform([[x] for x in uselessDeletedDf['Stkcd'].values])\n",
    "# Stkcd_onehot"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T14:19:07.751516Z",
     "start_time": "2023-08-28T14:18:07.185533Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def addColumnToDataFrame(name:str, theArray, theDataFrame=uselessDeletedDf):\n",
    "    theDict={}\n",
    "    thelist = [[r[col] for r in theArray] for col in range(len(theArray[0]))]\n",
    "    # print(f\"{name} column: {len(thelist)}\")\n",
    "    # print(f\"{name} row: {[len(a) for a in Color_onehot][0]}\")\n",
    "    numOfColumn = 0\n",
    "    for column in thelist:\n",
    "        theDict[name + str(numOfColumn)] = column\n",
    "        numOfColumn += 1\n",
    "    newDF=pd.DataFrame.from_dict(theDict)\n",
    "    theDataFrame=pd.concat([theDataFrame,newDF])\n",
    "    # return theDataFrame"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T14:19:07.757397Z",
     "start_time": "2023-08-28T14:19:07.753156Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "addColumnToDataFrame('OWNERSHIPTYPE',OWNERSHIPTYPE_onehot)\n",
    "addColumnToDataFrame('csmar_listedcoinfo.EquityNature',EquityNature_onehot)\n",
    "addColumnToDataFrame('Indnme',Indnme_onehot)\n",
    "addColumnToDataFrame('Nindnme',Nindnme_onehot)\n",
    "addColumnToDataFrame('Nnindnme',Nnindnme_onehot)\n",
    "addColumnToDataFrame('CITY',CITY_onehot)\n",
    "# addColumnToDataFrame('Stkcd',Stkcd_onehot)\n",
    "uselessDeletedDf=uselessDeletedDf.drop(columns=['OWNERSHIPTYPE','csmar_listedcoinfo.EquityNature','Indnme','Nindnme','Nnindnme','CITY','Stkcd'])\n",
    "uselessDeletedDf"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-08-28T14:19:07.800323Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### train & test data\n",
    "Y=uselessDeletedDf['ChangeRatio']\n",
    "X=uselessDeletedDf.drop(columns='ChangeRatio')\n",
    "x_train , x_test , y_train , y_test = train_test_split(X,Y , test_size= 0.3 ,random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_regressor = LinearRegression()\n",
    "linear_regressor.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = linear_regressor.predict(x_test)\n",
    "y_trainPredicted=linear_regressor.predict(x_train[-3000:])\n",
    "LR = pd.DataFrame({'y_test':y_test,'y_pred':y_pred})\n",
    "LR"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(LR[:50])\n",
    "plt.legend(['Actual' , 'Predicted'])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
