{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 合并表格"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ### 读取\n",
    "# trd_dalyr0=pd.read_excel(\"stockData/furtherInformation/日个股回报率文件185043337(仅供中央财经大学使用)/TRD_Dalyr.xlsx\")\n",
    "# trd_dalyr0=trd_dalyr0.drop([0,1],axis=0)\n",
    "# trd_dalyr1=pd.read_excel(\"stockData/furtherInformation/日个股回报率文件185043337(仅供中央财经大学使用)/TRD_Dalyr1.xlsx\")\n",
    "# trd_dalyr1=trd_dalyr1.drop([0,1],axis=0)\n",
    "# trd_dalyr2=pd.read_excel(\"stockData/furtherInformation/日个股回报率文件185043337(仅供中央财经大学使用)/TRD_Dalyr2.xlsx\")\n",
    "# trd_dalyr2=trd_dalyr2.drop([0,1],axis=0)\n",
    "# trd_dalyr3=pd.read_excel(\"stockData/furtherInformation/日个股回报率文件185043337(仅供中央财经大学使用)/TRD_Dalyr3.xlsx\")\n",
    "# trd_dalyr3=trd_dalyr3.drop([0,1],axis=0)\n",
    "# trd_dalyr4=pd.read_excel(\"stockData/furtherInformation/日个股回报率文件185043337(仅供中央财经大学使用)/TRD_Dalyr4.xlsx\")\n",
    "# trd_dalyr4=trd_dalyr4.drop([0,1],axis=0)\n",
    "# diaryData=[trd_dalyr0,trd_dalyr1,trd_dalyr2,trd_dalyr3,trd_dalyr4]\n",
    "# finalDF=pd.concat(diaryData)\n",
    "# finalDF"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# companyData=pd.read_excel(\"stockData/furtherInformation/公司文件184301535(仅供中央财经大学使用)/TRD_Co.xlsx\")\n",
    "# companyData=companyData.drop([0,1],axis=0)\n",
    "# companyData"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# companyAssetData=pd.read_excel(\"stockData/furtherInformation/资产负债表(联表查询)181028530/FS_Combas(Merge Query).xlsx\")\n",
    "# companyAssetData=companyAssetData.drop([0,1],axis=0)\n",
    "# companyAssetData"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ### 去除b部分\n",
    "# companyAssetData=companyAssetData[companyAssetData[\"FS_Combas.Typrep\"]!=\"B\"]\n",
    "# companyAssetData=companyAssetData.reindex()\n",
    "# ### 去除12-31，因为与1-1有重复\n",
    "# companyAssetData=companyAssetData[companyAssetData['FS_Combas.Accper'].str.contains(\"01-01|03-31|06-30|09-30\")]\n",
    "# companyAssetData['FS_Combas.Accper']=pd.to_datetime(companyAssetData['FS_Combas.Accper'], format=\"%Y-%m-%d\")\n",
    "# \n",
    "# companyAssetData=companyAssetData.rename(columns={\"FS_Combas.Stkcd\":\"Stkcd\",\"FS_Combas.Accper\":\"Trddt_quarter\"})\n",
    "# companyAssetData"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ### todo：开始合并 日个股回报与公司信息\n",
    "# df=pd.merge(finalDF,companyData,on='Stkcd')\n",
    "# df['Trddt']=pd.to_datetime(df[\"Trddt\"], format=\"%Y-%m-%d\")\n",
    "# df"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "###转换时间为季度\n",
    "def dateToQuarter(date):\n",
    "        # print(\"time: \",date)\n",
    "        quarter_date={1:\"01-01\",2:\"03-31\",3:\"06-30\",4:\"09-30\"}\n",
    "        year=date.astype('datetime64[Y]').astype(int) + 1970\n",
    "        month = date.astype('datetime64[M]').astype(int) % 12 + 1\n",
    "        the_quarter = (month - 1) // 3 + 1                  #计算季度\n",
    "        quarter_name = str(year) + '年' + str(the_quarter) + '季度'\n",
    "        quarter_name_short = str(year) + 'Q' + str(the_quarter)\n",
    "        # print(\"quarter time: \",quarter_name)\n",
    "        return [str(year)+\"-\"+quarter_date[the_quarter],the_quarter]\n",
    "\n",
    "# dateToQuarter(numpy.datetime64(\"2020-04-30\"))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df[\"Trddt_quarter\"]=[dateToQuarter(i)[0] for i in df['Trddt'].values]\n",
    "# df[\"Trddt_quarter\"]=pd.to_datetime(df[\"Trddt_quarter\"], format=\"%Y-%m-%d\")\n",
    "# df"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ###todo：根据季度与股票代码合并之前的总表与资产负债表\n",
    "# allData=pd.merge(df,companyAssetData,on=[\"Stkcd\",'Trddt_quarter'],how='outer')\n",
    "# # allData['Stkcd']=allData['Stkcd'].astype(str)\n",
    "# allData"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# allData.to_csv(\"stockData/furtherInformation/AllData.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 读取疫情数据并合并表格"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "covidData=pd.read_csv(\"stockData/furtherInformation/covid19/CovidNews01.csv\")\n",
    "covidData['Public_Time']=pd.to_datetime(covidData[\"Public_Time\"], format=\"%Y-%m-%d\")\n",
    "covidData"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(covidData.shape)\n",
    "print(len(covidData['Link'].unique()))\n",
    "print(len(covidData['Public_Time'].unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from jieba import analyse\n",
    "\n",
    "# print(\"title: \",covidData['Title'].values[0])\n",
    "# for para in covidData['Content'].values[0].split(\"\\n\"):\n",
    "#     if para.strip()!=\"\":\n",
    "#         print(\"-----------------------\")\n",
    "#         print(para.strip())\n",
    "#         keywords = analyse.extract_tags(para.strip(),withWeight=False)\n",
    "#         print(\"tf-idf筛选：\",keywords)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(covidData['Title'].values[4])\n",
    "print(covidData['Content'].values[4])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 数据去重，并且删除部分缺失值"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# allData=pd.read_csv(\"stockData/furtherInformation/AllData.csv\",index_col=0,dtype=object)\n",
    "# allData['Trddt']=pd.to_datetime(allData[\"Trddt\"], format=\"%Y-%m-%d\")\n",
    "# allData"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ###todo：要删除的重复列名\n",
    "# deleteColumns=[\"Trddt_quarter\",\"FS_Combas.Typrep\",\"FS_Combas.ShortName\",\"csmar_listedcoinfo.Stknme\",\"csmar_listedcoinfo.Conme\",\"FS_Comscfd.ShortName\",\"FS_Comins.ShortName\",\"csmar_listedcoinfo.Conme_en\",\"csmar_listedcoinfo.Nnindcd\",\"csmar_listedcoinfo.PROVINCECD\",\"csmar_listedcoinfo.CITY\",\"csmar_listedcoinfo.Nnindnme\"]\n",
    "# afterDeleteData=allData[[i for i in allData.columns if i not in deleteColumns]]\n",
    "# afterDeleteData"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# afterDeleteData.to_csv(\"stockData/furtherInformation/afterDeleteData.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ### 检查是否有缺失值达到50%的，有的话就删除\n",
    "# totalNumRows=5000412\n",
    "# num = afterDeleteData.isna().sum()\n",
    "# indexs=[]\n",
    "# nullNums=[]\n",
    "# nullPerc=[]\n",
    "# for index in num.index:\n",
    "#     indexs.append(index)\n",
    "#     nullNums.append(num[index])\n",
    "#     nullPerc.append(str(round(float(num[index]/totalNumRows),3)*100)+\" %\")\n",
    "# \n",
    "# num=pd.DataFrame.from_dict({\"Variance\":indexs,\"Number Of Null\":nullNums,\"Percentage Of Null\":nullPerc})\n",
    "# num"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ###todo：删除和处理回归不能输入的数据,删除回报率为null的行,同时删除缺失值过多的 [FS_Combas.A001127000,FS_Combas.A001220000,FS_Combas.A001219000,FS_Combas.A001109000] 列\n",
    "# uselessColumns=[\"FS_Combas.A001127000\",\"FS_Combas.A001220000\",\"FS_Combas.A001219000\",\"FS_Combas.A001109000\",\"Stknme\",\"Listdt\",\"csmar_listedcoinfo.BUSSINESSRANGE\",\"Conme_en\",\"PROVINCECODE\",\"Parvcur\",\"csmar_listedcoinfo.MAINBUSSINESS\",\"CITYCODE\",\"PROVINCE\",\"Cuntrycd\",\"Conme\",\"Nindcd\",\"Nindcd\",\"Nnindcd\",\"OWNERSHIPTYPECODE\",\"Opnprc\",\"Hiprc\",\"Loprc\",\"Clsprc\",\"Indcd\",\"csmar_listedcoinfo.OWNERSHIPTYPE\",\"Markettype\",\"Sctcd\"]\n",
    "# \n",
    "# uselessDeletedDf=allData[[i for i in allData.columns if i not in deleteColumns and i not in uselessColumns]]\n",
    "# uselessDeletedDf=uselessDeletedDf.dropna()\n",
    "# uselessDeletedDf"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "###查看并确定目前的数据类型\n",
    "# print(\"占有类型： \",uselessDeletedDf[\"OWNERSHIPTYPE\"].unique())\n",
    "# print(\"财产类型：\",uselessDeletedDf[\"csmar_listedcoinfo.EquityNature\"].unique())\n",
    "# print(\"产业类型：\",uselessDeletedDf[\"Indnme\"].unique())\n",
    "# print(\"产业细分1：\",uselessDeletedDf[\"Nindnme\"].unique())\n",
    "# print(\"产业细分2：\",uselessDeletedDf[\"Nnindnme\"].unique())\n",
    "# print(\"公司所在地区：\",uselessDeletedDf[\"CITY\"].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# uselessDeletedDf.to_csv(\"stockData/furtherInformation/Input.csv\",index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 数据转换 与 回归"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "uselessDeletedDf=pd.read_csv(\"stockData/furtherInformation/Input.csv\")\n",
    "uselessDeletedDf"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "###由于资产那个表格没有显示医药股，所以需要tushare的表格来查询\n",
    "def getCodeWithoutSuffix(suffix:list,code:str):\n",
    "    for su in suffix:\n",
    "        code=code.replace(su,\"\")\n",
    "    return int(code)\n",
    "tushareData=pd.read_csv(\"stockData/TushareRawData.csv\")\n",
    "suffix=['.SH','.SZ','.BJ']\n",
    "tushareData['ts_code_nosuffix']=[getCodeWithoutSuffix(suffix,str(i)) for i in tushareData['ts_code'].values]\n",
    "tushareData"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tushareData['industry']=tushareData['industry'].astype(str)\n",
    "# tushareData['industry'].unique()\n",
    "###[医药商业]\n",
    "medicIndustry=tushareData[tushareData['industry']=='医药商业']\n",
    "medicIndustry"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "uselessDeletedDf['Stkcd']=uselessDeletedDf['Stkcd'].astype(int)\n",
    "medicUseful=uselessDeletedDf.loc[uselessDeletedDf['Stkcd'].isin(medicIndustry['ts_code_nosuffix'].values)]\n",
    "medicUseful"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "uselessDeletedDf=medicUseful"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### 使用onehot 与 lable转换一些数据\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder\n",
    "uselessDeletedDf['Trddt']=pd.to_datetime(uselessDeletedDf[\"Trddt\"], format=\"%Y-%m-%d\")\n",
    "start = datetime(2019, 1, 1)\n",
    "end = datetime(2019, 6, 1)\n",
    "uselessDeletedDf=uselessDeletedDf[(uselessDeletedDf['Trddt'] < end) | (uselessDeletedDf['Trddt'] > start)]\n",
    "###增加一个季度变量\n",
    "lableEncoder=LabelEncoder()\n",
    "uselessDeletedDf['Quarter']=[dateToQuarter(i)[1] for i in uselessDeletedDf['Trddt'].values]\n",
    "Trddt_lable=lableEncoder.fit_transform([[x] for x in uselessDeletedDf['Trddt'].values])\n",
    "uselessDeletedDf['Trddt']=Trddt_lable\n",
    "# Stkcd_lable=lableEncoder.fit_transform([[x] for x in uselessDeletedDf['Stkcd'].values])\n",
    "# uselessDeletedDf['Stkcd']=Trddt_lable\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "OWNERSHIPTYPE_onehot = encoder.fit_transform([[x] for x in uselessDeletedDf['OWNERSHIPTYPE'].values])\n",
    "EquityNature_onehot = encoder.fit_transform([[x] for x in uselessDeletedDf['csmar_listedcoinfo.EquityNature'].values])\n",
    "Indnme_onehot = encoder.fit_transform([[x] for x in uselessDeletedDf['Indnme'].values])\n",
    "Nindnme_onehot = encoder.fit_transform([[x] for x in uselessDeletedDf['Nindnme'].values])\n",
    "Nnindnme_onehot = encoder.fit_transform([[x] for x in uselessDeletedDf['Nnindnme'].values])\n",
    "CITY_onehot = encoder.fit_transform([[x] for x in uselessDeletedDf['CITY'].values])\n",
    "# uselessDeletedDf['Stkcd']=uselessDeletedDf['Stkcd'].astype(int)\n",
    "Stkcd_onehot = encoder.fit_transform([[x] for x in uselessDeletedDf['Stkcd'].values])\n",
    "uselessDeletedDf"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def addColumnToDataFrame(name:str, theArray, theDataFrame=uselessDeletedDf):\n",
    "    theDict={}\n",
    "    thelist = [[r[col] for r in theArray] for col in range(len(theArray[0]))]\n",
    "    # print(f\"{name} column: {len(thelist)}\")\n",
    "    # print(f\"{name} row: {[len(a) for a in Color_onehot][0]}\")\n",
    "    numOfColumn = 0\n",
    "    for column in thelist:\n",
    "        theDict[name + str(numOfColumn)] = column\n",
    "        numOfColumn += 1\n",
    "    newDF=pd.DataFrame.from_dict(theDict)\n",
    "    theDataFrame=pd.concat([theDataFrame,newDF])\n",
    "    # return theDataFrame"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "addColumnToDataFrame('OWNERSHIPTYPE',OWNERSHIPTYPE_onehot)\n",
    "addColumnToDataFrame('csmar_listedcoinfo.EquityNature',EquityNature_onehot)\n",
    "addColumnToDataFrame('Indnme',Indnme_onehot)\n",
    "addColumnToDataFrame('Nindnme',Nindnme_onehot)\n",
    "addColumnToDataFrame('Nnindnme',Nnindnme_onehot)\n",
    "addColumnToDataFrame('CITY',CITY_onehot)\n",
    "addColumnToDataFrame('Stkcd',Stkcd_onehot)\n",
    "uselessDeletedDf=uselessDeletedDf.drop(columns=['OWNERSHIPTYPE','csmar_listedcoinfo.EquityNature','Indnme','Nindnme','Nnindnme','CITY','Stkcd'])\n",
    "uselessDeletedDf"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### train & test data\n",
    "Y=uselessDeletedDf['ChangeRatio']\n",
    "X=uselessDeletedDf.drop(columns='ChangeRatio')\n",
    "x_train , x_test , y_train , y_test = train_test_split(X,Y , test_size= 0.3 ,random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_regressor = LinearRegression()\n",
    "linear_regressor.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = linear_regressor.predict(x_test)\n",
    "y_trainPredicted=linear_regressor.predict(x_train[-3000:])\n",
    "LR = pd.DataFrame({'y_test':y_test,'y_pred':y_pred})\n",
    "LR"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(LR[:50])\n",
    "plt.legend(['Actual' , 'Predicted'])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from keras.losses import mean_absolute_error\n",
    "from keras.losses import mean_squared_error\n",
    "\n",
    "\n",
    "def calPerformance(y_true,y_pred):\n",
    "    model_metrics_name=[mean_absolute_error, mean_squared_error, r2_score]\n",
    "    tmp_list=[]\n",
    "    for one in model_metrics_name:\n",
    "        tmp_score=one(y_true,y_pred)\n",
    "        tmp_list.append([round(tmp_score,3)])\n",
    "    # print ['explained_variance_score','mean_absolute_error','mean_squared_error','r2_score']\n",
    "    # print tmp_list\n",
    "    row=[\"explained_variance_score\",\"mean_absolute_error\",\"mean_squared_error\",\"r2_score\"]\n",
    "\n",
    "    # fig, ax =plt.subplots(1,1)\n",
    "    # ax.axis('tight')\n",
    "    # ax.axis('off')\n",
    "    # ax.table(cellText=tmp_list,rowLabels=row,loc=\"center\")\n",
    "\n",
    "    # print(f\"explained_variance_score  {tmp_list[0]}\")\n",
    "    print(f\"mean_absolute_error  {tmp_list[0]}\")\n",
    "    print(f\"mean_squared_error  {tmp_list[1]}\")\n",
    "    print(f\"r2_score  {tmp_list[2]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "calPerformance(y_train,y_trainPredicted)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
