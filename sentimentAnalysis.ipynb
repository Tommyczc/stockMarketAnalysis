{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "本文的研究目的是 情感分析"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### todo bert 情绪分析，从网上复制的，看看情况怎么样\n",
    "### https://github.com/rsanshierli/EasyBert/tree/master/Sentiment\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from pytorch_pretrained import BertModel, BertTokenizer\n",
    "\n",
    "\n",
    "class Config(object):\n",
    "\n",
    "    \"\"\"配置参数\"\"\"\n",
    "    def __init__(self):\n",
    "        self.model_name = 'bert'\n",
    "        self.class_list = ['中性', '积极', '消极']          # 类别名单\n",
    "        self.save_path = './Sentiment/saved_dict/bert.ckpt'        # 模型训练结果\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   # 设备\n",
    "\n",
    "        self.require_improvement = 1000                                 # 若超过1000batch效果还没提升，则提前结束训练\n",
    "        self.num_classes = len(self.class_list)                         # 类别数\n",
    "        self.num_epochs = 3                                             # epoch数\n",
    "        self.batch_size = 128                                           # mini-batch大小\n",
    "        self.pad_size = 32                                              # 每句话处理成的长度(短填长切)\n",
    "        self.learning_rate = 5e-5                                       # 学习率\n",
    "        self.bert_path = './bert_pretrain'\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.bert_path)\n",
    "        self.hidden_size = 768\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(Model, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(config.bert_path)\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.fc = nn.Linear(config.hidden_size, config.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        context = x[0]  # 输入的句子\n",
    "        mask = x[2]  # 对padding部分进行mask，和句子一个size，padding部分用0表示，如：[1, 1, 1, 1, 0, 0]\n",
    "        _, pooled = self.bert(context, attention_mask=mask, output_all_encoded_layers=False)\n",
    "        out = self.fc(pooled)\n",
    "        return out\n",
    "\n",
    "\n",
    "PAD, CLS = '[PAD]', '[CLS]'  # padding符号, bert中综合信息符号\n",
    "\n",
    "def clean(text):\n",
    "    # text = re.sub(r\"(回复)?(//)?\\s*@\\S*?\\s*(:| |$)\", \" \", text)  # 去除正文中的@和回复/转发中的用户名\n",
    "    # text = re.sub(r\"\\[\\S+\\]\", \"\", text)  # 去除表情符号\n",
    "    # text = re.sub(r\"#\\S+#\", \"\", text)  # 保留话题内容\n",
    "    URL_REGEX = re.compile(\n",
    "        r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))',\n",
    "        re.IGNORECASE)\n",
    "    text = re.sub(URL_REGEX, \"\", text)  # 去除网址\n",
    "    text = text.replace(\"转发微博\", \"\")  # 去除无意义的词语\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # 合并正文中过多的空格\n",
    "    return text.strip()\n",
    "\n",
    "def load_dataset(data, config):\n",
    "    pad_size = config.pad_size\n",
    "    contents = []\n",
    "    for line in data:\n",
    "        lin = clean(line)\n",
    "        token = config.tokenizer.tokenize(lin)      # 分词\n",
    "        token = [CLS] + token                           # 句首加入CLS\n",
    "        seq_len = len(token)\n",
    "        mask = []\n",
    "        token_ids = config.tokenizer.convert_tokens_to_ids(token)\n",
    "\n",
    "        if pad_size:\n",
    "            if len(token) < pad_size:\n",
    "                mask = [1] * len(token_ids) + [0] * (pad_size - len(token))\n",
    "                token_ids += ([0] * (pad_size - len(token)))\n",
    "            else:\n",
    "                mask = [1] * pad_size\n",
    "                token_ids = token_ids[:pad_size]\n",
    "                seq_len = pad_size\n",
    "        contents.append((token_ids, int(0), seq_len, mask))\n",
    "    return contents\n",
    "\n",
    "class DatasetIterater(object):\n",
    "    def __init__(self, batches, batch_size, device):\n",
    "        self.batch_size = batch_size\n",
    "        self.batches = batches     # data\n",
    "        self.n_batches = len(batches) // batch_size\n",
    "        self.residue = False  # 记录batch数量是否为整数\n",
    "        if len(batches) % self.n_batches != 0:\n",
    "            self.residue = True\n",
    "        self.index = 0\n",
    "        self.device = device\n",
    "\n",
    "    def _to_tensor(self, datas):\n",
    "        x = torch.LongTensor([_[0] for _ in datas]).to(self.device)\n",
    "        y = torch.LongTensor([_[1] for _ in datas]).to(self.device)\n",
    "\n",
    "        # pad前的长度(超过pad_size的设为pad_size)\n",
    "        seq_len = torch.LongTensor([_[2] for _ in datas]).to(self.device)\n",
    "        mask = torch.LongTensor([_[3] for _ in datas]).to(self.device)\n",
    "        return (x, seq_len, mask), y\n",
    "\n",
    "    def __next__(self):     # 返回下一个迭代器对象，必须控制结束条件\n",
    "        if self.residue and self.index == self.n_batches:\n",
    "            batches = self.batches[self.index * self.batch_size: len(self.batches)]\n",
    "            self.index += 1\n",
    "            batches = self._to_tensor(batches)\n",
    "            return batches\n",
    "\n",
    "        elif self.index >= self.n_batches:\n",
    "            self.index = 0\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            batches = self.batches[self.index * self.batch_size: (self.index + 1) * self.batch_size]\n",
    "            self.index += 1\n",
    "            batches = self._to_tensor(batches)\n",
    "            return batches\n",
    "\n",
    "    def __iter__(self):     # 返回一个特殊的迭代器对象，这个迭代器对象实现了 __next__() 方法并通过 StopIteration 异常标识迭代的完成。\n",
    "        return self\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.residue:\n",
    "            return self.n_batches + 1\n",
    "        else:\n",
    "            return self.n_batches\n",
    "\n",
    "\n",
    "def build_iterator(dataset, config):\n",
    "    iter = DatasetIterater(dataset, 1, config.device)\n",
    "    return iter\n",
    "\n",
    "\n",
    "def match_label(pred, config):\n",
    "    label_list = config.class_list\n",
    "    return label_list[pred]\n",
    "\n",
    "\n",
    "def final_predict(config, model, data_iter):\n",
    "    map_location = lambda storage, loc: storage\n",
    "    model.load_state_dict(torch.load(config.save_path, map_location=map_location))\n",
    "    model.eval()\n",
    "    predict_all = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for texts, _ in data_iter:\n",
    "            outputs = model(texts)\n",
    "            pred = torch.max(outputs.data, 1)[1].cpu().numpy()\n",
    "            pred_label = [match_label(i, config) for i in pred]\n",
    "            predict_all = np.append(predict_all, pred_label)\n",
    "\n",
    "    return predict_all\n",
    "\n",
    "def main(text):\n",
    "    config = Config()\n",
    "    model = Model(config).to(config.device)\n",
    "    test_data = load_dataset(text, config)\n",
    "    test_iter = build_iterator(test_data, config)\n",
    "    result = final_predict(config, model, test_iter)\n",
    "    for i, j in enumerate(result):\n",
    "        print('text:{}'.format(text[i]))\n",
    "        print('label:{}'.format(j))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    test = ['#你好2020#新年第一天元气满满的早起出门买早饭结果高估了自己抗冻能力回家成功冻发烧（大概是想告诉我2020要量力而行）然鹅这并不影响后续计划一出门立马生龙活虎新年和新??更配哦??看了误杀吃了大餐就让新的一年一直这样美滋滋下去吧??',\n",
    "            '大宝又感冒鼻塞咳嗽了，还有发烧。队友加班几天不回。感觉自己的情绪在家已然是随时引爆的状态。情绪一上来，容易对孩子说出自己都想不到的话来……2020年，真的要学会控制情绪，管理好家人健康。这是今年最大的目标。?',\n",
    "            '还要去输两天液，这天也太容易感冒发烧了，一定要多喝热水啊?',\n",
    "            '我太难了别人怎么发烧都没事就我一检查甲型流感?',\n",
    "            '果然是要病一场的喽回来第三天开始感冒今儿还发烧了喉咙眼睛都难受的一匹怎么样能不经意让我的毕设导师看到这条微博并给我放一天假呢?']\n",
    "    main(test)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
