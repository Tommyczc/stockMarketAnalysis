{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1.0 Get the raw news information\n",
    "* 本篇代码用来获取相关公司的新闻文本\n",
    "* 由于信息渠道广泛，将会爬虫数个新闻网站: [新浪新闻，微信公众号]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 新浪新闻获取"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, news\n",
      "Load time  0:00:00.216617\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import xlwt as xlwt\n",
    "\n",
    "print(\"Hello, news\")\n",
    "from datetime import datetime\n",
    "now=datetime.now()\n",
    "import numpy as np\n",
    "from pylab import mpl\n",
    "# todo: solve chinese problem for plt\n",
    "mpl.rcParams['font.sans-serif']=['SimHei']\n",
    "mpl.rcParams['axes.unicode_minus']=False\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import json\n",
    "from pyppeteer import launch\n",
    "from bs4 import BeautifulSoup\n",
    "from pyppeteer import launcher\n",
    "launcher.DEFAULT_ARGS.remove(\"--enable-automation\")\n",
    "print(\"Load time \",datetime.now()-now)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T06:35:59.636381Z",
     "start_time": "2023-08-30T06:35:59.401397Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from requests import RequestException\n",
    "\n",
    "\n",
    "class newsToolForSina:\n",
    "    @staticmethod\n",
    "    def get_list(url):\n",
    "\n",
    "        # 新闻链接\n",
    "        res=requests.get(url)\n",
    "        res.encoding='utf-8'\n",
    "\n",
    "        # 完整HTML\n",
    "        html=BeautifulSoup(res.text,'html.parser')\n",
    "\n",
    "        # 新闻列表\n",
    "        newList=[]\n",
    "\n",
    "        for item in html.find_all('div',['news-item','img-news-item']):\n",
    "            try:\n",
    "                newObj={}\n",
    "                newObj['title']=item.select('h2 a')[0].text\n",
    "                newObj['url']=item.select('h2 a')[0].get('href')\n",
    "                newList.append(newObj)\n",
    "            except:\n",
    "                print('出现异常')\n",
    "        return newList\n",
    "\n",
    "    @staticmethod\n",
    "    def get_HtmlDetail_Sina(url):\n",
    "\n",
    "        # 新闻链接\n",
    "        res=requests.get(url)\n",
    "        res.encoding='utf-8'\n",
    "\n",
    "        # 完整HTML\n",
    "        html=BeautifulSoup(res.text,'html.parser')\n",
    "\n",
    "        # 新闻对象\n",
    "        result={}\n",
    "\n",
    "        # 新闻标题\n",
    "        result['title']=html.select('.main-title')[0].text\n",
    "\n",
    "        # 发布时间\n",
    "        timesource=html.select('.date-source span')[0].text\n",
    "        createtime=datetime.strptime(timesource,'%Y年%m月%d日 %H:%M')\n",
    "        createtime.strftime('%Y-%m-%d')\n",
    "        result['createtime']=createtime\n",
    "\n",
    "        # 新闻来源\n",
    "        result['place']=html.select('.date-source a')[0].text\n",
    "\n",
    "        # 新闻内容\n",
    "        article=[]\n",
    "        for p in html.select('#article p')[:-1]:\n",
    "            article.append(p.text.strip())\n",
    "        articleText=' '.join(article)\n",
    "        result['article']=articleText\n",
    "\n",
    "        # 新闻作者\n",
    "        result['author']=html.select('.show_author')[0].text.strip('责任编辑：')\n",
    "\n",
    "        # 新闻链接\n",
    "        result['url']=url\n",
    "\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def get_page_news(browser,urlList):\n",
    "        #获取当前页面所有包含新闻的a标签\n",
    "        news = browser.find_elements(\"xpath\",'//div[@class=\"d_list_txt\"]/ul/li/span/a')\n",
    "        if len(news)==0:\n",
    "            return np.nan\n",
    "        for i in news:\n",
    "            link = i.get_attribute('href') #得到新闻url\n",
    "            # print(len(urlList),link)\n",
    "            if link not in urlList:  #通过url去重\n",
    "                urlList.append(link)\n",
    "        return urlList\n",
    "\n",
    "    @staticmethod\n",
    "    def getNewsData(url):\n",
    "        # 获取新闻的详细信息\n",
    "        html = newsToolForSina.get_response(url)\n",
    "        #使用beautifulsoup进行解析\n",
    "        soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "        #标题\n",
    "        '''\n",
    "        <h1 class=\"main-title\">证监会要求北京银行说明是否串通*ST康得管理层舞弊</h1>\n",
    "        '''\n",
    "        title = soup.select('.main-title')\n",
    "        #可能有小部分标题的标签不是上述格式 对其进行补充\n",
    "        if not title:\n",
    "            title = soup.select('#artibodyTitle')\n",
    "        if title:\n",
    "            title = title[0].text\n",
    "        # print(title)\n",
    "\n",
    "        #日期\n",
    "        '''\n",
    "        <span class=\"date\">2019年07月20日 16:52</span>\n",
    "        '''\n",
    "        date = soup.select('.date')\n",
    "        # 可能有小部分日期的标签不是上述格式 对其进行补充\n",
    "        if not date:\n",
    "            date = soup.select('#pub_date')\n",
    "        if date:\n",
    "            date = date[0].text\n",
    "        # print(date)\n",
    "\n",
    "        #来源\n",
    "        '''\n",
    "        <span class=\"source ent-source\">中国证券报</span>\n",
    "        '''\n",
    "        source = soup.select('.source')\n",
    "        # 可能有小部分来源的标签不是上述格式 对其进行补充\n",
    "        if not source:\n",
    "            source = soup.select('[data-sudaclick=\"media_name\"]')\n",
    "        if source:\n",
    "            source = source[0].text\n",
    "        # print(source)\n",
    "\n",
    "        #正文\n",
    "        article = soup.select('div[class=\"article\"] p')\n",
    "        # 可能有小部分正文的标签不是上述格式 对其进行补充\n",
    "        if not article:\n",
    "            article = soup.select('div[id=\"artibody\"] p')\n",
    "        if article:\n",
    "            #把正文放在一个列表中 每个p标签的内容为列表的一项\n",
    "            article_list = []\n",
    "            for i in article:\n",
    "                # print(i.text)\n",
    "                article_list.append(i.text)\n",
    "        #转为字典格式\n",
    "        news = {'link': url, 'title': title, 'date': date, 'source': source, 'article': article_list}\n",
    "        return news\n",
    "\n",
    "    @staticmethod\n",
    "    def get_response(url):\n",
    "        try:\n",
    "            #添加User-Agent，放在headers中，伪装成浏览器\n",
    "            headers = {\n",
    "                'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36'\n",
    "            }\n",
    "            response = requests.get(url,headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                response.encoding = 'utf-8'\n",
    "                return response.text\n",
    "            return None\n",
    "        except RequestException:\n",
    "            return None\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T06:35:59.657884Z",
     "start_time": "2023-08-30T06:35:59.633715Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "###test\n",
    "# newList=newsToolForSina.get_list('https://news.sina.com.cn/world/')\n",
    "# resultList=pd.DataFrame()\n",
    "#\n",
    "# for i,item in enumerate(newList):\n",
    "#     try:\n",
    "#         result=newsToolForSina.get_HtmlDetail_Sina(item['url'])\n",
    "#         newObj=pd.DataFrame(result,index=[0])\n",
    "#         resultList=resultList.append(newObj)\n",
    "#         print (str(i),'写入成功')\n",
    "#     except BaseException as err:\n",
    "#         print (str(i),'出现异常: ',err)\n",
    "#\n",
    "# resultList.to_csv(\"newsData/test.csv\",header=resultList.columns)\n",
    "# resultList"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T06:35:59.662796Z",
     "start_time": "2023-08-30T06:35:59.645170Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 注意: 新浪新闻的历史数据只能查到近期一个月的，并不能查之前的，所以新浪的可以放弃一部分了"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# from selenium.common import NoSuchElementException\n",
    "#\n",
    "# #打开浏览器\n",
    "# UrlList=[]\n",
    "# browser = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "# browser.implicitly_wait(10)\n",
    "# #打开网址\n",
    "# browser.get('https://news.sina.com.cn/roll/')\n",
    "# #获取当前页面新闻的url\n",
    "# UrlList=newsToolForSina.get_page_news(browser,urlList=UrlList)\n",
    "# while True:\n",
    "#     try:\n",
    "#         #找到下一页按钮 并点击\n",
    "#         '''\n",
    "#         <a href=\"javascript:void(0)\" onclick=\"newsList.page.next();return false;\">下一页</a>\n",
    "#         '''\n",
    "#         browser.find_element(\"xpath\",'//a[@onclick=\"newsList.page.next();return false;\"]').click()\n",
    "#         #获取下一页新闻的url\n",
    "#         result=newsToolForSina.get_page_news(browser,urlList=UrlList)\n",
    "#         if result is np.nan:\n",
    "#             break\n",
    "#     except BaseException as err:\n",
    "#         print(err)\n",
    "#         browser.close()\n",
    "#\n",
    "#\n",
    "# print(\"Have found {} URL records, trying to get news text data\".format(len(UrlList)))\n",
    "# resultList=pd.DataFrame()\n",
    "# for i,item in enumerate(UrlList):\n",
    "#     try:\n",
    "#         result=newsToolForSina.getNewsData(item)\n",
    "#         newObj=pd.DataFrame(result)\n",
    "#         resultList=resultList.append(newObj)\n",
    "#         print (str(i),'写入成功')\n",
    "#         # break\n",
    "#     except BaseException as err:\n",
    "#         print (str(i),'出现异常: ',err)\n",
    "#         # break\n",
    "#\n",
    "#\n",
    "# resultList.to_csv(\"newsData/SinaNewsRawData.csv\",header=resultList.columns)\n",
    "# resultList"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T06:35:59.662959Z",
     "start_time": "2023-08-30T06:35:59.648554Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "       Unnamed: 0                                               link  \\\n0               0  https://finance.sina.com.cn/roll/2023-05-12/do...   \n1               1  https://finance.sina.com.cn/roll/2023-05-12/do...   \n2               2  https://finance.sina.com.cn/roll/2023-05-12/do...   \n3               3  https://finance.sina.com.cn/roll/2023-05-12/do...   \n4               4  https://finance.sina.com.cn/roll/2023-05-12/do...   \n...           ...                                                ...   \n47350           2  https://finance.sina.com.cn/tob/2023-05-10/doc...   \n47351           0  https://finance.sina.com.cn/tob/2023-05-10/doc...   \n47352           1  https://finance.sina.com.cn/tob/2023-05-10/doc...   \n47353           0  https://finance.sina.com.cn/tob/2023-05-10/doc...   \n47354           1  https://finance.sina.com.cn/tob/2023-05-10/doc...   \n\n                                 title               date source  \\\n0                 4月居民存款锐减之谜，1.2万亿去哪了？  2023年05月12日 16:48   第一财经   \n1                 4月居民存款锐减之谜，1.2万亿去哪了？  2023年05月12日 16:48   第一财经   \n2                 4月居民存款锐减之谜，1.2万亿去哪了？  2023年05月12日 16:48   第一财经   \n3                 4月居民存款锐减之谜，1.2万亿去哪了？  2023年05月12日 16:48   第一财经   \n4                 4月居民存款锐减之谜，1.2万亿去哪了？  2023年05月12日 16:48   第一财经   \n...                                ...                ...    ...   \n47350      蒙牛乳业5月9日斥资约1826.08万港元回购55万股  2023年05月10日 08:59   新浪港股   \n47351   太古股份公司A5月9日斥资272.95万港元回购4.55万股  2023年05月10日 08:58   新浪港股   \n47352   太古股份公司A5月9日斥资272.95万港元回购4.55万股  2023年05月10日 08:58   新浪港股   \n47353  太古股份公司B5月9日耗资约550.67万港元回购55.5万股  2023年05月10日 08:58   新浪港股   \n47354  太古股份公司B5月9日耗资约550.67万港元回购55.5万股  2023年05月10日 08:58   新浪港股   \n\n                                                 article  \n0                 　　炒股就看金麒麟分析师研报，权威，专业，及时，全面，助您挖掘潜力主题机会！  \n1      　　但这在数据上并未得到印证。国家统计局公布的数据显示，4月份，全国CPI同比上涨0.1%；...  \n2                                 　　4月居民存款大幅减少引起市场的广泛热议。  \n3      　　央行最新公布的4月金融数据显示，4月人民币存款减少4609亿元，同比多减5524亿元，其...  \n4      　　不少分析认为，4月居民存款减少或源自“提前还贷”和消费回升所致；另外的观点则认为，4月份...  \n...                                                  ...  \n47350                                          责任编辑：卢昱君   \n47351  　　太古股份公司A（00019）发布公告，于2023年5月9日斥资272.95万港元回购4....  \n47352                                          责任编辑：卢昱君   \n47353  　　太古股份公司B（00087）公布，2023年5月9日耗资约550.67万港元回购55.5...  \n47354                                          责任编辑：卢昱君   \n\n[47355 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>link</th>\n      <th>title</th>\n      <th>date</th>\n      <th>source</th>\n      <th>article</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>https://finance.sina.com.cn/roll/2023-05-12/do...</td>\n      <td>4月居民存款锐减之谜，1.2万亿去哪了？</td>\n      <td>2023年05月12日 16:48</td>\n      <td>第一财经</td>\n      <td>炒股就看金麒麟分析师研报，权威，专业，及时，全面，助您挖掘潜力主题机会！</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>https://finance.sina.com.cn/roll/2023-05-12/do...</td>\n      <td>4月居民存款锐减之谜，1.2万亿去哪了？</td>\n      <td>2023年05月12日 16:48</td>\n      <td>第一财经</td>\n      <td>但这在数据上并未得到印证。国家统计局公布的数据显示，4月份，全国CPI同比上涨0.1%；...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>https://finance.sina.com.cn/roll/2023-05-12/do...</td>\n      <td>4月居民存款锐减之谜，1.2万亿去哪了？</td>\n      <td>2023年05月12日 16:48</td>\n      <td>第一财经</td>\n      <td>4月居民存款大幅减少引起市场的广泛热议。</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>https://finance.sina.com.cn/roll/2023-05-12/do...</td>\n      <td>4月居民存款锐减之谜，1.2万亿去哪了？</td>\n      <td>2023年05月12日 16:48</td>\n      <td>第一财经</td>\n      <td>央行最新公布的4月金融数据显示，4月人民币存款减少4609亿元，同比多减5524亿元，其...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>https://finance.sina.com.cn/roll/2023-05-12/do...</td>\n      <td>4月居民存款锐减之谜，1.2万亿去哪了？</td>\n      <td>2023年05月12日 16:48</td>\n      <td>第一财经</td>\n      <td>不少分析认为，4月居民存款减少或源自“提前还贷”和消费回升所致；另外的观点则认为，4月份...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>47350</th>\n      <td>2</td>\n      <td>https://finance.sina.com.cn/tob/2023-05-10/doc...</td>\n      <td>蒙牛乳业5月9日斥资约1826.08万港元回购55万股</td>\n      <td>2023年05月10日 08:59</td>\n      <td>新浪港股</td>\n      <td>责任编辑：卢昱君</td>\n    </tr>\n    <tr>\n      <th>47351</th>\n      <td>0</td>\n      <td>https://finance.sina.com.cn/tob/2023-05-10/doc...</td>\n      <td>太古股份公司A5月9日斥资272.95万港元回购4.55万股</td>\n      <td>2023年05月10日 08:58</td>\n      <td>新浪港股</td>\n      <td>太古股份公司A（00019）发布公告，于2023年5月9日斥资272.95万港元回购4....</td>\n    </tr>\n    <tr>\n      <th>47352</th>\n      <td>1</td>\n      <td>https://finance.sina.com.cn/tob/2023-05-10/doc...</td>\n      <td>太古股份公司A5月9日斥资272.95万港元回购4.55万股</td>\n      <td>2023年05月10日 08:58</td>\n      <td>新浪港股</td>\n      <td>责任编辑：卢昱君</td>\n    </tr>\n    <tr>\n      <th>47353</th>\n      <td>0</td>\n      <td>https://finance.sina.com.cn/tob/2023-05-10/doc...</td>\n      <td>太古股份公司B5月9日耗资约550.67万港元回购55.5万股</td>\n      <td>2023年05月10日 08:58</td>\n      <td>新浪港股</td>\n      <td>太古股份公司B（00087）公布，2023年5月9日耗资约550.67万港元回购55.5...</td>\n    </tr>\n    <tr>\n      <th>47354</th>\n      <td>1</td>\n      <td>https://finance.sina.com.cn/tob/2023-05-10/doc...</td>\n      <td>太古股份公司B5月9日耗资约550.67万港元回购55.5万股</td>\n      <td>2023年05月10日 08:58</td>\n      <td>新浪港股</td>\n      <td>责任编辑：卢昱君</td>\n    </tr>\n  </tbody>\n</table>\n<p>47355 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultList=pd.read_csv(\"newsData/SinaNewsRawData.csv\")\n",
    "resultList"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T06:35:59.837245Z",
     "start_time": "2023-08-30T06:35:59.650963Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T06:35:59.841934Z",
     "start_time": "2023-08-30T06:35:59.837401Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 新闻联播文本稿"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T06:35:59.842150Z",
     "start_time": "2023-08-30T06:35:59.839728Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 微博基于关键字内容爬取 (主要内容: 文章文本，观看人数，评论，点赞)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T06:35:59.847132Z",
     "start_time": "2023-08-30T06:35:59.841890Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4 微信公众号基于关键字爬取 (主要内容: 文章文本，评论，点赞，收藏)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T06:35:59.847284Z",
     "start_time": "2023-08-30T06:35:59.844097Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.5 卫生办 新冠病毒 人数统计(日)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "class newsToolForHealthCenter:\n",
    "    @staticmethod\n",
    "    def get_page_news(keyword:str,browser,urlList:[],endTime:str):\n",
    "        \n",
    "        news = browser.find_elements(\"xpath\",'/html/body/div[2]/div/div[1]//*[@class=\"wordGuide Residence-permit\"]//*[@class=\"bigTit clearfix\"]/a')\n",
    "        if len(news)==0:\n",
    "            return np.nan\n",
    "        print(\"--------------new page--------------\")\n",
    "        for i in news:\n",
    "            title=i.get_attribute(\"title\")\n",
    "            link = i.get_attribute('href') #得到新闻url\n",
    "            if re.match(keyword,title):\n",
    "                print(\"Found: \",title)\n",
    "                urlList.append([title,link])\n",
    "            # print(title)\n",
    "            # print(link)\n",
    "        \n",
    "        \n",
    "        return urlList\n",
    "    \n",
    "    @staticmethod\n",
    "    async def getPageContent(url:str):\n",
    "        publicDate=\"\"\n",
    "        source=\"\"\n",
    "        content=\"\"\n",
    "        dateRe=\"发布时间：.?\"\n",
    "        sourceRe=\"来源:.?\"\n",
    "        # 获取新闻的详细信息\n",
    "        html=await newsToolForHealthCenter.pyppteer_fetchUrl(url)\n",
    "        #使用beautifulsoup进行解析\n",
    "        soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "        #日期\n",
    "        '''\n",
    "        <source>\n",
    "            <span>发布时间：2022-09-02</span>\n",
    "        '''\n",
    "        origin = soup.find_all('span')\n",
    "        # 可能有小部分日期的标签不是上述格式 对其进行补充\n",
    "        for ele in origin:\n",
    "            if re.match(string=ele.text.strip(),pattern=dateRe):\n",
    "                # print(ele.text)\n",
    "                publicDate=ele.text.replace(\"发布时间：\",\"\").strip()\n",
    "            if re.match(string=ele.text.strip(),pattern=sourceRe):\n",
    "                # print(ele.text)\n",
    "                source=ele.text.replace(\"来源:\",\"\").strip()\n",
    "\n",
    "        #正文\n",
    "        article = soup.find(id=\"xw_box\").text.strip()\n",
    "        # print(\"---------------\")\n",
    "        # print(article)\n",
    "        content=article\n",
    "        return {\"Public_Date\":publicDate,\"Source\":source,\"Content\":content}\n",
    "\n",
    "    @staticmethod\n",
    "    async def pyppteer_fetchUrl(url):\n",
    "        browser = await launch({'headless': False,'dumpio':True, 'autoClose':True})\n",
    "        page = await browser.newPage()\n",
    "        await page.goto(url)\n",
    "        await page.waitFor(100)\n",
    "        await asyncio.wait([page.waitForNavigation()])\n",
    "        str = await page.content()\n",
    "        await browser.close()\n",
    "        return str\n",
    "    \n",
    "    # @staticmethod\n",
    "    # async def fetchUrl(url):\n",
    "    #     return await newsToolForHealthCenter.pyppteer_fetchUrl(url)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T06:35:59.855952Z",
     "start_time": "2023-08-30T06:35:59.847780Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# import asyncio\n",
    "# import nest_asyncio\n",
    "# \n",
    "# # 👇️ call apply()\n",
    "# nest_asyncio.apply()\n",
    "# url = 'http://www.nhc.gov.cn/yjb/s7860/202209/e0a18445e0ab47608527b9c910f77699.shtml'\n",
    "# \n",
    "# async def fetchUrl(url):\n",
    "#     browser = await launch({'headless': False,'dumpio':True, 'autoClose':True})\n",
    "#     page = await browser.newPage()\n",
    "# \n",
    "#     await page.goto(url)\n",
    "#     await asyncio.wait([page.waitForNavigation()])\n",
    "#     str = await page.content()\n",
    "#     await browser.close()\n",
    "#     print(\"-------------------\")\n",
    "#     print(str)\n",
    "# \n",
    "# asyncio.get_event_loop().run_until_complete(fetchUrl(url))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T06:35:59.883424Z",
     "start_time": "2023-08-30T06:35:59.856500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------new page--------------\n",
      "Found:  截至10月22日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至10月20日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至10月11日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月28日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月22日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至10月6日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至10月4日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月30日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月6日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至10月29日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至10月18日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至10月10日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至10月3日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至10月2日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月26日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至11月4日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至11月2日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至11月1日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至10月23日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至10月1日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至10月26日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至10月16日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至10月12日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月16日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月12日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月10日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月2日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月31日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至10月28日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至10月24日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至10月21日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至10月19日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至10月14日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至10月8日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至10月7日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月29日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月21日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月11日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月5日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至11月4日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至9月3日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月1日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至10月13日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月19日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月18日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月17日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月15日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月14日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月13日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月9日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至9月12日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月10日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月2日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月31日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至10月25日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至10月9日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月24日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月23日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月3日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月1日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至10月12日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月16日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月12日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月10日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至9月2日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月31日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至11月5日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至11月6日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至11月7日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至11月3日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至8月28日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月22日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月13日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月5日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至7月26日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至6月30日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至6月8日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月29日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月28日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月27日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月8日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月18日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月16日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月19日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月14日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月10日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至8月9日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至7月25日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至7月22日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至7月7日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至6月29日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至6月28日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至6月22日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至6月17日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月18日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月17日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至5月9日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月18日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月11日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月10日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月28日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月27日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月21日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月4日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月3日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月11日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至2月6日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月26日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月11日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月7日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月21日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月20日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月18日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月12日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至7月27日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至7月24日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至7月21日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至7月10日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至7月9日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至7月2日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至6月26日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至6月9日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至6月3日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月29日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月26日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月23日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至5月11日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月10日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月8日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月3日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月2日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月14日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月16日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月10日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月9日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月7日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至8月15日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月6日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月4日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月1日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至7月23日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至7月18日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至7月17日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至6月23日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至6月4日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月25日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至5月21日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月13日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月12日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月24日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月23日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月11日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月10日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月7日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月14日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月11日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至5月18日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月17日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月18日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月11日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月10日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月28日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月27日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月21日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月4日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月3日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至5月27日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月7日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月21日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月22日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月17日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月14日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月2日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月25日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月18日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月30日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至7月9日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至6月26日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至6月9日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至6月3日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月29日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月26日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月23日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月11日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月10日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月8日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至5月2日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月14日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月10日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月9日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月7日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至6月14日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月28日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月19日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月1日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月27日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至4月23日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月17日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月15日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月7日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月25日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月21日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月21日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月6日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月2日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月1日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至8月17日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至6月24日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至6月19日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至6月7日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至6月2日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月4日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月30日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月19日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月6日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月5日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至4月1日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月9日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月13日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月28日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月5日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至7月20日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至7月15日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至7月4日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至6月18日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月30日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至5月16日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月29日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月15日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至6月15日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至6月13日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月14日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月20日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月3日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月29日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月19日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至3月6日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月17日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月29日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月24日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月22日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月13日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月12日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月8日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月26日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月23日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至2月17日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月29日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月24日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月22日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月13日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月12日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月8日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月26日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月23日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至7月29日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至7月5日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至6月25日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月18日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月26日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月23日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月17日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月7日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至7月30日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月5日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月29日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至3月5日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月2日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月9日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月20日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月26日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月16日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月13日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月12日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月2日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月24日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至8月27日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月8日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月3日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至7月28日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至7月8日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至6月16日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至6月1日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至5月15日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月25日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月5日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至4月4日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月31日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月8日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月24日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月2日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至7月3日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月8日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月23日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月16日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月5日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至2月26日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至7月30日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月22日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月20日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月18日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月4日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月19日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月14日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月10日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至6月13日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至2月19日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月2日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月23日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月16日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月5日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月3日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月4日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至3月15日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月31日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至4月25日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至8月23日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月17日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月17日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月24日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月8日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至12月27日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至12月13日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至12月11日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至12月28日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至12月26日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至2月3日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至2月19日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月31日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至1月15日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至8月25日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至12月22日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至12月18日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至12月6日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至12月5日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至11月21日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至11月17日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至11月13日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至11月29日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至11月24日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至11月18日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至11月10日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至12月3日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至11月30日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至11月28日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至12月23日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至12月16日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至12月1日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至11月11日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至11月23日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至11月16日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至11月15日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至12月31日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至12月25日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至12月12日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至11月22日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至12月2日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至12月19日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至12月30日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "Found:  截至12月25日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至12月23日24时新型冠状病毒肺炎疫情最新情况\n",
      "Found:  截至12月12日24时新型冠状病毒肺炎疫情最新情况\n",
      "--------------new page--------------\n",
      "--------------new page--------------\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.support import wait\n",
    "from selenium.common import NoSuchElementException\n",
    "\n",
    "#打开浏览器\n",
    "browser = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "browser.implicitly_wait(100)\n",
    "#打开网址\n",
    "browser.get('http://zs.kaipuyun.cn/s?searchWord=%25E6%2596%25B0%25E5%259E%258B%25E5%2586%25A0%25E7%258A%25B6%25E7%2597%2585%25E6%25AF%2592%25E8%2582%25BA%25E7%2582%258E&column=%25E6%259C%25AC%25E7%25AB%2599&pageSize=10&pageNum=0&siteCode=N000001642&sonSiteCode=&checkHandle=1&searchSource=0&areaSearchFlag=0&secondSearchWords=&topical=&docName=&label=&countKey=0&uc=0&left_right_index=0&searchBoxSettingsIndex=&isSecondSearch=undefined&manualWord=%25E6%2596%25B0%25E5%259E%258B%25E5%2586%25A0%25E7%258A%25B6%25E7%2597%2585%25E6%25AF%2592%25E8%2582%25BA%25E7%2582%258E&orderBy=0&startTime=&endTime=&timeStamp=0&strFileType=&wordPlace=0')\n",
    "#获取当前页面新闻的url\n",
    "keywords=\"截至.+新型冠状病毒肺炎疫情最新情况\"\n",
    "endTime=\"2018-6-6\"\n",
    "urlList=[]\n",
    "urlList=newsToolForHealthCenter.get_page_news(keywords,browser,urlList=urlList,endTime=endTime)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        #找到下一页按钮 并点击\n",
    "        browser.find_element(\"xpath\",'//*[@id=\"pageInfo\"]//*[@class=\"next\"]/a').click()\n",
    "        #获取下一页新闻的url\n",
    "        result=newsToolForHealthCenter.get_page_news(keywords,browser,urlList=urlList,endTime=endTime)\n",
    "\n",
    "        if result is np.nan:\n",
    "            break\n",
    "    except BaseException as err:\n",
    "        # print(err)\n",
    "        browser.close()\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T06:39:58.306521Z",
     "start_time": "2023-08-30T06:35:59.860684Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362\n"
     ]
    }
   ],
   "source": [
    "print(len(urlList))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T06:39:58.311726Z",
     "start_time": "2023-08-30T06:39:58.307538Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "DevTools listening on ws://127.0.0.1:52179/devtools/browser/16d9c82e-9f0a-4921-a629-00aa4346f58b\n",
      "[5667:259:0830/143958.916229:ERROR:delegated_frame_host.cc(173)] Not implemented reached in void content::DelegatedFrameHost::SetNeedsBeginFrames(bool)\n",
      "FALLBACK (log once): Fallback to SW vertex processing because buildPipelineState failed\n",
      "FALLBACK (log once): Fallback to SW fragment processing because buildPipelineState failed\n",
      "UNSUPPORTED (log once): UNEXPECTED/FATAL?: buildPipelineState failed to build fragment-fallback PSO, m_disable_code: 1001000\n",
      "FALLBACK (log once): Fallback to SW vertex processing, m_disable_code: 1000\n",
      "FALLBACK (log once): Fallback to SW fragment processing, m_disable_code: 1000000\n",
      "2023-08-30 14:39:59.145 Chromium Helper[5672:285065] failed assertion clearFunction != 0 at line 1608 in getClearShaderFragmentFunction\n",
      "Received signal 6\n",
      " [0x000117ac817c]\n",
      " [0x000117ac8071]\n",
      " [0x7ff815f3c5ed]\n",
      " [0x0000c2000000]\n",
      " [0x7ff815e35b45]\n",
      " [0x7ff81fba794c]\n",
      " [0x00011107081c]\n",
      " [0x00011109a38b]\n",
      " [0x7ffa2dea8e39]\n",
      " [0x000118dd9f9c]\n",
      " [0x000118dd9831]\n",
      " [0x000118e5fa4c]\n",
      " [0x000118e5f5c9]\n",
      " [0x000118dd4556]\n",
      " [0x000118dd5edd]\n",
      " [0x000118da4fa3]\n",
      " [0x000118dc8a18]\n",
      " [0x000118d61cc8]\n",
      " [0x000118efb53f]\n",
      " [0x000118efb369]\n",
      " [0x000118efa0ba]\n",
      " [0x000118f046fd]\n",
      " [0x000118f029b8]\n",
      " [0x000118d668cb]\n",
      " [0x000117a165c2]\n",
      " [0x000117a336be]\n",
      " [0x000117a33a23]\n",
      " [0x000117a35f0a]\n",
      " [0x000117a277da]\n",
      " [0x000117a3586f]\n",
      " [0x7ff815fea906]\n",
      " [0x7ff815fea8a9]\n",
      " [0x7ff815fea686]\n",
      " [0x7ff815fe930a]\n",
      " [0x7ff815fe891c]\n",
      " [0x7ff816dd42c3]\n",
      " [0x000117a3656d]\n",
      " [0x000117a3537e]\n",
      " [0x000117a58c95]\n",
      " [0x00011bc2d427]\n",
      " [0x0001175da481]\n",
      " [0x0001191f2d31]\n",
      " [0x0001175d97e4]\n",
      " [0x000115606b03]\n",
      " [0x00010496eab1]\n",
      " [0x000204aba41f]\n",
      "[end of stack trace]\n",
      "[0830/143959.161834:ERROR:process_reader_mac.cc(289)] thread_get_state(4): (os/kern) invalid argument (4)\n",
      "[0830/143959.161975:ERROR:process_reader_mac.cc(289)] thread_get_state(4): (os/kern) invalid argument (4)\n",
      "[0830/143959.161983:ERROR:process_reader_mac.cc(289)] thread_get_state(4): (os/kern) invalid argument (4)\n",
      "[0830/143959.161989:ERROR:process_reader_mac.cc(289)] thread_get_state(4): (os/kern) invalid argument (4)\n",
      "[0830/143959.161993:ERROR:process_reader_mac.cc(289)] thread_get_state(4): (os/kern) invalid argument (4)\n",
      "[0830/143959.161997:ERROR:process_reader_mac.cc(289)] thread_get_state(4): (os/kern) invalid argument (4)\n",
      "[0830/143959.162002:ERROR:process_reader_mac.cc(289)] thread_get_state(4): (os/kern) invalid argument (4)\n",
      "[0830/143959.162007:ERROR:process_reader_mac.cc(289)] thread_get_state(4): (os/kern) invalid argument (4)\n",
      "[0830/143959.162012:ERROR:process_reader_mac.cc(289)] thread_get_state(4): (os/kern) invalid argument (4)\n",
      "[0830/143959.162017:ERROR:process_reader_mac.cc(289)] thread_get_state(4): (os/kern) invalid argument (4)\n",
      "[0830/143959.162021:ERROR:process_reader_mac.cc(289)] thread_get_state(4): (os/kern) invalid argument (4)\n",
      "[0830/143959.162025:ERROR:process_reader_mac.cc(289)] thread_get_state(4): (os/kern) invalid argument (4)\n",
      "[0830/143959.162029:ERROR:process_reader_mac.cc(289)] thread_get_state(4): (os/kern) invalid argument (4)\n",
      "[0830/143959.162033:ERROR:process_reader_mac.cc(289)] thread_get_state(4): (os/kern) invalid argument (4)\n",
      "[0830/143959.162037:ERROR:process_reader_mac.cc(289)] thread_get_state(4): (os/kern) invalid argument (4)\n",
      "[0830/143959.162041:ERROR:process_reader_mac.cc(289)] thread_get_state(4): (os/kern) invalid argument (4)\n",
      "[0830/143959.162566:WARNING:process_reader_mac.cc(495)] multiple MH_EXECUTE modules (/usr/libexec/rosetta/runtime, /Library/Apple/usr/libexec/oah/libRosettaRuntime)\n",
      "[0830/143959.162767:WARNING:process_reader_mac.cc(495)] multiple MH_EXECUTE modules (/usr/libexec/rosetta/runtime, /Users/czc/Library/Application Support/pyppeteer/local-chromium/588429/chrome-mac/Chromium.app/Contents/Versions/71.0.3542.0/Chromium Helper.app/Contents/MacOS/Chromium Helper)\n",
      "[0830/143959.255050:ERROR:exception_snapshot_mac.cc(139)] exception_thread not found in task\n",
      "Received signal 11 SEGV_MAPERR 000000000000\n",
      " [0x000117c0717c]\n",
      " [0x000117c07071]\n",
      " [0x7ff815f3c5ed]\n",
      " [0x000000000000]\n",
      " [0x7ff8223d5274]\n",
      " [0x000117b96317]\n",
      " [0x000117b95b3c]\n",
      " [0x000117b9708f]\n",
      " [0x000117b555c2]\n",
      " [0x000117b726be]\n",
      " [0x000117b72b81]\n",
      " [0x000117b741fc]\n",
      " [0x000117b97c95]\n",
      " [0x000117bdc691]\n",
      " [0x000117c104c7]\n",
      " [0x7ff815f0f1d3]\n",
      " [0x7ff815f0abd3]\n",
      "[end of stack trace]\n"
     ]
    },
    {
     "ename": "BrowserError",
     "evalue": "Browser closed unexpectedly:\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mBrowserError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m allHealthCenterNews\u001B[38;5;241m=\u001B[39mpd\u001B[38;5;241m.\u001B[39mDataFrame()\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m urlList:\n\u001B[0;32m----> 3\u001B[0m     contentAndTime\u001B[38;5;241m=\u001B[39m\u001B[43masyncio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnewsToolForHealthCenter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetPageContent\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m     theNewsInstance\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTitle\u001B[39m\u001B[38;5;124m\"\u001B[39m:[item[\u001B[38;5;241m0\u001B[39m]],\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLink\u001B[39m\u001B[38;5;124m\"\u001B[39m:[item[\u001B[38;5;241m1\u001B[39m]],\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mContent\u001B[39m\u001B[38;5;124m\"\u001B[39m:[contentAndTime[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mContent\u001B[39m\u001B[38;5;124m'\u001B[39m]],\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPublic_Time\u001B[39m\u001B[38;5;124m\"\u001B[39m:[contentAndTime[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPublic_Date\u001B[39m\u001B[38;5;124m'\u001B[39m]],\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSource\u001B[39m\u001B[38;5;124m\"\u001B[39m:[contentAndTime[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSource\u001B[39m\u001B[38;5;124m'\u001B[39m]]}\n\u001B[1;32m      5\u001B[0m     theNewsDf\u001B[38;5;241m=\u001B[39mpd\u001B[38;5;241m.\u001B[39mDataFrame\u001B[38;5;241m.\u001B[39mfrom_dict(theNewsInstance)\n",
      "File \u001B[0;32m~/anaconda3/envs/DataAnalysis/lib/python3.9/site-packages/nest_asyncio.py:35\u001B[0m, in \u001B[0;36m_patch_asyncio.<locals>.run\u001B[0;34m(main, debug)\u001B[0m\n\u001B[1;32m     33\u001B[0m task \u001B[38;5;241m=\u001B[39m asyncio\u001B[38;5;241m.\u001B[39mensure_future(main)\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 35\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mloop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_until_complete\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m task\u001B[38;5;241m.\u001B[39mdone():\n",
      "File \u001B[0;32m~/anaconda3/envs/DataAnalysis/lib/python3.9/site-packages/nest_asyncio.py:90\u001B[0m, in \u001B[0;36m_patch_loop.<locals>.run_until_complete\u001B[0;34m(self, future)\u001B[0m\n\u001B[1;32m     87\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m f\u001B[38;5;241m.\u001B[39mdone():\n\u001B[1;32m     88\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m     89\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEvent loop stopped before Future completed.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 90\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/DataAnalysis/lib/python3.9/asyncio/futures.py:201\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__log_traceback \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    200\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 201\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[1;32m    202\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\n",
      "File \u001B[0;32m~/anaconda3/envs/DataAnalysis/lib/python3.9/asyncio/tasks.py:256\u001B[0m, in \u001B[0;36mTask.__step\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    253\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m exc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    254\u001B[0m         \u001B[38;5;66;03m# We use the `send` method directly, because coroutines\u001B[39;00m\n\u001B[1;32m    255\u001B[0m         \u001B[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001B[39;00m\n\u001B[0;32m--> 256\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43mcoro\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    257\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    258\u001B[0m         result \u001B[38;5;241m=\u001B[39m coro\u001B[38;5;241m.\u001B[39mthrow(exc)\n",
      "Cell \u001B[0;32mIn[6], line 33\u001B[0m, in \u001B[0;36mnewsToolForHealthCenter.getPageContent\u001B[0;34m(url)\u001B[0m\n\u001B[1;32m     31\u001B[0m sourceRe\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m来源:.?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;66;03m# 获取新闻的详细信息\u001B[39;00m\n\u001B[0;32m---> 33\u001B[0m html\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mawait\u001B[39;00m newsToolForHealthCenter\u001B[38;5;241m.\u001B[39mpyppteer_fetchUrl(url)\n\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m#使用beautifulsoup进行解析\u001B[39;00m\n\u001B[1;32m     35\u001B[0m soup \u001B[38;5;241m=\u001B[39m BeautifulSoup(html,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlxml\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[0;32mIn[6], line 61\u001B[0m, in \u001B[0;36mnewsToolForHealthCenter.pyppteer_fetchUrl\u001B[0;34m(url)\u001B[0m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpyppteer_fetchUrl\u001B[39m(url):\n\u001B[0;32m---> 61\u001B[0m     browser \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m launch({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mheadless\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28;01mFalse\u001B[39;00m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdumpio\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mautoClose\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;28;01mTrue\u001B[39;00m})\n\u001B[1;32m     62\u001B[0m     page \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m browser\u001B[38;5;241m.\u001B[39mnewPage()\n\u001B[1;32m     63\u001B[0m     \u001B[38;5;28;01mawait\u001B[39;00m page\u001B[38;5;241m.\u001B[39mgoto(url)\n",
      "File \u001B[0;32m~/anaconda3/envs/DataAnalysis/lib/python3.9/site-packages/pyppeteer/launcher.py:307\u001B[0m, in \u001B[0;36mlaunch\u001B[0;34m(options, **kwargs)\u001B[0m\n\u001B[1;32m    239\u001B[0m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlaunch\u001B[39m(options: \u001B[38;5;28mdict\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Browser:\n\u001B[1;32m    240\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Start chrome process and return :class:`~pyppeteer.browser.Browser`.\u001B[39;00m\n\u001B[1;32m    241\u001B[0m \u001B[38;5;124;03m    This function is a shortcut to :meth:`Launcher(options, **kwargs).launch`.\u001B[39;00m\n\u001B[1;32m    242\u001B[0m \u001B[38;5;124;03m    Available options are:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;124;03m        option with extreme caution.\u001B[39;00m\n\u001B[1;32m    306\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 307\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m Launcher(options, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\u001B[38;5;241m.\u001B[39mlaunch()\n",
      "File \u001B[0;32m~/anaconda3/envs/DataAnalysis/lib/python3.9/site-packages/pyppeteer/launcher.py:168\u001B[0m, in \u001B[0;36mLauncher.launch\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    165\u001B[0m         signal\u001B[38;5;241m.\u001B[39msignal(signal\u001B[38;5;241m.\u001B[39mSIGHUP, _close_process)\n\u001B[1;32m    167\u001B[0m connectionDelay \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mslowMo\n\u001B[0;32m--> 168\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbrowserWSEndpoint \u001B[38;5;241m=\u001B[39m \u001B[43mget_ws_endpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    169\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBrowser listening on: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbrowserWSEndpoint\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    170\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconnection \u001B[38;5;241m=\u001B[39m Connection(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbrowserWSEndpoint, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_loop, connectionDelay, )\n",
      "File \u001B[0;32m~/anaconda3/envs/DataAnalysis/lib/python3.9/site-packages/pyppeteer/launcher.py:227\u001B[0m, in \u001B[0;36mget_ws_endpoint\u001B[0;34m(url)\u001B[0m\n\u001B[1;32m    225\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m    226\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m>\u001B[39m timeout:\n\u001B[0;32m--> 227\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m BrowserError(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBrowser closed unexpectedly:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    229\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m urlopen(url) \u001B[38;5;28;01mas\u001B[39;00m f:\n",
      "\u001B[0;31mBrowserError\u001B[0m: Browser closed unexpectedly:\n"
     ]
    }
   ],
   "source": [
    "allHealthCenterNews=pd.DataFrame()\n",
    "for item in urlList:\n",
    "    contentAndTime=asyncio.run(newsToolForHealthCenter.getPageContent(url=item[1]))\n",
    "    theNewsInstance={\"Title\":[item[0]],\"Link\":[item[1]],\"Content\":[contentAndTime['Content']],\"Public_Time\":[contentAndTime['Public_Date']],\"Source\":[contentAndTime['Source']]}\n",
    "    theNewsDf=pd.DataFrame.from_dict(theNewsInstance)\n",
    "    allHealthCenterNews=pd.concat([theNewsDf,allHealthCenterNews])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T06:40:29.147146Z",
     "start_time": "2023-08-30T06:39:58.313161Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "allHealthCenterNews"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T06:40:29.148081Z",
     "start_time": "2023-08-30T06:40:29.147295Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "allHealthCenterNews.to_csv(\"stockData/furtherInformation/covid19/CovidNews.csv\",index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T06:40:29.148769Z",
     "start_time": "2023-08-30T06:40:29.148641Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
