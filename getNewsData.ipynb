{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1.0 Get the raw news information\n",
    "* æœ¬ç¯‡ä»£ç ç”¨æ¥è·å–ç›¸å…³å…¬å¸çš„æ–°é—»æ–‡æœ¬\n",
    "* ç”±äºä¿¡æ¯æ¸ é“å¹¿æ³›ï¼Œå°†ä¼šçˆ¬è™«æ•°ä¸ªæ–°é—»ç½‘ç«™: [æ–°æµªæ–°é—»ï¼Œå¾®ä¿¡å…¬ä¼—å·]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 æ–°æµªæ–°é—»è·å–"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, news\n",
      "Load time  0:00:00.151431\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import xlwt as xlwt\n",
    "\n",
    "print(\"Hello, news\")\n",
    "from datetime import datetime\n",
    "now=datetime.now()\n",
    "import numpy as np\n",
    "from pylab import mpl\n",
    "# todo: solve chinese problem for plt\n",
    "mpl.rcParams['font.sans-serif']=['SimHei']\n",
    "mpl.rcParams['axes.unicode_minus']=False\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import json\n",
    "from pyppeteer import launch\n",
    "from bs4 import BeautifulSoup\n",
    "from pyppeteer import launcher\n",
    "launcher.DEFAULT_ARGS.remove(\"--enable-automation\")\n",
    "print(\"Load time \",datetime.now()-now)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T18:47:55.350577Z",
     "start_time": "2023-11-16T18:47:55.181904Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from requests import RequestException\n",
    "\n",
    "\n",
    "class newsToolForSina:\n",
    "    @staticmethod\n",
    "    def get_list(url):\n",
    "\n",
    "        # æ–°é—»é“¾æ¥\n",
    "        res=requests.get(url)\n",
    "        res.encoding='utf-8'\n",
    "\n",
    "        # å®Œæ•´HTML\n",
    "        html=BeautifulSoup(res.text,'html.parser')\n",
    "\n",
    "        # æ–°é—»åˆ—è¡¨\n",
    "        newList=[]\n",
    "\n",
    "        for item in html.find_all('div',['news-item','img-news-item']):\n",
    "            try:\n",
    "                newObj={}\n",
    "                newObj['title']=item.select('h2 a')[0].text\n",
    "                newObj['url']=item.select('h2 a')[0].get('href')\n",
    "                newList.append(newObj)\n",
    "            except:\n",
    "                print('å‡ºç°å¼‚å¸¸')\n",
    "        return newList\n",
    "\n",
    "    @staticmethod\n",
    "    def get_HtmlDetail_Sina(url):\n",
    "\n",
    "        # æ–°é—»é“¾æ¥\n",
    "        res=requests.get(url)\n",
    "        res.encoding='utf-8'\n",
    "\n",
    "        # å®Œæ•´HTML\n",
    "        html=BeautifulSoup(res.text,'html.parser')\n",
    "\n",
    "        # æ–°é—»å¯¹è±¡\n",
    "        result={}\n",
    "\n",
    "        # æ–°é—»æ ‡é¢˜\n",
    "        result['title']=html.select('.main-title')[0].text\n",
    "\n",
    "        # å‘å¸ƒæ—¶é—´\n",
    "        timesource=html.select('.date-source span')[0].text\n",
    "        createtime=datetime.strptime(timesource,'%Yå¹´%mæœˆ%dæ—¥ %H:%M')\n",
    "        createtime.strftime('%Y-%m-%d')\n",
    "        result['createtime']=createtime\n",
    "\n",
    "        # æ–°é—»æ¥æº\n",
    "        result['place']=html.select('.date-source a')[0].text\n",
    "\n",
    "        # æ–°é—»å†…å®¹\n",
    "        article=[]\n",
    "        for p in html.select('#article p')[:-1]:\n",
    "            article.append(p.text.strip())\n",
    "        articleText=' '.join(article)\n",
    "        result['article']=articleText\n",
    "\n",
    "        # æ–°é—»ä½œè€…\n",
    "        result['author']=html.select('.show_author')[0].text.strip('è´£ä»»ç¼–è¾‘ï¼š')\n",
    "\n",
    "        # æ–°é—»é“¾æ¥\n",
    "        result['url']=url\n",
    "\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def get_page_news(browser,urlList):\n",
    "        #è·å–å½“å‰é¡µé¢æ‰€æœ‰åŒ…å«æ–°é—»çš„aæ ‡ç­¾\n",
    "        news = browser.find_elements(\"xpath\",'//div[@class=\"d_list_txt\"]/ul/li/span/a')\n",
    "        if len(news)==0:\n",
    "            return np.nan\n",
    "        for i in news:\n",
    "            link = i.get_attribute('href') #å¾—åˆ°æ–°é—»url\n",
    "            # print(len(urlList),link)\n",
    "            if link not in urlList:  #é€šè¿‡urlå»é‡\n",
    "                urlList.append(link)\n",
    "        return urlList\n",
    "\n",
    "    @staticmethod\n",
    "    def getNewsData(url):\n",
    "        # è·å–æ–°é—»çš„è¯¦ç»†ä¿¡æ¯\n",
    "        html = newsToolForSina.get_response(url)\n",
    "        #ä½¿ç”¨beautifulsoupè¿›è¡Œè§£æ\n",
    "        soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "        #æ ‡é¢˜\n",
    "        '''\n",
    "        <h1 class=\"main-title\">è¯ç›‘ä¼šè¦æ±‚åŒ—äº¬é“¶è¡Œè¯´æ˜æ˜¯å¦ä¸²é€š*STåº·å¾—ç®¡ç†å±‚èˆå¼Š</h1>\n",
    "        '''\n",
    "        title = soup.select('.main-title')\n",
    "        #å¯èƒ½æœ‰å°éƒ¨åˆ†æ ‡é¢˜çš„æ ‡ç­¾ä¸æ˜¯ä¸Šè¿°æ ¼å¼ å¯¹å…¶è¿›è¡Œè¡¥å……\n",
    "        if not title:\n",
    "            title = soup.select('#artibodyTitle')\n",
    "        if title:\n",
    "            title = title[0].text\n",
    "        # print(title)\n",
    "\n",
    "        #æ—¥æœŸ\n",
    "        '''\n",
    "        <span class=\"date\">2019å¹´07æœˆ20æ—¥ 16:52</span>\n",
    "        '''\n",
    "        date = soup.select('.date')\n",
    "        # å¯èƒ½æœ‰å°éƒ¨åˆ†æ—¥æœŸçš„æ ‡ç­¾ä¸æ˜¯ä¸Šè¿°æ ¼å¼ å¯¹å…¶è¿›è¡Œè¡¥å……\n",
    "        if not date:\n",
    "            date = soup.select('#pub_date')\n",
    "        if date:\n",
    "            date = date[0].text\n",
    "        # print(date)\n",
    "\n",
    "        #æ¥æº\n",
    "        '''\n",
    "        <span class=\"source ent-source\">ä¸­å›½è¯åˆ¸æŠ¥</span>\n",
    "        '''\n",
    "        source = soup.select('.source')\n",
    "        # å¯èƒ½æœ‰å°éƒ¨åˆ†æ¥æºçš„æ ‡ç­¾ä¸æ˜¯ä¸Šè¿°æ ¼å¼ å¯¹å…¶è¿›è¡Œè¡¥å……\n",
    "        if not source:\n",
    "            source = soup.select('[data-sudaclick=\"media_name\"]')\n",
    "        if source:\n",
    "            source = source[0].text\n",
    "        # print(source)\n",
    "\n",
    "        #æ­£æ–‡\n",
    "        article = soup.select('div[class=\"article\"] p')\n",
    "        # å¯èƒ½æœ‰å°éƒ¨åˆ†æ­£æ–‡çš„æ ‡ç­¾ä¸æ˜¯ä¸Šè¿°æ ¼å¼ å¯¹å…¶è¿›è¡Œè¡¥å……\n",
    "        if not article:\n",
    "            article = soup.select('div[id=\"artibody\"] p')\n",
    "        if article:\n",
    "            #æŠŠæ­£æ–‡æ”¾åœ¨ä¸€ä¸ªåˆ—è¡¨ä¸­ æ¯ä¸ªpæ ‡ç­¾çš„å†…å®¹ä¸ºåˆ—è¡¨çš„ä¸€é¡¹\n",
    "            article_list = []\n",
    "            for i in article:\n",
    "                # print(i.text)\n",
    "                article_list.append(i.text)\n",
    "        #è½¬ä¸ºå­—å…¸æ ¼å¼\n",
    "        news = {'link': url, 'title': title, 'date': date, 'source': source, 'article': article_list}\n",
    "        return news\n",
    "\n",
    "    @staticmethod\n",
    "    def get_response(url):\n",
    "        try:\n",
    "            #æ·»åŠ User-Agentï¼Œæ”¾åœ¨headersä¸­ï¼Œä¼ªè£…æˆæµè§ˆå™¨\n",
    "            headers = {\n",
    "                'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36'\n",
    "            }\n",
    "            response = requests.get(url,headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                response.encoding = 'utf-8'\n",
    "                return response.text\n",
    "            return None\n",
    "        except RequestException:\n",
    "            return None\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T18:47:55.366014Z",
     "start_time": "2023-11-16T18:47:55.364646Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "###test\n",
    "# newList=newsToolForSina.get_list('https://news.sina.com.cn/world/')\n",
    "# resultList=pd.DataFrame()\n",
    "#\n",
    "# for i,item in enumerate(newList):\n",
    "#     try:\n",
    "#         result=newsToolForSina.get_HtmlDetail_Sina(item['url'])\n",
    "#         newObj=pd.DataFrame(result,index=[0])\n",
    "#         resultList=resultList.append(newObj)\n",
    "#         print (str(i),'å†™å…¥æˆåŠŸ')\n",
    "#     except BaseException as err:\n",
    "#         print (str(i),'å‡ºç°å¼‚å¸¸: ',err)\n",
    "#\n",
    "# resultList.to_csv(\"newsData/test.csv\",header=resultList.columns)\n",
    "# resultList"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T18:47:55.386504Z",
     "start_time": "2023-11-16T18:47:55.367777Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## æ³¨æ„: æ–°æµªæ–°é—»çš„å†å²æ•°æ®åªèƒ½æŸ¥åˆ°è¿‘æœŸä¸€ä¸ªæœˆçš„ï¼Œå¹¶ä¸èƒ½æŸ¥ä¹‹å‰çš„ï¼Œæ‰€ä»¥æ–°æµªçš„å¯ä»¥æ”¾å¼ƒä¸€éƒ¨åˆ†äº†"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# from selenium.common import NoSuchElementException\n",
    "#\n",
    "# #æ‰“å¼€æµè§ˆå™¨\n",
    "# UrlList=[]\n",
    "# browser = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "# browser.implicitly_wait(10)\n",
    "# #æ‰“å¼€ç½‘å€\n",
    "# browser.get('https://news.sina.com.cn/roll/')\n",
    "# #è·å–å½“å‰é¡µé¢æ–°é—»çš„url\n",
    "# UrlList=newsToolForSina.get_page_news(browser,urlList=UrlList)\n",
    "# while True:\n",
    "#     try:\n",
    "#         #æ‰¾åˆ°ä¸‹ä¸€é¡µæŒ‰é’® å¹¶ç‚¹å‡»\n",
    "#         '''\n",
    "#         <a href=\"javascript:void(0)\" onclick=\"newsList.page.next();return false;\">ä¸‹ä¸€é¡µ</a>\n",
    "#         '''\n",
    "#         browser.find_element(\"xpath\",'//a[@onclick=\"newsList.page.next();return false;\"]').click()\n",
    "#         #è·å–ä¸‹ä¸€é¡µæ–°é—»çš„url\n",
    "#         result=newsToolForSina.get_page_news(browser,urlList=UrlList)\n",
    "#         if result is np.nan:\n",
    "#             break\n",
    "#     except BaseException as err:\n",
    "#         print(err)\n",
    "#         browser.close()\n",
    "#\n",
    "#\n",
    "# print(\"Have found {} URL records, trying to get news text data\".format(len(UrlList)))\n",
    "# resultList=pd.DataFrame()\n",
    "# for i,item in enumerate(UrlList):\n",
    "#     try:\n",
    "#         result=newsToolForSina.getNewsData(item)\n",
    "#         newObj=pd.DataFrame(result)\n",
    "#         resultList=resultList.append(newObj)\n",
    "#         print (str(i),'å†™å…¥æˆåŠŸ')\n",
    "#         # break\n",
    "#     except BaseException as err:\n",
    "#         print (str(i),'å‡ºç°å¼‚å¸¸: ',err)\n",
    "#         # break\n",
    "#\n",
    "#\n",
    "# resultList.to_csv(\"newsData/SinaNewsRawData.csv\",header=resultList.columns)\n",
    "# resultList"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T18:47:55.393965Z",
     "start_time": "2023-11-16T18:47:55.373056Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "       Unnamed: 0                                               link  \\\n0               0  https://finance.sina.com.cn/roll/2023-05-12/do...   \n1               1  https://finance.sina.com.cn/roll/2023-05-12/do...   \n2               2  https://finance.sina.com.cn/roll/2023-05-12/do...   \n3               3  https://finance.sina.com.cn/roll/2023-05-12/do...   \n4               4  https://finance.sina.com.cn/roll/2023-05-12/do...   \n...           ...                                                ...   \n47350           2  https://finance.sina.com.cn/tob/2023-05-10/doc...   \n47351           0  https://finance.sina.com.cn/tob/2023-05-10/doc...   \n47352           1  https://finance.sina.com.cn/tob/2023-05-10/doc...   \n47353           0  https://finance.sina.com.cn/tob/2023-05-10/doc...   \n47354           1  https://finance.sina.com.cn/tob/2023-05-10/doc...   \n\n                                 title               date source  \\\n0                 4æœˆå±…æ°‘å­˜æ¬¾é”å‡ä¹‹è°œï¼Œ1.2ä¸‡äº¿å»å“ªäº†ï¼Ÿ  2023å¹´05æœˆ12æ—¥ 16:48   ç¬¬ä¸€è´¢ç»   \n1                 4æœˆå±…æ°‘å­˜æ¬¾é”å‡ä¹‹è°œï¼Œ1.2ä¸‡äº¿å»å“ªäº†ï¼Ÿ  2023å¹´05æœˆ12æ—¥ 16:48   ç¬¬ä¸€è´¢ç»   \n2                 4æœˆå±…æ°‘å­˜æ¬¾é”å‡ä¹‹è°œï¼Œ1.2ä¸‡äº¿å»å“ªäº†ï¼Ÿ  2023å¹´05æœˆ12æ—¥ 16:48   ç¬¬ä¸€è´¢ç»   \n3                 4æœˆå±…æ°‘å­˜æ¬¾é”å‡ä¹‹è°œï¼Œ1.2ä¸‡äº¿å»å“ªäº†ï¼Ÿ  2023å¹´05æœˆ12æ—¥ 16:48   ç¬¬ä¸€è´¢ç»   \n4                 4æœˆå±…æ°‘å­˜æ¬¾é”å‡ä¹‹è°œï¼Œ1.2ä¸‡äº¿å»å“ªäº†ï¼Ÿ  2023å¹´05æœˆ12æ—¥ 16:48   ç¬¬ä¸€è´¢ç»   \n...                                ...                ...    ...   \n47350      è’™ç‰›ä¹³ä¸š5æœˆ9æ—¥æ–¥èµ„çº¦1826.08ä¸‡æ¸¯å…ƒå›è´­55ä¸‡è‚¡  2023å¹´05æœˆ10æ—¥ 08:59   æ–°æµªæ¸¯è‚¡   \n47351   å¤ªå¤è‚¡ä»½å…¬å¸A5æœˆ9æ—¥æ–¥èµ„272.95ä¸‡æ¸¯å…ƒå›è´­4.55ä¸‡è‚¡  2023å¹´05æœˆ10æ—¥ 08:58   æ–°æµªæ¸¯è‚¡   \n47352   å¤ªå¤è‚¡ä»½å…¬å¸A5æœˆ9æ—¥æ–¥èµ„272.95ä¸‡æ¸¯å…ƒå›è´­4.55ä¸‡è‚¡  2023å¹´05æœˆ10æ—¥ 08:58   æ–°æµªæ¸¯è‚¡   \n47353  å¤ªå¤è‚¡ä»½å…¬å¸B5æœˆ9æ—¥è€—èµ„çº¦550.67ä¸‡æ¸¯å…ƒå›è´­55.5ä¸‡è‚¡  2023å¹´05æœˆ10æ—¥ 08:58   æ–°æµªæ¸¯è‚¡   \n47354  å¤ªå¤è‚¡ä»½å…¬å¸B5æœˆ9æ—¥è€—èµ„çº¦550.67ä¸‡æ¸¯å…ƒå›è´­55.5ä¸‡è‚¡  2023å¹´05æœˆ10æ—¥ 08:58   æ–°æµªæ¸¯è‚¡   \n\n                                                 article  \n0                 ã€€ã€€ç‚’è‚¡å°±çœ‹é‡‘éº’éºŸåˆ†æå¸ˆç ”æŠ¥ï¼Œæƒå¨ï¼Œä¸“ä¸šï¼ŒåŠæ—¶ï¼Œå…¨é¢ï¼ŒåŠ©æ‚¨æŒ–æ˜æ½œåŠ›ä¸»é¢˜æœºä¼šï¼  \n1      ã€€ã€€ä½†è¿™åœ¨æ•°æ®ä¸Šå¹¶æœªå¾—åˆ°å°è¯ã€‚å›½å®¶ç»Ÿè®¡å±€å…¬å¸ƒçš„æ•°æ®æ˜¾ç¤ºï¼Œ4æœˆä»½ï¼Œå…¨å›½CPIåŒæ¯”ä¸Šæ¶¨0.1%ï¼›...  \n2                                 ã€€ã€€4æœˆå±…æ°‘å­˜æ¬¾å¤§å¹…å‡å°‘å¼•èµ·å¸‚åœºçš„å¹¿æ³›çƒ­è®®ã€‚  \n3      ã€€ã€€å¤®è¡Œæœ€æ–°å…¬å¸ƒçš„4æœˆé‡‘èæ•°æ®æ˜¾ç¤ºï¼Œ4æœˆäººæ°‘å¸å­˜æ¬¾å‡å°‘4609äº¿å…ƒï¼ŒåŒæ¯”å¤šå‡5524äº¿å…ƒï¼Œå…¶...  \n4      ã€€ã€€ä¸å°‘åˆ†æè®¤ä¸ºï¼Œ4æœˆå±…æ°‘å­˜æ¬¾å‡å°‘æˆ–æºè‡ªâ€œæå‰è¿˜è´·â€å’Œæ¶ˆè´¹å›å‡æ‰€è‡´ï¼›å¦å¤–çš„è§‚ç‚¹åˆ™è®¤ä¸ºï¼Œ4æœˆä»½...  \n...                                                  ...  \n47350                                          è´£ä»»ç¼–è¾‘ï¼šå¢æ˜±å›   \n47351  ã€€ã€€å¤ªå¤è‚¡ä»½å…¬å¸Aï¼ˆ00019ï¼‰å‘å¸ƒå…¬å‘Šï¼Œäº2023å¹´5æœˆ9æ—¥æ–¥èµ„272.95ä¸‡æ¸¯å…ƒå›è´­4....  \n47352                                          è´£ä»»ç¼–è¾‘ï¼šå¢æ˜±å›   \n47353  ã€€ã€€å¤ªå¤è‚¡ä»½å…¬å¸Bï¼ˆ00087ï¼‰å…¬å¸ƒï¼Œ2023å¹´5æœˆ9æ—¥è€—èµ„çº¦550.67ä¸‡æ¸¯å…ƒå›è´­55.5...  \n47354                                          è´£ä»»ç¼–è¾‘ï¼šå¢æ˜±å›   \n\n[47355 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>link</th>\n      <th>title</th>\n      <th>date</th>\n      <th>source</th>\n      <th>article</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>https://finance.sina.com.cn/roll/2023-05-12/do...</td>\n      <td>4æœˆå±…æ°‘å­˜æ¬¾é”å‡ä¹‹è°œï¼Œ1.2ä¸‡äº¿å»å“ªäº†ï¼Ÿ</td>\n      <td>2023å¹´05æœˆ12æ—¥ 16:48</td>\n      <td>ç¬¬ä¸€è´¢ç»</td>\n      <td>ç‚’è‚¡å°±çœ‹é‡‘éº’éºŸåˆ†æå¸ˆç ”æŠ¥ï¼Œæƒå¨ï¼Œä¸“ä¸šï¼ŒåŠæ—¶ï¼Œå…¨é¢ï¼ŒåŠ©æ‚¨æŒ–æ˜æ½œåŠ›ä¸»é¢˜æœºä¼šï¼</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>https://finance.sina.com.cn/roll/2023-05-12/do...</td>\n      <td>4æœˆå±…æ°‘å­˜æ¬¾é”å‡ä¹‹è°œï¼Œ1.2ä¸‡äº¿å»å“ªäº†ï¼Ÿ</td>\n      <td>2023å¹´05æœˆ12æ—¥ 16:48</td>\n      <td>ç¬¬ä¸€è´¢ç»</td>\n      <td>ä½†è¿™åœ¨æ•°æ®ä¸Šå¹¶æœªå¾—åˆ°å°è¯ã€‚å›½å®¶ç»Ÿè®¡å±€å…¬å¸ƒçš„æ•°æ®æ˜¾ç¤ºï¼Œ4æœˆä»½ï¼Œå…¨å›½CPIåŒæ¯”ä¸Šæ¶¨0.1%ï¼›...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>https://finance.sina.com.cn/roll/2023-05-12/do...</td>\n      <td>4æœˆå±…æ°‘å­˜æ¬¾é”å‡ä¹‹è°œï¼Œ1.2ä¸‡äº¿å»å“ªäº†ï¼Ÿ</td>\n      <td>2023å¹´05æœˆ12æ—¥ 16:48</td>\n      <td>ç¬¬ä¸€è´¢ç»</td>\n      <td>4æœˆå±…æ°‘å­˜æ¬¾å¤§å¹…å‡å°‘å¼•èµ·å¸‚åœºçš„å¹¿æ³›çƒ­è®®ã€‚</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>https://finance.sina.com.cn/roll/2023-05-12/do...</td>\n      <td>4æœˆå±…æ°‘å­˜æ¬¾é”å‡ä¹‹è°œï¼Œ1.2ä¸‡äº¿å»å“ªäº†ï¼Ÿ</td>\n      <td>2023å¹´05æœˆ12æ—¥ 16:48</td>\n      <td>ç¬¬ä¸€è´¢ç»</td>\n      <td>å¤®è¡Œæœ€æ–°å…¬å¸ƒçš„4æœˆé‡‘èæ•°æ®æ˜¾ç¤ºï¼Œ4æœˆäººæ°‘å¸å­˜æ¬¾å‡å°‘4609äº¿å…ƒï¼ŒåŒæ¯”å¤šå‡5524äº¿å…ƒï¼Œå…¶...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>https://finance.sina.com.cn/roll/2023-05-12/do...</td>\n      <td>4æœˆå±…æ°‘å­˜æ¬¾é”å‡ä¹‹è°œï¼Œ1.2ä¸‡äº¿å»å“ªäº†ï¼Ÿ</td>\n      <td>2023å¹´05æœˆ12æ—¥ 16:48</td>\n      <td>ç¬¬ä¸€è´¢ç»</td>\n      <td>ä¸å°‘åˆ†æè®¤ä¸ºï¼Œ4æœˆå±…æ°‘å­˜æ¬¾å‡å°‘æˆ–æºè‡ªâ€œæå‰è¿˜è´·â€å’Œæ¶ˆè´¹å›å‡æ‰€è‡´ï¼›å¦å¤–çš„è§‚ç‚¹åˆ™è®¤ä¸ºï¼Œ4æœˆä»½...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>47350</th>\n      <td>2</td>\n      <td>https://finance.sina.com.cn/tob/2023-05-10/doc...</td>\n      <td>è’™ç‰›ä¹³ä¸š5æœˆ9æ—¥æ–¥èµ„çº¦1826.08ä¸‡æ¸¯å…ƒå›è´­55ä¸‡è‚¡</td>\n      <td>2023å¹´05æœˆ10æ—¥ 08:59</td>\n      <td>æ–°æµªæ¸¯è‚¡</td>\n      <td>è´£ä»»ç¼–è¾‘ï¼šå¢æ˜±å›</td>\n    </tr>\n    <tr>\n      <th>47351</th>\n      <td>0</td>\n      <td>https://finance.sina.com.cn/tob/2023-05-10/doc...</td>\n      <td>å¤ªå¤è‚¡ä»½å…¬å¸A5æœˆ9æ—¥æ–¥èµ„272.95ä¸‡æ¸¯å…ƒå›è´­4.55ä¸‡è‚¡</td>\n      <td>2023å¹´05æœˆ10æ—¥ 08:58</td>\n      <td>æ–°æµªæ¸¯è‚¡</td>\n      <td>å¤ªå¤è‚¡ä»½å…¬å¸Aï¼ˆ00019ï¼‰å‘å¸ƒå…¬å‘Šï¼Œäº2023å¹´5æœˆ9æ—¥æ–¥èµ„272.95ä¸‡æ¸¯å…ƒå›è´­4....</td>\n    </tr>\n    <tr>\n      <th>47352</th>\n      <td>1</td>\n      <td>https://finance.sina.com.cn/tob/2023-05-10/doc...</td>\n      <td>å¤ªå¤è‚¡ä»½å…¬å¸A5æœˆ9æ—¥æ–¥èµ„272.95ä¸‡æ¸¯å…ƒå›è´­4.55ä¸‡è‚¡</td>\n      <td>2023å¹´05æœˆ10æ—¥ 08:58</td>\n      <td>æ–°æµªæ¸¯è‚¡</td>\n      <td>è´£ä»»ç¼–è¾‘ï¼šå¢æ˜±å›</td>\n    </tr>\n    <tr>\n      <th>47353</th>\n      <td>0</td>\n      <td>https://finance.sina.com.cn/tob/2023-05-10/doc...</td>\n      <td>å¤ªå¤è‚¡ä»½å…¬å¸B5æœˆ9æ—¥è€—èµ„çº¦550.67ä¸‡æ¸¯å…ƒå›è´­55.5ä¸‡è‚¡</td>\n      <td>2023å¹´05æœˆ10æ—¥ 08:58</td>\n      <td>æ–°æµªæ¸¯è‚¡</td>\n      <td>å¤ªå¤è‚¡ä»½å…¬å¸Bï¼ˆ00087ï¼‰å…¬å¸ƒï¼Œ2023å¹´5æœˆ9æ—¥è€—èµ„çº¦550.67ä¸‡æ¸¯å…ƒå›è´­55.5...</td>\n    </tr>\n    <tr>\n      <th>47354</th>\n      <td>1</td>\n      <td>https://finance.sina.com.cn/tob/2023-05-10/doc...</td>\n      <td>å¤ªå¤è‚¡ä»½å…¬å¸B5æœˆ9æ—¥è€—èµ„çº¦550.67ä¸‡æ¸¯å…ƒå›è´­55.5ä¸‡è‚¡</td>\n      <td>2023å¹´05æœˆ10æ—¥ 08:58</td>\n      <td>æ–°æµªæ¸¯è‚¡</td>\n      <td>è´£ä»»ç¼–è¾‘ï¼šå¢æ˜±å›</td>\n    </tr>\n  </tbody>\n</table>\n<p>47355 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultList=pd.read_csv(\"newsData/SinaNewsRawData.csv\")\n",
    "resultList"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T18:47:55.648236Z",
     "start_time": "2023-11-16T18:47:55.376155Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T18:47:55.650987Z",
     "start_time": "2023-11-16T18:47:55.647947Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 æ–°é—»è”æ’­æ–‡æœ¬ç¨¿"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T18:47:55.653102Z",
     "start_time": "2023-11-16T18:47:55.650412Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 å¾®åšåŸºäºå…³é”®å­—å†…å®¹çˆ¬å– (ä¸»è¦å†…å®¹: æ–‡ç« æ–‡æœ¬ï¼Œè§‚çœ‹äººæ•°ï¼Œè¯„è®ºï¼Œç‚¹èµ)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 89\u001B[0m\n\u001B[1;32m     87\u001B[0m data\u001B[38;5;241m=\u001B[39mget_page(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     88\u001B[0m result\u001B[38;5;241m=\u001B[39mparse_json(data)\n\u001B[0;32m---> 89\u001B[0m \u001B[38;5;28;43mprint\u001B[39;49m(result)\n",
      "Cell \u001B[0;32mIn[7], line 89\u001B[0m\n\u001B[1;32m     87\u001B[0m data\u001B[38;5;241m=\u001B[39mget_page(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     88\u001B[0m result\u001B[38;5;241m=\u001B[39mparse_json(data)\n\u001B[0;32m---> 89\u001B[0m \u001B[38;5;28;43mprint\u001B[39;49m(result)\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:1095\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_39_64.pyx:1053\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_39_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py:169\u001B[0m, in \u001B[0;36mstop\u001B[0;34m(plugin, pydb, frame, event, args, stop_info, arg, step_cmd)\u001B[0m\n\u001B[1;32m    167\u001B[0m     frame \u001B[38;5;241m=\u001B[39m suspend_jupyter(main_debugger, thread, frame, step_cmd)\n\u001B[1;32m    168\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m frame:\n\u001B[0;32m--> 169\u001B[0m         \u001B[43mmain_debugger\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    170\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T18:49:22.324578Z",
     "start_time": "2023-11-16T18:48:00.091215Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4 å¾®ä¿¡å…¬ä¼—å·åŸºäºå…³é”®å­—çˆ¬å– (ä¸»è¦å†…å®¹: æ–‡ç« æ–‡æœ¬ï¼Œè¯„è®ºï¼Œç‚¹èµï¼Œæ”¶è—)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.5 å«ç”ŸåŠ æ–°å† ç—…æ¯’ äººæ•°ç»Ÿè®¡(æ—¥)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "class newsToolForHealthCenter:\n",
    "    @staticmethod\n",
    "    def get_page_news(keywords:[],browser,urlList:{},endTime:str):\n",
    "        \n",
    "        news = browser.find_elements(\"xpath\",'/html/body/div[2]/div/div[1]//*[@class=\"wordGuide Residence-permit\"]//*[@class=\"bigTit clearfix\"]/a')\n",
    "        similarArticles=browser.find_elements(\"xpath\",'/html/body/div[2]/div/div[1]//*[@class=\"wordGuide Residence-permit\"]//*[@class=\"listInfoCon clearfix \"]//*[@class=\"listIntro wh100 fl\"]//*[@class=\"similarArticles\"]//*[@class=\"similarArticlesList\"]/ul//*[@class=\"clearfix\"]/a')\n",
    "        if len(news)==0:\n",
    "            return np.nan\n",
    "        print(\"--------------new page--------------\")\n",
    "        if len(similarArticles)>0:\n",
    "            for article in similarArticles:\n",
    "                # print(\"-----------  ------------\")\n",
    "                # print(article.get_attribute(\"text\"))\n",
    "                # print(article.get_attribute(\"href\"))\n",
    "                similartitle=article.get_attribute(\"text\").strip()\n",
    "                similarlink=article.get_attribute(\"href\").strip()\n",
    "                for keyword in keywords:\n",
    "                    if re.match(pattern=keyword,string=similartitle):\n",
    "                        print(\"Found similar article: \",similartitle)\n",
    "                        if similarlink not in urlList.keys():\n",
    "                            urlList[similarlink]=similartitle\n",
    "        for i in news:\n",
    "            title=i.get_attribute(\"title\").strip()\n",
    "            link = i.get_attribute('href').strip() #å¾—åˆ°æ–°é—»url\n",
    "            for keyword in keywords:\n",
    "                if re.match(pattern=keyword,string=title):\n",
    "                    print(\"Found: \",title)\n",
    "                    if link not in urlList.keys():\n",
    "                        urlList[link]=title\n",
    "        return urlList\n",
    "    \n",
    "    @staticmethod\n",
    "    async def getPageContent(url:str):\n",
    "        publicDate=\"\"\n",
    "        source=\"\"\n",
    "        content=\"\"\n",
    "        dateRe=\"å‘å¸ƒæ—¶é—´ï¼š.?\"\n",
    "        sourceRe=\"æ¥æº:.?\"\n",
    "        # è·å–æ–°é—»çš„è¯¦ç»†ä¿¡æ¯\n",
    "        html=await newsToolForHealthCenter.pyppteer_fetchUrl(url)\n",
    "        if html is None:\n",
    "            print(url,\"  is nome type\")\n",
    "            return {\"Public_Date\":np.nan,\"Source\":np.nan,\"Content\":np.nan}\n",
    "        \n",
    "        elif len(html)<=0:\n",
    "            return {\"Public_Date\":np.nan,\"Source\":np.nan,\"Content\":np.nan}\n",
    "        #ä½¿ç”¨beautifulsoupè¿›è¡Œè§£æ\n",
    "        soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "        #æ—¥æœŸ\n",
    "        '''\n",
    "        <source>\n",
    "            <span>å‘å¸ƒæ—¶é—´ï¼š2022-09-02</span>\n",
    "        '''\n",
    "        origin = soup.find_all('span')\n",
    "        # å¯èƒ½æœ‰å°éƒ¨åˆ†æ—¥æœŸçš„æ ‡ç­¾ä¸æ˜¯ä¸Šè¿°æ ¼å¼ å¯¹å…¶è¿›è¡Œè¡¥å……\n",
    "        for ele in origin:\n",
    "            if re.match(string=ele.text.strip(),pattern=dateRe):\n",
    "                # print(ele.text)\n",
    "                publicDate=ele.text.replace(\"å‘å¸ƒæ—¶é—´ï¼š\",\"\").strip()\n",
    "            if re.match(string=ele.text.strip(),pattern=sourceRe):\n",
    "                # print(ele.text)\n",
    "                source=ele.text.replace(\"æ¥æº:\",\"\").strip()\n",
    "                \n",
    "        article=\"\"\n",
    "        try: \n",
    "            #æ­£æ–‡\n",
    "            article = soup.find(id=\"xw_box\").text.strip()\n",
    "            # print(\"---------------\")\n",
    "            # print(article)\n",
    "            content=article\n",
    "        except BaseException as err:\n",
    "            return {\"Public_Date\":np.nan,\"Source\":np.nan,\"Content\":np.nan}\n",
    "        \n",
    "        return {\"Public_Date\":publicDate,\"Source\":source,\"Content\":content}\n",
    "\n",
    "    @staticmethod\n",
    "    async def pyppteer_fetchUrl(url):\n",
    "        browser = await launch({'headless': False,'dumpio':True, 'autoClose':True})\n",
    "        page = await browser.newPage()\n",
    "        await page.goto(url)\n",
    "        await page.waitFor(100)\n",
    "        await asyncio.wait([page.waitForNavigation(timeout=500000)])\n",
    "        str = await page.content()\n",
    "        await browser.close()\n",
    "        return str\n",
    "    \n",
    "    # @staticmethod\n",
    "    # async def fetchUrl(url):\n",
    "    #     return await newsToolForHealthCenter.pyppteer_fetchUrl(url)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import asyncio\n",
    "# import nest_asyncio\n",
    "# \n",
    "# # ğŸ‘‡ï¸ call apply()\n",
    "# nest_asyncio.apply()\n",
    "# url = 'http://www.nhc.gov.cn/yjb/s7860/202209/e0a18445e0ab47608527b9c910f77699.shtml'\n",
    "# \n",
    "# async def fetchUrl(url):\n",
    "#     browser = await launch({'headless': False,'dumpio':True, 'autoClose':True})\n",
    "#     page = await browser.newPage()\n",
    "# \n",
    "#     await page.goto(url)\n",
    "#     await asyncio.wait([page.waitForNavigation()])\n",
    "#     str = await page.content()\n",
    "#     await browser.close()\n",
    "#     print(\"-------------------\")\n",
    "#     print(str)\n",
    "# \n",
    "# asyncio.get_event_loop().run_until_complete(fetchUrl(url))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support import wait\n",
    "from selenium.common import NoSuchElementException\n",
    "# \n",
    "#æ‰“å¼€æµè§ˆå™¨\n",
    "browser = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "options = Options()\n",
    "browser = webdriver.Chrome(service=Service(ChromeDriverManager( latest_release_url='https://googlechromelabs.github.io/chrome-for-testing/last-known-good-versions-with-downloads.json', driver_version='116.0.5845.96').install()), options=options)\n",
    "\n",
    "browser.implicitly_wait(100)\n",
    "# #æ‰“å¼€ç½‘å€\n",
    "# # browser.get('http://zs.kaipuyun.cn/s?searchWord=%25E6%2596%25B0%25E5%259E%258B%25E5%2586%25A0%25E7%258A%25B6%25E7%2597%2585%25E6%25AF%2592%25E8%2582%25BA%25E7%2582%258E&column=%25E6%259C%25AC%25E7%25AB%2599&pageSize=10&pageNum=0&siteCode=N000001642&sonSiteCode=&checkHandle=1&searchSource=0&areaSearchFlag=0&secondSearchWords=&topical=&docName=&label=&countKey=0&uc=0&left_right_index=0&searchBoxSettingsIndex=&isSecondSearch=undefined&manualWord=%25E6%2596%25B0%25E5%259E%258B%25E5%2586%25A0%25E7%258A%25B6%25E7%2597%2585%25E6%25AF%2592%25E8%2582%25BA%25E7%2582%258E&orderBy=0&startTime=&endTime=&timeStamp=0&strFileType=&wordPlace=0')\n",
    "# \n",
    "# browser.get('http://zs.kaipuyun.cn/s?searchWord=%25E6%2596%25B0%25E5%259E%258B%25E5%2586%25A0%25E7%258A%25B6%25E7%2597%2585%25E6%25AF%2592%25E8%2582%25BA%25E7%2582%258E%25E7%2596%25AB%25E6%2583%2585%25E6%259C%2580%25E6%2596%25B0%25E6%2583%2585%25E5%2586%25B5&column=%25E6%259C%25AC%25E7%25AB%2599&pageSize=10&pageNum=0&siteCode=N000001642&sonSiteCode=&checkHandle=1&searchSource=1&areaSearchFlag=0&secondSearchWords=&topical=&docName=&label=&countKey=0&uc=0&left_right_index=0&searchBoxSettingsIndex=&isSecondSearch=undefined&manualWord=%25E6%2596%25B0%25E5%259E%258B%25E5%2586%25A0%25E7%258A%25B6%25E7%2597%2585%25E6%25AF%2592%25E8%2582%25BA%25E7%2582%258E%25E7%2596%25AB%25E6%2583%2585%25E6%259C%2580%25E6%2596%25B0%25E6%2583%2585%25E5%2586%25B5&orderBy=0&startTime=&endTime=&timeStamp=0&strFileType=&wordPlace=0')\n",
    "# \n",
    "# #è·å–å½“å‰é¡µé¢æ–°é—»çš„url\n",
    "# keywords=[\"æˆªè‡³.*æ–°å‹å† çŠ¶ç—…æ¯’è‚ºç‚ç–«æƒ…æœ€æ–°æƒ…å†µ\",'.*æ–°å‹å† çŠ¶ç—…æ¯’æ„ŸæŸ“çš„è‚ºç‚ç–«æƒ…æƒ…å†µ']\n",
    "# endTime=\"2018-6-6\"\n",
    "# urlList={}\n",
    "# urlList=newsToolForHealthCenter.get_page_news(keywords,browser,urlList=urlList,endTime=endTime)\n",
    "# \n",
    "# while True:\n",
    "#     try:\n",
    "#         #æ‰¾åˆ°ä¸‹ä¸€é¡µæŒ‰é’® å¹¶ç‚¹å‡»\n",
    "#         browser.find_element(\"xpath\",'//*[@id=\"pageInfo\"]//*[@class=\"next\"]/a').click()\n",
    "#         #è·å–ä¸‹ä¸€é¡µæ–°é—»çš„url\n",
    "#         result=newsToolForHealthCenter.get_page_news(keywords,browser,urlList=urlList,endTime=endTime)\n",
    "#         if result is np.nan:\n",
    "#             break\n",
    "#     except BaseException as err:\n",
    "#         # print(err)\n",
    "#         browser.close()\n",
    "#         break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(len(urlList))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ###å…¶ä¸­æœ‰ä¸€ä¸ªæ–‡ç« é“¾æ¥ä¼šæŠ¥é”™\n",
    "# allHealthCenterNews=pd.DataFrame()\n",
    "# for link,title in urlList.items():\n",
    "#     contentAndTime=asyncio.run(newsToolForHealthCenter.getPageContent(url=link))\n",
    "#     theNewsInstance={\"Title\":[title],\"Link\":[link],\"Content\":[contentAndTime['Content']],\"Public_Time\":[contentAndTime['Public_Date']],\"Source\":[contentAndTime['Source']]}\n",
    "#     theNewsDf=pd.DataFrame.from_dict(theNewsInstance)\n",
    "#     allHealthCenterNews=pd.concat([theNewsDf,allHealthCenterNews])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# allHealthCenterNews"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# allHealthCenterNews.to_csv(\"stockData/furtherInformation/covid19/CovidNews01.csv\",index=False,encoding=\"utf-8\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "allHealthCenterNews=pd.read_csv(\"stockData/furtherInformation/covid19/CovidNews.csv\")\n",
    "allHealthCenterNews"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get the city name in china"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tkinter import _flatten\n",
    "\n",
    "## url: https://zh.wikipedia.org/zh-hans/%E4%B8%AD%E5%8D%8E%E4%BA%BA%E6%B0%91%E5%85%B1%E5%92%8C%E5%9B%BD%E5%9F%8E%E5%B8%82%E5%88%97%E8%A1%A8\n",
    "\n",
    "def filterChara(content:str):\n",
    "    content=[c.replace(\"åœ°çº§å¸‚ï¼š\",\"\").replace(\"å¿çº§å¸‚ï¼š\",\"\").replace(\"å‰¯çœçº§å¸‚ï¼š\",\"\").strip().split(\"ã€\") for c in content.split(\"\\n\")]\n",
    "    content=list(_flatten(content))\n",
    "    return content\n",
    "\n",
    "browser.get('https://zh.wikipedia.org/zh-hans/%E4%B8%AD%E5%8D%8E%E4%BA%BA%E6%B0%91%E5%85%B1%E5%92%8C%E5%9B%BD%E5%9F%8E%E5%B8%82%E5%88%97%E8%A1%A8')\n",
    "\n",
    "cities = browser.find_elements(\"xpath\",'//*[@class=\"mw-content-container\"]//*[@id=\"content\"]//*[@id=\"bodyContent\"]//*[@id=\"mw-content-text\"]//*[@class=\"mw-parser-output\"]/h3//*[@class=\"mw-headline\"]/a')\n",
    "\n",
    "towns = browser.find_elements(\"xpath\",'//*[@class=\"mw-content-container\"]//*[@id=\"content\"]//*[@id=\"bodyContent\"]//*[@id=\"mw-content-text\"]//*[@class=\"mw-parser-output\"]/ul')\n",
    "\n",
    "directlyCities=[\"åŒ—äº¬å¸‚\",\"å¤©æ´¥å¸‚\",\"ä¸Šæµ·å¸‚\",\"é‡åº†å¸‚\"]\n",
    "specialArea=[\"é¦™æ¸¯ç‰¹åˆ«è¡Œæ”¿åŒº\",\"æ¾³é—¨ç‰¹åˆ«è¡Œæ”¿åŒº\"]\n",
    "\n",
    "allCityAndTown={}\n",
    "\n",
    "cityList=[\"ç›´è¾–å¸‚\",\"ç‰¹åˆ«è¡Œæ”¿åŒº\"]\n",
    "for city in cities:\n",
    "    # print(\"-------------------------\")\n",
    "    # print(city.get_attribute(\"title\"))\n",
    "    cityList.append(city.get_attribute(\"title\"))\n",
    "\n",
    "townList=[]\n",
    "for index,town in enumerate(towns):\n",
    "    if index>=len(cityList):\n",
    "        break\n",
    "    for j,city in enumerate(cityList):\n",
    "        if index==j:\n",
    "            # print(city,\":  \\n\",filterChara(town.text))\n",
    "            allCityAndTown[city]=filterChara(town.text)\n",
    "allCityAndTown"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "file = open(\"dictionary_data.json\", \"w\")\n",
    "json.dump(allCityAndTown, file)\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-27T12:05:31.903516Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
