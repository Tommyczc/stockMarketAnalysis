{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1.0 Get the raw news information\n",
    "* 本篇代码用来获取相关公司的新闻文本\n",
    "* 由于信息渠道广泛，将会爬虫数个新闻网站: [新浪新闻，微信公众号]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 新浪新闻获取"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, news\n",
      "Load time  0:00:00.625339\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xlwt as xlwt\n",
    "\n",
    "print(\"Hello, news\")\n",
    "from datetime import datetime\n",
    "now=datetime.now()\n",
    "from lxml import etree\n",
    "import numpy as np\n",
    "from pylab import mpl\n",
    "# todo: solve chinese problem for plt\n",
    "mpl.rcParams['font.sans-serif']=['SimHei']\n",
    "mpl.rcParams['axes.unicode_minus']=False\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import json\n",
    "print(\"Load time \",datetime.now()-now)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T07:41:36.654909400Z",
     "start_time": "2023-08-29T07:41:35.636686900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from requests import RequestException\n",
    "\n",
    "\n",
    "class newsToolForSina:\n",
    "    @staticmethod\n",
    "    def get_list(url):\n",
    "\n",
    "        # 新闻链接\n",
    "        res=requests.get(url)\n",
    "        res.encoding='utf-8'\n",
    "\n",
    "        # 完整HTML\n",
    "        html=BeautifulSoup(res.text,'html.parser')\n",
    "\n",
    "        # 新闻列表\n",
    "        newList=[]\n",
    "\n",
    "        for item in html.find_all('div',['news-item','img-news-item']):\n",
    "            try:\n",
    "                newObj={}\n",
    "                newObj['title']=item.select('h2 a')[0].text\n",
    "                newObj['url']=item.select('h2 a')[0].get('href')\n",
    "                newList.append(newObj)\n",
    "            except:\n",
    "                print('出现异常')\n",
    "        return newList\n",
    "\n",
    "    @staticmethod\n",
    "    def get_HtmlDetail_Sina(url):\n",
    "\n",
    "        # 新闻链接\n",
    "        res=requests.get(url)\n",
    "        res.encoding='utf-8'\n",
    "\n",
    "        # 完整HTML\n",
    "        html=BeautifulSoup(res.text,'html.parser')\n",
    "\n",
    "        # 新闻对象\n",
    "        result={}\n",
    "\n",
    "        # 新闻标题\n",
    "        result['title']=html.select('.main-title')[0].text\n",
    "\n",
    "        # 发布时间\n",
    "        timesource=html.select('.date-source span')[0].text\n",
    "        createtime=datetime.strptime(timesource,'%Y年%m月%d日 %H:%M')\n",
    "        createtime.strftime('%Y-%m-%d')\n",
    "        result['createtime']=createtime\n",
    "\n",
    "        # 新闻来源\n",
    "        result['place']=html.select('.date-source a')[0].text\n",
    "\n",
    "        # 新闻内容\n",
    "        article=[]\n",
    "        for p in html.select('#article p')[:-1]:\n",
    "            article.append(p.text.strip())\n",
    "        articleText=' '.join(article)\n",
    "        result['article']=articleText\n",
    "\n",
    "        # 新闻作者\n",
    "        result['author']=html.select('.show_author')[0].text.strip('责任编辑：')\n",
    "\n",
    "        # 新闻链接\n",
    "        result['url']=url\n",
    "\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def get_page_news(browser,urlList):\n",
    "        #获取当前页面所有包含新闻的a标签\n",
    "        news = browser.find_elements(\"xpath\",'//div[@class=\"d_list_txt\"]/ul/li/span/a')\n",
    "        if len(news)==0:\n",
    "            return np.nan\n",
    "        for i in news:\n",
    "            link = i.get_attribute('href') #得到新闻url\n",
    "            # print(len(urlList),link)\n",
    "            if link not in urlList:  #通过url去重\n",
    "                urlList.append(link)\n",
    "        return urlList\n",
    "\n",
    "    @staticmethod\n",
    "    def getNewsData(url):\n",
    "        # 获取新闻的详细信息\n",
    "        html = newsToolForSina.get_response(url)\n",
    "        #使用beautifulsoup进行解析\n",
    "        soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "        #标题\n",
    "        '''\n",
    "        <h1 class=\"main-title\">证监会要求北京银行说明是否串通*ST康得管理层舞弊</h1>\n",
    "        '''\n",
    "        title = soup.select('.main-title')\n",
    "        #可能有小部分标题的标签不是上述格式 对其进行补充\n",
    "        if not title:\n",
    "            title = soup.select('#artibodyTitle')\n",
    "        if title:\n",
    "            title = title[0].text\n",
    "        # print(title)\n",
    "\n",
    "        #日期\n",
    "        '''\n",
    "        <span class=\"date\">2019年07月20日 16:52</span>\n",
    "        '''\n",
    "        date = soup.select('.date')\n",
    "        # 可能有小部分日期的标签不是上述格式 对其进行补充\n",
    "        if not date:\n",
    "            date = soup.select('#pub_date')\n",
    "        if date:\n",
    "            date = date[0].text\n",
    "        # print(date)\n",
    "\n",
    "        #来源\n",
    "        '''\n",
    "        <span class=\"source ent-source\">中国证券报</span>\n",
    "        '''\n",
    "        source = soup.select('.source')\n",
    "        # 可能有小部分来源的标签不是上述格式 对其进行补充\n",
    "        if not source:\n",
    "            source = soup.select('[data-sudaclick=\"media_name\"]')\n",
    "        if source:\n",
    "            source = source[0].text\n",
    "        # print(source)\n",
    "\n",
    "        #正文\n",
    "        article = soup.select('div[class=\"article\"] p')\n",
    "        # 可能有小部分正文的标签不是上述格式 对其进行补充\n",
    "        if not article:\n",
    "            article = soup.select('div[id=\"artibody\"] p')\n",
    "        if article:\n",
    "            #把正文放在一个列表中 每个p标签的内容为列表的一项\n",
    "            article_list = []\n",
    "            for i in article:\n",
    "                # print(i.text)\n",
    "                article_list.append(i.text)\n",
    "        #转为字典格式\n",
    "        news = {'link': url, 'title': title, 'date': date, 'source': source, 'article': article_list}\n",
    "        return news\n",
    "\n",
    "    @staticmethod\n",
    "    def get_response(url):\n",
    "        try:\n",
    "            #添加User-Agent，放在headers中，伪装成浏览器\n",
    "            headers = {\n",
    "                'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36'\n",
    "            }\n",
    "            response = requests.get(url,headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                response.encoding = 'utf-8'\n",
    "                return response.text\n",
    "            return None\n",
    "        except RequestException:\n",
    "            return None\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T07:41:36.690812800Z",
     "start_time": "2023-08-29T07:41:36.656902400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "###test\n",
    "# newList=newsToolForSina.get_list('https://news.sina.com.cn/world/')\n",
    "# resultList=pd.DataFrame()\n",
    "#\n",
    "# for i,item in enumerate(newList):\n",
    "#     try:\n",
    "#         result=newsToolForSina.get_HtmlDetail_Sina(item['url'])\n",
    "#         newObj=pd.DataFrame(result,index=[0])\n",
    "#         resultList=resultList.append(newObj)\n",
    "#         print (str(i),'写入成功')\n",
    "#     except BaseException as err:\n",
    "#         print (str(i),'出现异常: ',err)\n",
    "#\n",
    "# resultList.to_csv(\"newsData/test.csv\",header=resultList.columns)\n",
    "# resultList"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T07:41:36.701782500Z",
     "start_time": "2023-08-29T07:41:36.685825500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 注意: 新浪新闻的历史数据只能查到近期一个月的，并不能查之前的，所以新浪的可以放弃一部分了"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# from selenium.common import NoSuchElementException\n",
    "#\n",
    "# #打开浏览器\n",
    "# UrlList=[]\n",
    "# browser = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "# browser.implicitly_wait(10)\n",
    "# #打开网址\n",
    "# browser.get('https://news.sina.com.cn/roll/')\n",
    "# #获取当前页面新闻的url\n",
    "# UrlList=newsToolForSina.get_page_news(browser,urlList=UrlList)\n",
    "# while True:\n",
    "#     try:\n",
    "#         #找到下一页按钮 并点击\n",
    "#         '''\n",
    "#         <a href=\"javascript:void(0)\" onclick=\"newsList.page.next();return false;\">下一页</a>\n",
    "#         '''\n",
    "#         browser.find_element(\"xpath\",'//a[@onclick=\"newsList.page.next();return false;\"]').click()\n",
    "#         #获取下一页新闻的url\n",
    "#         result=newsToolForSina.get_page_news(browser,urlList=UrlList)\n",
    "#         if result is np.nan:\n",
    "#             break\n",
    "#     except BaseException as err:\n",
    "#         print(err)\n",
    "#         browser.close()\n",
    "#\n",
    "#\n",
    "# print(\"Have found {} URL records, trying to get news text data\".format(len(UrlList)))\n",
    "# resultList=pd.DataFrame()\n",
    "# for i,item in enumerate(UrlList):\n",
    "#     try:\n",
    "#         result=newsToolForSina.getNewsData(item)\n",
    "#         newObj=pd.DataFrame(result)\n",
    "#         resultList=resultList.append(newObj)\n",
    "#         print (str(i),'写入成功')\n",
    "#         # break\n",
    "#     except BaseException as err:\n",
    "#         print (str(i),'出现异常: ',err)\n",
    "#         # break\n",
    "#\n",
    "#\n",
    "# resultList.to_csv(\"newsData/SinaNewsRawData.csv\",header=resultList.columns)\n",
    "# resultList"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T07:41:36.720731700Z",
     "start_time": "2023-08-29T07:41:36.703777600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "       Unnamed: 0                                               link  \\\n0               0  https://finance.sina.com.cn/roll/2023-05-12/do...   \n1               1  https://finance.sina.com.cn/roll/2023-05-12/do...   \n2               2  https://finance.sina.com.cn/roll/2023-05-12/do...   \n3               3  https://finance.sina.com.cn/roll/2023-05-12/do...   \n4               4  https://finance.sina.com.cn/roll/2023-05-12/do...   \n...           ...                                                ...   \n47350           2  https://finance.sina.com.cn/tob/2023-05-10/doc...   \n47351           0  https://finance.sina.com.cn/tob/2023-05-10/doc...   \n47352           1  https://finance.sina.com.cn/tob/2023-05-10/doc...   \n47353           0  https://finance.sina.com.cn/tob/2023-05-10/doc...   \n47354           1  https://finance.sina.com.cn/tob/2023-05-10/doc...   \n\n                                 title               date source  \\\n0                 4月居民存款锐减之谜，1.2万亿去哪了？  2023年05月12日 16:48   第一财经   \n1                 4月居民存款锐减之谜，1.2万亿去哪了？  2023年05月12日 16:48   第一财经   \n2                 4月居民存款锐减之谜，1.2万亿去哪了？  2023年05月12日 16:48   第一财经   \n3                 4月居民存款锐减之谜，1.2万亿去哪了？  2023年05月12日 16:48   第一财经   \n4                 4月居民存款锐减之谜，1.2万亿去哪了？  2023年05月12日 16:48   第一财经   \n...                                ...                ...    ...   \n47350      蒙牛乳业5月9日斥资约1826.08万港元回购55万股  2023年05月10日 08:59   新浪港股   \n47351   太古股份公司A5月9日斥资272.95万港元回购4.55万股  2023年05月10日 08:58   新浪港股   \n47352   太古股份公司A5月9日斥资272.95万港元回购4.55万股  2023年05月10日 08:58   新浪港股   \n47353  太古股份公司B5月9日耗资约550.67万港元回购55.5万股  2023年05月10日 08:58   新浪港股   \n47354  太古股份公司B5月9日耗资约550.67万港元回购55.5万股  2023年05月10日 08:58   新浪港股   \n\n                                                 article  \n0                 　　炒股就看金麒麟分析师研报，权威，专业，及时，全面，助您挖掘潜力主题机会！  \n1      　　但这在数据上并未得到印证。国家统计局公布的数据显示，4月份，全国CPI同比上涨0.1%；...  \n2                                 　　4月居民存款大幅减少引起市场的广泛热议。  \n3      　　央行最新公布的4月金融数据显示，4月人民币存款减少4609亿元，同比多减5524亿元，其...  \n4      　　不少分析认为，4月居民存款减少或源自“提前还贷”和消费回升所致；另外的观点则认为，4月份...  \n...                                                  ...  \n47350                                          责任编辑：卢昱君   \n47351  　　太古股份公司A（00019）发布公告，于2023年5月9日斥资272.95万港元回购4....  \n47352                                          责任编辑：卢昱君   \n47353  　　太古股份公司B（00087）公布，2023年5月9日耗资约550.67万港元回购55.5...  \n47354                                          责任编辑：卢昱君   \n\n[47355 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>link</th>\n      <th>title</th>\n      <th>date</th>\n      <th>source</th>\n      <th>article</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>https://finance.sina.com.cn/roll/2023-05-12/do...</td>\n      <td>4月居民存款锐减之谜，1.2万亿去哪了？</td>\n      <td>2023年05月12日 16:48</td>\n      <td>第一财经</td>\n      <td>炒股就看金麒麟分析师研报，权威，专业，及时，全面，助您挖掘潜力主题机会！</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>https://finance.sina.com.cn/roll/2023-05-12/do...</td>\n      <td>4月居民存款锐减之谜，1.2万亿去哪了？</td>\n      <td>2023年05月12日 16:48</td>\n      <td>第一财经</td>\n      <td>但这在数据上并未得到印证。国家统计局公布的数据显示，4月份，全国CPI同比上涨0.1%；...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>https://finance.sina.com.cn/roll/2023-05-12/do...</td>\n      <td>4月居民存款锐减之谜，1.2万亿去哪了？</td>\n      <td>2023年05月12日 16:48</td>\n      <td>第一财经</td>\n      <td>4月居民存款大幅减少引起市场的广泛热议。</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>https://finance.sina.com.cn/roll/2023-05-12/do...</td>\n      <td>4月居民存款锐减之谜，1.2万亿去哪了？</td>\n      <td>2023年05月12日 16:48</td>\n      <td>第一财经</td>\n      <td>央行最新公布的4月金融数据显示，4月人民币存款减少4609亿元，同比多减5524亿元，其...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>https://finance.sina.com.cn/roll/2023-05-12/do...</td>\n      <td>4月居民存款锐减之谜，1.2万亿去哪了？</td>\n      <td>2023年05月12日 16:48</td>\n      <td>第一财经</td>\n      <td>不少分析认为，4月居民存款减少或源自“提前还贷”和消费回升所致；另外的观点则认为，4月份...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>47350</th>\n      <td>2</td>\n      <td>https://finance.sina.com.cn/tob/2023-05-10/doc...</td>\n      <td>蒙牛乳业5月9日斥资约1826.08万港元回购55万股</td>\n      <td>2023年05月10日 08:59</td>\n      <td>新浪港股</td>\n      <td>责任编辑：卢昱君</td>\n    </tr>\n    <tr>\n      <th>47351</th>\n      <td>0</td>\n      <td>https://finance.sina.com.cn/tob/2023-05-10/doc...</td>\n      <td>太古股份公司A5月9日斥资272.95万港元回购4.55万股</td>\n      <td>2023年05月10日 08:58</td>\n      <td>新浪港股</td>\n      <td>太古股份公司A（00019）发布公告，于2023年5月9日斥资272.95万港元回购4....</td>\n    </tr>\n    <tr>\n      <th>47352</th>\n      <td>1</td>\n      <td>https://finance.sina.com.cn/tob/2023-05-10/doc...</td>\n      <td>太古股份公司A5月9日斥资272.95万港元回购4.55万股</td>\n      <td>2023年05月10日 08:58</td>\n      <td>新浪港股</td>\n      <td>责任编辑：卢昱君</td>\n    </tr>\n    <tr>\n      <th>47353</th>\n      <td>0</td>\n      <td>https://finance.sina.com.cn/tob/2023-05-10/doc...</td>\n      <td>太古股份公司B5月9日耗资约550.67万港元回购55.5万股</td>\n      <td>2023年05月10日 08:58</td>\n      <td>新浪港股</td>\n      <td>太古股份公司B（00087）公布，2023年5月9日耗资约550.67万港元回购55.5...</td>\n    </tr>\n    <tr>\n      <th>47354</th>\n      <td>1</td>\n      <td>https://finance.sina.com.cn/tob/2023-05-10/doc...</td>\n      <td>太古股份公司B5月9日耗资约550.67万港元回购55.5万股</td>\n      <td>2023年05月10日 08:58</td>\n      <td>新浪港股</td>\n      <td>责任编辑：卢昱君</td>\n    </tr>\n  </tbody>\n</table>\n<p>47355 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultList=pd.read_csv(\"newsData/SinaNewsRawData.csv\")\n",
    "resultList"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T07:41:37.010244400Z",
     "start_time": "2023-08-29T07:41:36.717740Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T07:41:37.031358Z",
     "start_time": "2023-08-29T07:41:37.011242700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 新闻联播文本稿"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T07:41:37.080226600Z",
     "start_time": "2023-08-29T07:41:37.028367200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 微博基于关键字内容爬取 (主要内容: 文章文本，观看人数，评论，点赞)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T07:41:37.111143100Z",
     "start_time": "2023-08-29T07:41:37.042327700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4 微信公众号基于关键字爬取 (主要内容: 文章文本，评论，点赞，收藏)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T07:41:37.112140700Z",
     "start_time": "2023-08-29T07:41:37.059282100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.5 卫生办 新冠病毒 人数统计(日)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class newsToolForHealthCenter:\n",
    "    @staticmethod\n",
    "    def get_page_news(keyword:str,browser):\n",
    "        newsList=[]\n",
    "        news = browser.find_elements(\"xpath\",'//*[@id=\"0\"]/div[1]/a')\n",
    "        if len(news)==0:\n",
    "            return np.nan\n",
    "        for i in news:\n",
    "            link = i.get_attribute('href') #得到新闻url\n",
    "            # print(len(urlList),link)\n",
    "        return newsList"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T07:41:37.113137900Z",
     "start_time": "2023-08-29T07:41:37.077237200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "SessionNotCreatedException",
     "evalue": "Message: session not created: This version of ChromeDriver only supports Chrome version 114\nCurrent browser version is 116.0.5845.111 with binary path C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x00E4A813+48355]\n\t(No symbol) [0x00DDC4B1]\n\t(No symbol) [0x00CE5358]\n\t(No symbol) [0x00D061AC]\n\t(No symbol) [0x00D01EF3]\n\t(No symbol) [0x00D00579]\n\t(No symbol) [0x00D30C55]\n\t(No symbol) [0x00D3093C]\n\t(No symbol) [0x00D2A536]\n\t(No symbol) [0x00D082DC]\n\t(No symbol) [0x00D093DD]\n\tGetHandleVerifier [0x010AAABD+2539405]\n\tGetHandleVerifier [0x010EA78F+2800735]\n\tGetHandleVerifier [0x010E456C+2775612]\n\tGetHandleVerifier [0x00ED51E0+616112]\n\t(No symbol) [0x00DE5F8C]\n\t(No symbol) [0x00DE2328]\n\t(No symbol) [0x00DE240B]\n\t(No symbol) [0x00DD4FF7]\n\tBaseThreadInitThunk [0x771400C9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77847B1E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77847AEE+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mSessionNotCreatedException\u001B[0m                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m#打开浏览器\u001B[39;00m\n\u001B[0;32m      4\u001B[0m UrlList\u001B[38;5;241m=\u001B[39m[]\n\u001B[1;32m----> 5\u001B[0m browser \u001B[38;5;241m=\u001B[39m \u001B[43mwebdriver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mChrome\u001B[49m\u001B[43m(\u001B[49m\u001B[43mservice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mService\u001B[49m\u001B[43m(\u001B[49m\u001B[43mChromeDriverManager\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minstall\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m browser\u001B[38;5;241m.\u001B[39mimplicitly_wait(\u001B[38;5;241m10\u001B[39m)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m#打开网址\u001B[39;00m\n",
      "File \u001B[1;32mE:\\Apps\\anaconda\\envs\\DataAnalysis\\lib\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py:45\u001B[0m, in \u001B[0;36mWebDriver.__init__\u001B[1;34m(self, options, service, keep_alive)\u001B[0m\n\u001B[0;32m     42\u001B[0m service \u001B[38;5;241m=\u001B[39m service \u001B[38;5;28;01mif\u001B[39;00m service \u001B[38;5;28;01melse\u001B[39;00m Service()\n\u001B[0;32m     43\u001B[0m options \u001B[38;5;241m=\u001B[39m options \u001B[38;5;28;01mif\u001B[39;00m options \u001B[38;5;28;01melse\u001B[39;00m Options()\n\u001B[1;32m---> 45\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m     46\u001B[0m \u001B[43m    \u001B[49m\u001B[43mDesiredCapabilities\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCHROME\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbrowserName\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     47\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgoog\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     48\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     49\u001B[0m \u001B[43m    \u001B[49m\u001B[43mservice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     50\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkeep_alive\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     51\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Apps\\anaconda\\envs\\DataAnalysis\\lib\\site-packages\\selenium\\webdriver\\chromium\\webdriver.py:56\u001B[0m, in \u001B[0;36mChromiumDriver.__init__\u001B[1;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mservice\u001B[38;5;241m.\u001B[39mstart()\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 56\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m     57\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcommand_executor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mChromiumRemoteConnection\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     58\u001B[0m \u001B[43m            \u001B[49m\u001B[43mremote_server_addr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mservice\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mservice_url\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     59\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbrowser_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbrowser_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[43m            \u001B[49m\u001B[43mvendor_prefix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvendor_prefix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     61\u001B[0m \u001B[43m            \u001B[49m\u001B[43mkeep_alive\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_alive\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     62\u001B[0m \u001B[43m            \u001B[49m\u001B[43mignore_proxy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_ignore_local_proxy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     63\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     64\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     65\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m     67\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquit()\n",
      "File \u001B[1;32mE:\\Apps\\anaconda\\envs\\DataAnalysis\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:206\u001B[0m, in \u001B[0;36mWebDriver.__init__\u001B[1;34m(self, command_executor, keep_alive, file_detector, options)\u001B[0m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_authenticator_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstart_client()\n\u001B[1;32m--> 206\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart_session\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcapabilities\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Apps\\anaconda\\envs\\DataAnalysis\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:290\u001B[0m, in \u001B[0;36mWebDriver.start_session\u001B[1;34m(self, capabilities)\u001B[0m\n\u001B[0;32m    283\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Creates a new session with the desired capabilities.\u001B[39;00m\n\u001B[0;32m    284\u001B[0m \n\u001B[0;32m    285\u001B[0m \u001B[38;5;124;03m:Args:\u001B[39;00m\n\u001B[0;32m    286\u001B[0m \u001B[38;5;124;03m - capabilities - a capabilities dict to start the session with.\u001B[39;00m\n\u001B[0;32m    287\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    289\u001B[0m caps \u001B[38;5;241m=\u001B[39m _create_caps(capabilities)\n\u001B[1;32m--> 290\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mCommand\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mNEW_SESSION\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaps\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    291\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msession_id \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msessionId\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    292\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcaps \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcapabilities\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mE:\\Apps\\anaconda\\envs\\DataAnalysis\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:345\u001B[0m, in \u001B[0;36mWebDriver.execute\u001B[1;34m(self, driver_command, params)\u001B[0m\n\u001B[0;32m    343\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_executor\u001B[38;5;241m.\u001B[39mexecute(driver_command, params)\n\u001B[0;32m    344\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response:\n\u001B[1;32m--> 345\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merror_handler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresponse\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    346\u001B[0m     response[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_unwrap_value(response\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    347\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[1;32mE:\\Apps\\anaconda\\envs\\DataAnalysis\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001B[0m, in \u001B[0;36mErrorHandler.check_response\u001B[1;34m(self, response)\u001B[0m\n\u001B[0;32m    227\u001B[0m         alert_text \u001B[38;5;241m=\u001B[39m value[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124malert\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    228\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001B[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001B[39;00m\n\u001B[1;32m--> 229\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001B[1;31mSessionNotCreatedException\u001B[0m: Message: session not created: This version of ChromeDriver only supports Chrome version 114\nCurrent browser version is 116.0.5845.111 with binary path C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x00E4A813+48355]\n\t(No symbol) [0x00DDC4B1]\n\t(No symbol) [0x00CE5358]\n\t(No symbol) [0x00D061AC]\n\t(No symbol) [0x00D01EF3]\n\t(No symbol) [0x00D00579]\n\t(No symbol) [0x00D30C55]\n\t(No symbol) [0x00D3093C]\n\t(No symbol) [0x00D2A536]\n\t(No symbol) [0x00D082DC]\n\t(No symbol) [0x00D093DD]\n\tGetHandleVerifier [0x010AAABD+2539405]\n\tGetHandleVerifier [0x010EA78F+2800735]\n\tGetHandleVerifier [0x010E456C+2775612]\n\tGetHandleVerifier [0x00ED51E0+616112]\n\t(No symbol) [0x00DE5F8C]\n\t(No symbol) [0x00DE2328]\n\t(No symbol) [0x00DE240B]\n\t(No symbol) [0x00DD4FF7]\n\tBaseThreadInitThunk [0x771400C9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77847B1E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77847AEE+238]\n"
     ]
    }
   ],
   "source": [
    "from selenium.common import NoSuchElementException\n",
    "\n",
    "#打开浏览器\n",
    "UrlList=[]\n",
    "browser = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "browser.implicitly_wait(10)\n",
    "#打开网址\n",
    "browser.get('http://zs.kaipuyun.cn/s?token=&siteCode=N000001642&searchWord=%E6%96%B0%E5%9E%8B%E5%86%A0%E7%8A%B6%E7%97%85%E6%AF%92&button=')\n",
    "#获取当前页面新闻的url\n",
    "UrlList=[]\n",
    "currentPageList=newsToolForHealthCenter.get_page_news(\"截至???新型冠状病毒肺炎疫情最新情况\",browser)\n",
    "if currentPageList is not np.nan:\n",
    "    print(currentPageList)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-29T07:41:50.735780200Z",
     "start_time": "2023-08-29T07:41:37.089201900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
