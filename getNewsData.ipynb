{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1.0 Get the raw news information\n",
    "* 本篇代码用来获取相关公司的新闻文本\n",
    "* 由于信息渠道广泛，将会爬虫数个新闻网站: [新浪新闻，微信公众号]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 新浪新闻获取"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, news\n",
      "Load time  0:00:00.188781\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import xlwt as xlwt\n",
    "\n",
    "print(\"Hello, news\")\n",
    "from datetime import datetime\n",
    "now=datetime.now()\n",
    "import numpy as np\n",
    "from pylab import mpl\n",
    "# todo: solve chinese problem for plt\n",
    "mpl.rcParams['font.sans-serif']=['SimHei']\n",
    "mpl.rcParams['axes.unicode_minus']=False\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import json\n",
    "from pyppeteer import launch\n",
    "from bs4 import BeautifulSoup\n",
    "from pyppeteer import launcher\n",
    "launcher.DEFAULT_ARGS.remove(\"--enable-automation\")\n",
    "print(\"Load time \",datetime.now()-now)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T09:40:05.191873Z",
     "start_time": "2023-09-26T09:40:04.991109Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from requests import RequestException\n",
    "\n",
    "\n",
    "class newsToolForSina:\n",
    "    @staticmethod\n",
    "    def get_list(url):\n",
    "\n",
    "        # 新闻链接\n",
    "        res=requests.get(url)\n",
    "        res.encoding='utf-8'\n",
    "\n",
    "        # 完整HTML\n",
    "        html=BeautifulSoup(res.text,'html.parser')\n",
    "\n",
    "        # 新闻列表\n",
    "        newList=[]\n",
    "\n",
    "        for item in html.find_all('div',['news-item','img-news-item']):\n",
    "            try:\n",
    "                newObj={}\n",
    "                newObj['title']=item.select('h2 a')[0].text\n",
    "                newObj['url']=item.select('h2 a')[0].get('href')\n",
    "                newList.append(newObj)\n",
    "            except:\n",
    "                print('出现异常')\n",
    "        return newList\n",
    "\n",
    "    @staticmethod\n",
    "    def get_HtmlDetail_Sina(url):\n",
    "\n",
    "        # 新闻链接\n",
    "        res=requests.get(url)\n",
    "        res.encoding='utf-8'\n",
    "\n",
    "        # 完整HTML\n",
    "        html=BeautifulSoup(res.text,'html.parser')\n",
    "\n",
    "        # 新闻对象\n",
    "        result={}\n",
    "\n",
    "        # 新闻标题\n",
    "        result['title']=html.select('.main-title')[0].text\n",
    "\n",
    "        # 发布时间\n",
    "        timesource=html.select('.date-source span')[0].text\n",
    "        createtime=datetime.strptime(timesource,'%Y年%m月%d日 %H:%M')\n",
    "        createtime.strftime('%Y-%m-%d')\n",
    "        result['createtime']=createtime\n",
    "\n",
    "        # 新闻来源\n",
    "        result['place']=html.select('.date-source a')[0].text\n",
    "\n",
    "        # 新闻内容\n",
    "        article=[]\n",
    "        for p in html.select('#article p')[:-1]:\n",
    "            article.append(p.text.strip())\n",
    "        articleText=' '.join(article)\n",
    "        result['article']=articleText\n",
    "\n",
    "        # 新闻作者\n",
    "        result['author']=html.select('.show_author')[0].text.strip('责任编辑：')\n",
    "\n",
    "        # 新闻链接\n",
    "        result['url']=url\n",
    "\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def get_page_news(browser,urlList):\n",
    "        #获取当前页面所有包含新闻的a标签\n",
    "        news = browser.find_elements(\"xpath\",'//div[@class=\"d_list_txt\"]/ul/li/span/a')\n",
    "        if len(news)==0:\n",
    "            return np.nan\n",
    "        for i in news:\n",
    "            link = i.get_attribute('href') #得到新闻url\n",
    "            # print(len(urlList),link)\n",
    "            if link not in urlList:  #通过url去重\n",
    "                urlList.append(link)\n",
    "        return urlList\n",
    "\n",
    "    @staticmethod\n",
    "    def getNewsData(url):\n",
    "        # 获取新闻的详细信息\n",
    "        html = newsToolForSina.get_response(url)\n",
    "        #使用beautifulsoup进行解析\n",
    "        soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "        #标题\n",
    "        '''\n",
    "        <h1 class=\"main-title\">证监会要求北京银行说明是否串通*ST康得管理层舞弊</h1>\n",
    "        '''\n",
    "        title = soup.select('.main-title')\n",
    "        #可能有小部分标题的标签不是上述格式 对其进行补充\n",
    "        if not title:\n",
    "            title = soup.select('#artibodyTitle')\n",
    "        if title:\n",
    "            title = title[0].text\n",
    "        # print(title)\n",
    "\n",
    "        #日期\n",
    "        '''\n",
    "        <span class=\"date\">2019年07月20日 16:52</span>\n",
    "        '''\n",
    "        date = soup.select('.date')\n",
    "        # 可能有小部分日期的标签不是上述格式 对其进行补充\n",
    "        if not date:\n",
    "            date = soup.select('#pub_date')\n",
    "        if date:\n",
    "            date = date[0].text\n",
    "        # print(date)\n",
    "\n",
    "        #来源\n",
    "        '''\n",
    "        <span class=\"source ent-source\">中国证券报</span>\n",
    "        '''\n",
    "        source = soup.select('.source')\n",
    "        # 可能有小部分来源的标签不是上述格式 对其进行补充\n",
    "        if not source:\n",
    "            source = soup.select('[data-sudaclick=\"media_name\"]')\n",
    "        if source:\n",
    "            source = source[0].text\n",
    "        # print(source)\n",
    "\n",
    "        #正文\n",
    "        article = soup.select('div[class=\"article\"] p')\n",
    "        # 可能有小部分正文的标签不是上述格式 对其进行补充\n",
    "        if not article:\n",
    "            article = soup.select('div[id=\"artibody\"] p')\n",
    "        if article:\n",
    "            #把正文放在一个列表中 每个p标签的内容为列表的一项\n",
    "            article_list = []\n",
    "            for i in article:\n",
    "                # print(i.text)\n",
    "                article_list.append(i.text)\n",
    "        #转为字典格式\n",
    "        news = {'link': url, 'title': title, 'date': date, 'source': source, 'article': article_list}\n",
    "        return news\n",
    "\n",
    "    @staticmethod\n",
    "    def get_response(url):\n",
    "        try:\n",
    "            #添加User-Agent，放在headers中，伪装成浏览器\n",
    "            headers = {\n",
    "                'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36'\n",
    "            }\n",
    "            response = requests.get(url,headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                response.encoding = 'utf-8'\n",
    "                return response.text\n",
    "            return None\n",
    "        except RequestException:\n",
    "            return None\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T09:40:05.201427Z",
     "start_time": "2023-09-26T09:40:05.199515Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "###test\n",
    "# newList=newsToolForSina.get_list('https://news.sina.com.cn/world/')\n",
    "# resultList=pd.DataFrame()\n",
    "#\n",
    "# for i,item in enumerate(newList):\n",
    "#     try:\n",
    "#         result=newsToolForSina.get_HtmlDetail_Sina(item['url'])\n",
    "#         newObj=pd.DataFrame(result,index=[0])\n",
    "#         resultList=resultList.append(newObj)\n",
    "#         print (str(i),'写入成功')\n",
    "#     except BaseException as err:\n",
    "#         print (str(i),'出现异常: ',err)\n",
    "#\n",
    "# resultList.to_csv(\"newsData/test.csv\",header=resultList.columns)\n",
    "# resultList"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T09:40:05.206176Z",
     "start_time": "2023-09-26T09:40:05.202668Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 注意: 新浪新闻的历史数据只能查到近期一个月的，并不能查之前的，所以新浪的可以放弃一部分了"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# from selenium.common import NoSuchElementException\n",
    "#\n",
    "# #打开浏览器\n",
    "# UrlList=[]\n",
    "# browser = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "# browser.implicitly_wait(10)\n",
    "# #打开网址\n",
    "# browser.get('https://news.sina.com.cn/roll/')\n",
    "# #获取当前页面新闻的url\n",
    "# UrlList=newsToolForSina.get_page_news(browser,urlList=UrlList)\n",
    "# while True:\n",
    "#     try:\n",
    "#         #找到下一页按钮 并点击\n",
    "#         '''\n",
    "#         <a href=\"javascript:void(0)\" onclick=\"newsList.page.next();return false;\">下一页</a>\n",
    "#         '''\n",
    "#         browser.find_element(\"xpath\",'//a[@onclick=\"newsList.page.next();return false;\"]').click()\n",
    "#         #获取下一页新闻的url\n",
    "#         result=newsToolForSina.get_page_news(browser,urlList=UrlList)\n",
    "#         if result is np.nan:\n",
    "#             break\n",
    "#     except BaseException as err:\n",
    "#         print(err)\n",
    "#         browser.close()\n",
    "#\n",
    "#\n",
    "# print(\"Have found {} URL records, trying to get news text data\".format(len(UrlList)))\n",
    "# resultList=pd.DataFrame()\n",
    "# for i,item in enumerate(UrlList):\n",
    "#     try:\n",
    "#         result=newsToolForSina.getNewsData(item)\n",
    "#         newObj=pd.DataFrame(result)\n",
    "#         resultList=resultList.append(newObj)\n",
    "#         print (str(i),'写入成功')\n",
    "#         # break\n",
    "#     except BaseException as err:\n",
    "#         print (str(i),'出现异常: ',err)\n",
    "#         # break\n",
    "#\n",
    "#\n",
    "# resultList.to_csv(\"newsData/SinaNewsRawData.csv\",header=resultList.columns)\n",
    "# resultList"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T09:40:05.207778Z",
     "start_time": "2023-09-26T09:40:05.205634Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "       Unnamed: 0                                               link  \\\n0               0  https://finance.sina.com.cn/roll/2023-05-12/do...   \n1               1  https://finance.sina.com.cn/roll/2023-05-12/do...   \n2               2  https://finance.sina.com.cn/roll/2023-05-12/do...   \n3               3  https://finance.sina.com.cn/roll/2023-05-12/do...   \n4               4  https://finance.sina.com.cn/roll/2023-05-12/do...   \n...           ...                                                ...   \n47350           2  https://finance.sina.com.cn/tob/2023-05-10/doc...   \n47351           0  https://finance.sina.com.cn/tob/2023-05-10/doc...   \n47352           1  https://finance.sina.com.cn/tob/2023-05-10/doc...   \n47353           0  https://finance.sina.com.cn/tob/2023-05-10/doc...   \n47354           1  https://finance.sina.com.cn/tob/2023-05-10/doc...   \n\n                                 title               date source  \\\n0                 4月居民存款锐减之谜，1.2万亿去哪了？  2023年05月12日 16:48   第一财经   \n1                 4月居民存款锐减之谜，1.2万亿去哪了？  2023年05月12日 16:48   第一财经   \n2                 4月居民存款锐减之谜，1.2万亿去哪了？  2023年05月12日 16:48   第一财经   \n3                 4月居民存款锐减之谜，1.2万亿去哪了？  2023年05月12日 16:48   第一财经   \n4                 4月居民存款锐减之谜，1.2万亿去哪了？  2023年05月12日 16:48   第一财经   \n...                                ...                ...    ...   \n47350      蒙牛乳业5月9日斥资约1826.08万港元回购55万股  2023年05月10日 08:59   新浪港股   \n47351   太古股份公司A5月9日斥资272.95万港元回购4.55万股  2023年05月10日 08:58   新浪港股   \n47352   太古股份公司A5月9日斥资272.95万港元回购4.55万股  2023年05月10日 08:58   新浪港股   \n47353  太古股份公司B5月9日耗资约550.67万港元回购55.5万股  2023年05月10日 08:58   新浪港股   \n47354  太古股份公司B5月9日耗资约550.67万港元回购55.5万股  2023年05月10日 08:58   新浪港股   \n\n                                                 article  \n0                 　　炒股就看金麒麟分析师研报，权威，专业，及时，全面，助您挖掘潜力主题机会！  \n1      　　但这在数据上并未得到印证。国家统计局公布的数据显示，4月份，全国CPI同比上涨0.1%；...  \n2                                 　　4月居民存款大幅减少引起市场的广泛热议。  \n3      　　央行最新公布的4月金融数据显示，4月人民币存款减少4609亿元，同比多减5524亿元，其...  \n4      　　不少分析认为，4月居民存款减少或源自“提前还贷”和消费回升所致；另外的观点则认为，4月份...  \n...                                                  ...  \n47350                                          责任编辑：卢昱君   \n47351  　　太古股份公司A（00019）发布公告，于2023年5月9日斥资272.95万港元回购4....  \n47352                                          责任编辑：卢昱君   \n47353  　　太古股份公司B（00087）公布，2023年5月9日耗资约550.67万港元回购55.5...  \n47354                                          责任编辑：卢昱君   \n\n[47355 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>link</th>\n      <th>title</th>\n      <th>date</th>\n      <th>source</th>\n      <th>article</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>https://finance.sina.com.cn/roll/2023-05-12/do...</td>\n      <td>4月居民存款锐减之谜，1.2万亿去哪了？</td>\n      <td>2023年05月12日 16:48</td>\n      <td>第一财经</td>\n      <td>炒股就看金麒麟分析师研报，权威，专业，及时，全面，助您挖掘潜力主题机会！</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>https://finance.sina.com.cn/roll/2023-05-12/do...</td>\n      <td>4月居民存款锐减之谜，1.2万亿去哪了？</td>\n      <td>2023年05月12日 16:48</td>\n      <td>第一财经</td>\n      <td>但这在数据上并未得到印证。国家统计局公布的数据显示，4月份，全国CPI同比上涨0.1%；...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>https://finance.sina.com.cn/roll/2023-05-12/do...</td>\n      <td>4月居民存款锐减之谜，1.2万亿去哪了？</td>\n      <td>2023年05月12日 16:48</td>\n      <td>第一财经</td>\n      <td>4月居民存款大幅减少引起市场的广泛热议。</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>https://finance.sina.com.cn/roll/2023-05-12/do...</td>\n      <td>4月居民存款锐减之谜，1.2万亿去哪了？</td>\n      <td>2023年05月12日 16:48</td>\n      <td>第一财经</td>\n      <td>央行最新公布的4月金融数据显示，4月人民币存款减少4609亿元，同比多减5524亿元，其...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>https://finance.sina.com.cn/roll/2023-05-12/do...</td>\n      <td>4月居民存款锐减之谜，1.2万亿去哪了？</td>\n      <td>2023年05月12日 16:48</td>\n      <td>第一财经</td>\n      <td>不少分析认为，4月居民存款减少或源自“提前还贷”和消费回升所致；另外的观点则认为，4月份...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>47350</th>\n      <td>2</td>\n      <td>https://finance.sina.com.cn/tob/2023-05-10/doc...</td>\n      <td>蒙牛乳业5月9日斥资约1826.08万港元回购55万股</td>\n      <td>2023年05月10日 08:59</td>\n      <td>新浪港股</td>\n      <td>责任编辑：卢昱君</td>\n    </tr>\n    <tr>\n      <th>47351</th>\n      <td>0</td>\n      <td>https://finance.sina.com.cn/tob/2023-05-10/doc...</td>\n      <td>太古股份公司A5月9日斥资272.95万港元回购4.55万股</td>\n      <td>2023年05月10日 08:58</td>\n      <td>新浪港股</td>\n      <td>太古股份公司A（00019）发布公告，于2023年5月9日斥资272.95万港元回购4....</td>\n    </tr>\n    <tr>\n      <th>47352</th>\n      <td>1</td>\n      <td>https://finance.sina.com.cn/tob/2023-05-10/doc...</td>\n      <td>太古股份公司A5月9日斥资272.95万港元回购4.55万股</td>\n      <td>2023年05月10日 08:58</td>\n      <td>新浪港股</td>\n      <td>责任编辑：卢昱君</td>\n    </tr>\n    <tr>\n      <th>47353</th>\n      <td>0</td>\n      <td>https://finance.sina.com.cn/tob/2023-05-10/doc...</td>\n      <td>太古股份公司B5月9日耗资约550.67万港元回购55.5万股</td>\n      <td>2023年05月10日 08:58</td>\n      <td>新浪港股</td>\n      <td>太古股份公司B（00087）公布，2023年5月9日耗资约550.67万港元回购55.5...</td>\n    </tr>\n    <tr>\n      <th>47354</th>\n      <td>1</td>\n      <td>https://finance.sina.com.cn/tob/2023-05-10/doc...</td>\n      <td>太古股份公司B5月9日耗资约550.67万港元回购55.5万股</td>\n      <td>2023年05月10日 08:58</td>\n      <td>新浪港股</td>\n      <td>责任编辑：卢昱君</td>\n    </tr>\n  </tbody>\n</table>\n<p>47355 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultList=pd.read_csv(\"newsData/SinaNewsRawData.csv\")\n",
    "resultList"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T09:40:05.408591Z",
     "start_time": "2023-09-26T09:40:05.207878Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T09:40:05.410335Z",
     "start_time": "2023-09-26T09:40:05.408184Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.2 新闻联播文本稿"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T09:40:05.414914Z",
     "start_time": "2023-09-26T09:40:05.410604Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3 微博基于关键字内容爬取 (主要内容: 文章文本，观看人数，评论，点赞)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T09:40:05.415084Z",
     "start_time": "2023-09-26T09:40:05.412806Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.4 微信公众号基于关键字爬取 (主要内容: 文章文本，评论，点赞，收藏)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T09:40:05.420090Z",
     "start_time": "2023-09-26T09:40:05.416314Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.5 卫生办 新冠病毒 人数统计(日)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "class newsToolForHealthCenter:\n",
    "    @staticmethod\n",
    "    def get_page_news(keywords:[],browser,urlList:{},endTime:str):\n",
    "        \n",
    "        news = browser.find_elements(\"xpath\",'/html/body/div[2]/div/div[1]//*[@class=\"wordGuide Residence-permit\"]//*[@class=\"bigTit clearfix\"]/a')\n",
    "        similarArticles=browser.find_elements(\"xpath\",'/html/body/div[2]/div/div[1]//*[@class=\"wordGuide Residence-permit\"]//*[@class=\"listInfoCon clearfix \"]//*[@class=\"listIntro wh100 fl\"]//*[@class=\"similarArticles\"]//*[@class=\"similarArticlesList\"]/ul//*[@class=\"clearfix\"]/a')\n",
    "        if len(news)==0:\n",
    "            return np.nan\n",
    "        print(\"--------------new page--------------\")\n",
    "        if len(similarArticles)>0:\n",
    "            for article in similarArticles:\n",
    "                # print(\"-----------  ------------\")\n",
    "                # print(article.get_attribute(\"text\"))\n",
    "                # print(article.get_attribute(\"href\"))\n",
    "                similartitle=article.get_attribute(\"text\").strip()\n",
    "                similarlink=article.get_attribute(\"href\").strip()\n",
    "                for keyword in keywords:\n",
    "                    if re.match(pattern=keyword,string=similartitle):\n",
    "                        print(\"Found similar article: \",similartitle)\n",
    "                        if similarlink not in urlList.keys():\n",
    "                            urlList[similarlink]=similartitle\n",
    "        for i in news:\n",
    "            title=i.get_attribute(\"title\").strip()\n",
    "            link = i.get_attribute('href').strip() #得到新闻url\n",
    "            for keyword in keywords:\n",
    "                if re.match(pattern=keyword,string=title):\n",
    "                    print(\"Found: \",title)\n",
    "                    if link not in urlList.keys():\n",
    "                        urlList[link]=title\n",
    "        return urlList\n",
    "    \n",
    "    @staticmethod\n",
    "    async def getPageContent(url:str):\n",
    "        publicDate=\"\"\n",
    "        source=\"\"\n",
    "        content=\"\"\n",
    "        dateRe=\"发布时间：.?\"\n",
    "        sourceRe=\"来源:.?\"\n",
    "        # 获取新闻的详细信息\n",
    "        html=await newsToolForHealthCenter.pyppteer_fetchUrl(url)\n",
    "        if html is None:\n",
    "            print(url,\"  is nome type\")\n",
    "            return {\"Public_Date\":np.nan,\"Source\":np.nan,\"Content\":np.nan}\n",
    "        \n",
    "        elif len(html)<=0:\n",
    "            return {\"Public_Date\":np.nan,\"Source\":np.nan,\"Content\":np.nan}\n",
    "        #使用beautifulsoup进行解析\n",
    "        soup = BeautifulSoup(html,'lxml')\n",
    "\n",
    "        #日期\n",
    "        '''\n",
    "        <source>\n",
    "            <span>发布时间：2022-09-02</span>\n",
    "        '''\n",
    "        origin = soup.find_all('span')\n",
    "        # 可能有小部分日期的标签不是上述格式 对其进行补充\n",
    "        for ele in origin:\n",
    "            if re.match(string=ele.text.strip(),pattern=dateRe):\n",
    "                # print(ele.text)\n",
    "                publicDate=ele.text.replace(\"发布时间：\",\"\").strip()\n",
    "            if re.match(string=ele.text.strip(),pattern=sourceRe):\n",
    "                # print(ele.text)\n",
    "                source=ele.text.replace(\"来源:\",\"\").strip()\n",
    "                \n",
    "        article=\"\"\n",
    "        try: \n",
    "            #正文\n",
    "            article = soup.find(id=\"xw_box\").text.strip()\n",
    "            # print(\"---------------\")\n",
    "            # print(article)\n",
    "            content=article\n",
    "        except BaseException as err:\n",
    "            return {\"Public_Date\":np.nan,\"Source\":np.nan,\"Content\":np.nan}\n",
    "        \n",
    "        return {\"Public_Date\":publicDate,\"Source\":source,\"Content\":content}\n",
    "\n",
    "    @staticmethod\n",
    "    async def pyppteer_fetchUrl(url):\n",
    "        browser = await launch({'headless': False,'dumpio':True, 'autoClose':True})\n",
    "        page = await browser.newPage()\n",
    "        await page.goto(url)\n",
    "        await page.waitFor(100)\n",
    "        await asyncio.wait([page.waitForNavigation(timeout=500000)])\n",
    "        str = await page.content()\n",
    "        await browser.close()\n",
    "        return str\n",
    "    \n",
    "    # @staticmethod\n",
    "    # async def fetchUrl(url):\n",
    "    #     return await newsToolForHealthCenter.pyppteer_fetchUrl(url)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T09:40:05.438370Z",
     "start_time": "2023-09-26T09:40:05.425850Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# import asyncio\n",
    "# import nest_asyncio\n",
    "# \n",
    "# # 👇️ call apply()\n",
    "# nest_asyncio.apply()\n",
    "# url = 'http://www.nhc.gov.cn/yjb/s7860/202209/e0a18445e0ab47608527b9c910f77699.shtml'\n",
    "# \n",
    "# async def fetchUrl(url):\n",
    "#     browser = await launch({'headless': False,'dumpio':True, 'autoClose':True})\n",
    "#     page = await browser.newPage()\n",
    "# \n",
    "#     await page.goto(url)\n",
    "#     await asyncio.wait([page.waitForNavigation()])\n",
    "#     str = await page.content()\n",
    "#     await browser.close()\n",
    "#     print(\"-------------------\")\n",
    "#     print(str)\n",
    "# \n",
    "# asyncio.get_event_loop().run_until_complete(fetchUrl(url))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T09:40:05.455809Z",
     "start_time": "2023-09-26T09:40:05.429688Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support import wait\n",
    "from selenium.common import NoSuchElementException\n",
    "# \n",
    "#打开浏览器\n",
    "# browser = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "options = Options()\n",
    "browser = webdriver.Chrome(service=Service(ChromeDriverManager( latest_release_url='https://googlechromelabs.github.io/chrome-for-testing/last-known-good-versions-with-downloads.json', driver_version='116.0.5845.96').install()), options=options)\n",
    "\n",
    "browser.implicitly_wait(100)\n",
    "# #打开网址\n",
    "# # browser.get('http://zs.kaipuyun.cn/s?searchWord=%25E6%2596%25B0%25E5%259E%258B%25E5%2586%25A0%25E7%258A%25B6%25E7%2597%2585%25E6%25AF%2592%25E8%2582%25BA%25E7%2582%258E&column=%25E6%259C%25AC%25E7%25AB%2599&pageSize=10&pageNum=0&siteCode=N000001642&sonSiteCode=&checkHandle=1&searchSource=0&areaSearchFlag=0&secondSearchWords=&topical=&docName=&label=&countKey=0&uc=0&left_right_index=0&searchBoxSettingsIndex=&isSecondSearch=undefined&manualWord=%25E6%2596%25B0%25E5%259E%258B%25E5%2586%25A0%25E7%258A%25B6%25E7%2597%2585%25E6%25AF%2592%25E8%2582%25BA%25E7%2582%258E&orderBy=0&startTime=&endTime=&timeStamp=0&strFileType=&wordPlace=0')\n",
    "# \n",
    "# browser.get('http://zs.kaipuyun.cn/s?searchWord=%25E6%2596%25B0%25E5%259E%258B%25E5%2586%25A0%25E7%258A%25B6%25E7%2597%2585%25E6%25AF%2592%25E8%2582%25BA%25E7%2582%258E%25E7%2596%25AB%25E6%2583%2585%25E6%259C%2580%25E6%2596%25B0%25E6%2583%2585%25E5%2586%25B5&column=%25E6%259C%25AC%25E7%25AB%2599&pageSize=10&pageNum=0&siteCode=N000001642&sonSiteCode=&checkHandle=1&searchSource=1&areaSearchFlag=0&secondSearchWords=&topical=&docName=&label=&countKey=0&uc=0&left_right_index=0&searchBoxSettingsIndex=&isSecondSearch=undefined&manualWord=%25E6%2596%25B0%25E5%259E%258B%25E5%2586%25A0%25E7%258A%25B6%25E7%2597%2585%25E6%25AF%2592%25E8%2582%25BA%25E7%2582%258E%25E7%2596%25AB%25E6%2583%2585%25E6%259C%2580%25E6%2596%25B0%25E6%2583%2585%25E5%2586%25B5&orderBy=0&startTime=&endTime=&timeStamp=0&strFileType=&wordPlace=0')\n",
    "# \n",
    "# #获取当前页面新闻的url\n",
    "# keywords=[\"截至.*新型冠状病毒肺炎疫情最新情况\",'.*新型冠状病毒感染的肺炎疫情情况']\n",
    "# endTime=\"2018-6-6\"\n",
    "# urlList={}\n",
    "# urlList=newsToolForHealthCenter.get_page_news(keywords,browser,urlList=urlList,endTime=endTime)\n",
    "# \n",
    "# while True:\n",
    "#     try:\n",
    "#         #找到下一页按钮 并点击\n",
    "#         browser.find_element(\"xpath\",'//*[@id=\"pageInfo\"]//*[@class=\"next\"]/a').click()\n",
    "#         #获取下一页新闻的url\n",
    "#         result=newsToolForHealthCenter.get_page_news(keywords,browser,urlList=urlList,endTime=endTime)\n",
    "#         if result is np.nan:\n",
    "#             break\n",
    "#     except BaseException as err:\n",
    "#         # print(err)\n",
    "#         browser.close()\n",
    "#         break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T09:40:27.680308Z",
     "start_time": "2023-09-26T09:40:05.431542Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# print(len(urlList))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T09:40:27.685057Z",
     "start_time": "2023-09-26T09:40:27.682313Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# ###其中有一个文章链接会报错\n",
    "# allHealthCenterNews=pd.DataFrame()\n",
    "# for link,title in urlList.items():\n",
    "#     contentAndTime=asyncio.run(newsToolForHealthCenter.getPageContent(url=link))\n",
    "#     theNewsInstance={\"Title\":[title],\"Link\":[link],\"Content\":[contentAndTime['Content']],\"Public_Time\":[contentAndTime['Public_Date']],\"Source\":[contentAndTime['Source']]}\n",
    "#     theNewsDf=pd.DataFrame.from_dict(theNewsInstance)\n",
    "#     allHealthCenterNews=pd.concat([theNewsDf,allHealthCenterNews])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T09:40:27.686570Z",
     "start_time": "2023-09-26T09:40:27.685156Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# allHealthCenterNews"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T09:40:27.690138Z",
     "start_time": "2023-09-26T09:40:27.687475Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# allHealthCenterNews.to_csv(\"stockData/furtherInformation/covid19/CovidNews01.csv\",index=False,encoding=\"utf-8\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T09:40:27.691488Z",
     "start_time": "2023-09-26T09:40:27.690001Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# allHealthCenterNews=pd.read_csv(\"stockData/furtherInformation/covid19/CovidNews.csv\")\n",
    "# allHealthCenterNews"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T09:40:27.694586Z",
     "start_time": "2023-09-26T09:40:27.691876Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get the city name in china"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(['河北省',\n  '山西省',\n  '内蒙古自治区',\n  '辽宁省',\n  '吉林省',\n  '黑龙江省',\n  '江苏省',\n  '浙江省',\n  '安徽省',\n  '福建省',\n  '江西省',\n  '山东省',\n  '河南省',\n  '湖北省',\n  '湖南省',\n  '广东省',\n  '广西壮族自治区',\n  '海南省',\n  '四川省',\n  '贵州省',\n  '云南省',\n  '陕西省',\n  '甘肃省',\n  '青海省',\n  '西藏自治区',\n  '宁夏回族自治区',\n  '新疆维吾尔自治区'],\n ['北京市',\n  '天津市',\n  '上海市',\n  '重庆市',\n  '香港',\n  '澳门',\n  '唐山市',\n  '秦皇岛市',\n  '邯郸市',\n  '邢台市',\n  '保定市',\n  '张家口市',\n  '承德市',\n  '沧州市',\n  '廊坊市',\n  '衡水市',\n  '辛集市',\n  '晋州市 (河北省)',\n  '新乐市',\n  '遵化市',\n  '迁安市',\n  '武安市',\n  '南宫市',\n  '沙河市',\n  '涿州市',\n  '定州市',\n  '安国市',\n  '高碑店市',\n  '平泉市',\n  '泊头市',\n  '任丘市',\n  '黄骅市',\n  '河间市',\n  '霸州市',\n  '三河市',\n  '深州市',\n  '大同市',\n  '阳泉市',\n  '长治市',\n  '晋城市',\n  '朔州市',\n  '晋中市',\n  '运城市',\n  '忻州市',\n  '临汾市',\n  '吕梁市',\n  '古交市',\n  '高平市',\n  '介休市',\n  '永济市',\n  '河津市',\n  '原平市',\n  '侯马市',\n  '霍州市',\n  '孝义市',\n  '汾阳市',\n  '怀仁市',\n  '包头市',\n  '乌海市',\n  '赤峰市',\n  '通辽市',\n  '鄂尔多斯市',\n  '呼伦贝尔市',\n  '巴彦淖尔市',\n  '乌兰察布市',\n  '霍林郭勒市',\n  '满洲里市',\n  '牙克石市',\n  '扎兰屯市',\n  '额尔古纳市',\n  '根河市',\n  '丰镇市',\n  '乌兰浩特市',\n  '阿尔山市',\n  '二连浩特市',\n  '锡林浩特市',\n  '大连市',\n  '鞍山市',\n  '抚顺市',\n  '本溪市',\n  '丹东市',\n  '锦州市',\n  '营口市',\n  '阜新市',\n  '辽阳市',\n  '盘锦市',\n  '铁岭市',\n  '朝阳市',\n  '葫芦岛市',\n  '新民市',\n  '瓦房店市',\n  '庄河市',\n  '海城市',\n  '东港市',\n  '凤城市',\n  '凌海市',\n  '北镇市',\n  '盖州市',\n  '大石桥市',\n  '灯塔市',\n  '调兵山市',\n  '开原市',\n  '北票市',\n  '凌源市',\n  '兴城市',\n  '吉林市',\n  '四平市',\n  '辽源市',\n  '通化市',\n  '白山市 (吉林省)',\n  '松原市 (吉林省)',\n  '白城市',\n  '榆树市',\n  '德惠市',\n  '蛟河市',\n  '桦甸市',\n  '舒兰市',\n  '磐石市',\n  '公主岭市',\n  '双辽市',\n  '梅河口市',\n  '集安市',\n  '洮南市',\n  '大安市',\n  '临江市',\n  '延吉市',\n  '图们市',\n  '敦化市',\n  '珲春市',\n  '龙井市',\n  '和龙市',\n  '扶余市',\n  '齐齐哈尔市',\n  '黑河市',\n  '大庆市',\n  '伊春市',\n  '鹤岗市',\n  '佳木斯市',\n  '双鸭山市',\n  '七台河市',\n  '鸡西市',\n  '牡丹江市',\n  '绥化市',\n  '尚志市',\n  '五常市',\n  '讷河市',\n  '北安市',\n  '五大连池市',\n  '嫩江市',\n  '铁力市',\n  '同江市',\n  '富锦市',\n  '虎林市',\n  '密山市',\n  '绥芬河市',\n  '海林市',\n  '宁安市',\n  '安达市',\n  '肇东市',\n  '海伦市',\n  '穆棱市',\n  '东宁市',\n  '抚远市',\n  '漠河市',\n  '徐州市',\n  '连云港市',\n  '宿迁市',\n  '淮安市',\n  '盐城市',\n  '扬州市',\n  '泰州市',\n  '南通市',\n  '镇江市',\n  '常州市',\n  '无锡市',\n  '苏州市',\n  '常熟市',\n  '张家港市',\n  '太仓市',\n  '昆山市',\n  '江阴市',\n  '宜兴市',\n  '溧阳市',\n  '扬中市',\n  '句容市',\n  '丹阳市',\n  '如皋市',\n  '启东市',\n  '海安市',\n  '高邮市',\n  '仪征市',\n  '兴化市',\n  '泰兴市',\n  '靖江市',\n  '东台市',\n  '邳州市',\n  '新沂市',\n  '宁波市',\n  '湖州市',\n  '嘉兴市',\n  '舟山市',\n  '绍兴市',\n  '衢州市',\n  '金华市',\n  '台州市',\n  '温州市',\n  '丽水市 (中国)',\n  '建德市',\n  '慈溪市',\n  '余姚市',\n  '平湖市',\n  '海宁市',\n  '桐乡市',\n  '诸暨市',\n  '嵊州市',\n  '江山市',\n  '兰溪市',\n  '永康市',\n  '义乌市',\n  '东阳市',\n  '临海市',\n  '温岭市',\n  '瑞安市',\n  '乐清市',\n  '龙港市',\n  '龙泉市',\n  '玉环市',\n  '芜湖市',\n  '蚌埠市',\n  '淮南市',\n  '马鞍山市',\n  '淮北市',\n  '铜陵市',\n  '安庆市',\n  '黄山市',\n  '滁州市',\n  '阜阳市',\n  '宿州市',\n  '六安市',\n  '亳州市',\n  '池州市',\n  '宣城市',\n  '巢湖市',\n  '桐城市',\n  '天长市',\n  '明光市',\n  '界首市',\n  '宁国市',\n  '广德市',\n  '潜山市',\n  '无为市',\n  '厦门市',\n  '南平市',\n  '三明市',\n  '莆田市',\n  '泉州市',\n  '漳州市',\n  '龙岩市',\n  '宁德市',\n  '福清市',\n  '邵武市',\n  '武夷山市',\n  '建瓯市',\n  '永安市',\n  '石狮市',\n  '晋江市',\n  '南安市',\n  '龙海市',\n  '漳平市',\n  '福安市',\n  '福鼎市',\n  '九江市',\n  '景德镇市',\n  '鹰潭市',\n  '新余市',\n  '萍乡市',\n  '赣州市',\n  '上饶市',\n  '抚州市',\n  '宜春市',\n  '吉安市',\n  '瑞昌市',\n  '共青城市',\n  '庐山市',\n  '乐平市',\n  '瑞金市',\n  '德兴市',\n  '丰城市',\n  '樟树市',\n  '高安市',\n  '井冈山市',\n  '贵溪市',\n  '青岛市',\n  '聊城市',\n  '德州市',\n  '东营市',\n  '淄博市',\n  '潍坊市',\n  '烟台市',\n  '威海市',\n  '日照市',\n  '临沂市',\n  '枣庄市',\n  '济宁市',\n  '泰安市',\n  '滨州市',\n  '菏泽市',\n  '胶州市',\n  '平度市',\n  '莱西市',\n  '临清市',\n  '乐陵市',\n  '禹城市',\n  '安丘市',\n  '昌邑市',\n  '高密市',\n  '青州市',\n  '诸城市',\n  '寿光市',\n  '栖霞市',\n  '海阳市',\n  '龙口市',\n  '莱阳市',\n  '莱州市',\n  '蓬莱市',\n  '招远市',\n  '荣成市',\n  '乳山市',\n  '滕州市',\n  '曲阜市',\n  '邹城市',\n  '新泰市',\n  '肥城市',\n  '邹平市',\n  '开封市',\n  '洛阳市',\n  '平顶山市',\n  '安阳市',\n  '鹤壁市',\n  '新乡市',\n  '焦作市',\n  '濮阳市',\n  '许昌市',\n  '漯河市',\n  '三门峡市',\n  '南阳市',\n  '商丘市',\n  '周口市',\n  '驻马店市',\n  '信阳市',\n  '荥阳市',\n  '新郑市',\n  '登封市',\n  '新密市',\n  '偃师市',\n  '孟州市',\n  '沁阳市',\n  '卫辉市',\n  '辉县市',\n  '长垣市',\n  '林州市',\n  '禹州市',\n  '长葛市',\n  '舞钢市',\n  '义马市',\n  '灵宝市',\n  '项城市',\n  '巩义市',\n  '邓州市',\n  '永城市',\n  '汝州市',\n  '济源市',\n  '十堰市',\n  '襄阳市',\n  '荆门市',\n  '孝感市',\n  '黄冈市',\n  '鄂州市',\n  '黄石市',\n  '咸宁市',\n  '荆州市',\n  '宜昌市',\n  '随州市',\n  '丹江口市',\n  '老河口市',\n  '枣阳市',\n  '宜城市',\n  '钟祥市',\n  '京山市',\n  '汉川市',\n  '应城市',\n  '安陆市',\n  '广水市',\n  '麻城市',\n  '武穴市',\n  '大冶市',\n  '赤壁市',\n  '石首市',\n  '洪湖市',\n  '松滋市',\n  '宜都市',\n  '枝江市',\n  '当阳市',\n  '恩施市',\n  '利川市 (湖北省)',\n  '仙桃市',\n  '天门市',\n  '潜江市',\n  '衡阳市',\n  '张家界市',\n  '常德市',\n  '益阳市',\n  '岳阳市',\n  '株洲市',\n  '湘潭市',\n  '郴州市',\n  '永州市',\n  '邵阳市',\n  '怀化市',\n  '娄底市',\n  '耒阳市',\n  '常宁市',\n  '浏阳市',\n  '津市市',\n  '沅江市',\n  '汨罗市',\n  '临湘市',\n  '醴陵市',\n  '湘乡市',\n  '韶山市',\n  '资兴市',\n  '武冈市',\n  '邵东市',\n  '洪江市',\n  '冷水江市',\n  '涟源市',\n  '吉首市',\n  '宁乡市',\n  '深圳市',\n  '清远市',\n  '韶关市',\n  '河源市',\n  '梅州市',\n  '潮州市',\n  '汕头市',\n  '揭阳市',\n  '汕尾市',\n  '惠州市',\n  '东莞市',\n  '珠海市',\n  '中山市',\n  '江门市',\n  '佛山市',\n  '肇庆市',\n  '云浮市',\n  '阳江市',\n  '茂名市',\n  '湛江市',\n  '英德市',\n  '连州市',\n  '乐昌市',\n  '南雄市',\n  '兴宁市',\n  '普宁市',\n  '陆丰市',\n  '恩平市',\n  '台山市',\n  '开平市',\n  '鹤山市',\n  '四会市',\n  '罗定市',\n  '阳春市',\n  '化州市',\n  '信宜市',\n  '高州市',\n  '吴川市',\n  '廉江市',\n  '雷州市',\n  '桂林市',\n  '柳州市',\n  '梧州市',\n  '贵港市',\n  '玉林市',\n  '钦州市',\n  '北海市',\n  '防城港市',\n  '崇左市',\n  '百色市',\n  '河池市',\n  '来宾市',\n  '贺州市',\n  '岑溪市',\n  '桂平市',\n  '北流市',\n  '东兴市',\n  '凭祥市',\n  '合山市',\n  '靖西市',\n  '平果市',\n  '荔浦市',\n  '三亚市',\n  '三沙市',\n  '儋州市',\n  '文昌市',\n  '琼海市',\n  '万宁市',\n  '东方市',\n  '五指山市',\n  '广元市',\n  '绵阳市',\n  '德阳市',\n  '南充市',\n  '广安市',\n  '遂宁市',\n  '内江市',\n  '乐山市',\n  '自贡市',\n  '泸州市',\n  '宜宾市',\n  '攀枝花市',\n  '巴中市',\n  '达州市',\n  '资阳市',\n  '眉山市',\n  '雅安市',\n  '崇州市',\n  '邛崃市',\n  '都江堰市',\n  '彭州市',\n  '江油市',\n  '什邡市',\n  '广汉市',\n  '绵竹市',\n  '阆中市',\n  '华蓥市',\n  '峨眉山市',\n  '万源市',\n  '简阳市',\n  '西昌市',\n  '康定市',\n  '马尔康市',\n  '隆昌市',\n  '射洪市',\n  '会理市',\n  '六盘水市',\n  '遵义市',\n  '安顺市',\n  '毕节市',\n  '铜仁市',\n  '清镇市',\n  '赤水市',\n  '仁怀市',\n  '凯里市',\n  '都匀市',\n  '兴义市',\n  '福泉市',\n  '盘州市',\n  '兴仁市',\n  '曲靖市',\n  '玉溪市',\n  '丽江市',\n  '昭通市',\n  '普洱市',\n  '临沧市',\n  '保山市',\n  '安宁市',\n  '宣威市',\n  '芒市',\n  '瑞丽市',\n  '大理市',\n  '楚雄市',\n  '个旧市',\n  '开远市',\n  '蒙自市',\n  '弥勒市',\n  '景洪市',\n  '文山市',\n  '香格里拉市',\n  '腾冲市',\n  '水富市',\n  '澄江市',\n  '泸水市',\n  '延安市',\n  '铜川市',\n  '渭南市',\n  '咸阳市',\n  '宝鸡市',\n  '汉中市',\n  '榆林市',\n  '商洛市',\n  '安康市',\n  '韩城市',\n  '华阴市',\n  '兴平市',\n  '彬州市',\n  '神木市',\n  '子长市',\n  '嘉峪关市',\n  '金昌市',\n  '白银市',\n  '天水市',\n  '酒泉市',\n  '张掖市',\n  '武威市',\n  '庆阳市',\n  '平凉市',\n  '定西市',\n  '陇南市',\n  '玉门市',\n  '敦煌市',\n  '临夏市',\n  '合作市',\n  '华亭市',\n  '海东市',\n  '格尔木市',\n  '德令哈市',\n  '玉树市',\n  '茫崖市',\n  '日喀则市',\n  '昌都市',\n  '林芝市',\n  '山南市',\n  '那曲市',\n  '石嘴山市',\n  '吴忠市',\n  '中卫市',\n  '固原市',\n  '灵武市',\n  '青铜峡市',\n  '克拉玛依市',\n  '吐鲁番市',\n  '哈密市',\n  '喀什市',\n  '阿克苏市',\n  '库车市',\n  '和田市',\n  '阿图什市',\n  '阿拉山口市',\n  '博乐市',\n  '昌吉市',\n  '阜康市',\n  '库尔勒市',\n  '伊宁市',\n  '奎屯市',\n  '塔城市',\n  '乌苏市',\n  '阿勒泰市',\n  '霍尔果斯市',\n  '师市合一',\n  '石河子市',\n  '阿拉尔市',\n  '图木舒克市',\n  '五家渠市',\n  '北屯市',\n  '铁门关市',\n  '双河市',\n  '可克达拉市',\n  '昆玉市',\n  '胡杨河市',\n  '中华人民共和国城市建制',\n  '中华人民共和国县级以上行政区列表',\n  '因用字生僻难认而更名的中国大陆地名列表',\n  '中华人民共和国城市城区人口排名'])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## url: https://zh.wikipedia.org/zh-hans/%E4%B8%AD%E5%8D%8E%E4%BA%BA%E6%B0%91%E5%85%B1%E5%92%8C%E5%9B%BD%E5%9F%8E%E5%B8%82%E5%88%97%E8%A1%A8\n",
    "browser.get('https://zh.wikipedia.org/zh-hans/%E4%B8%AD%E5%8D%8E%E4%BA%BA%E6%B0%91%E5%85%B1%E5%92%8C%E5%9B%BD%E5%9F%8E%E5%B8%82%E5%88%97%E8%A1%A8')\n",
    "\n",
    "cities = browser.find_elements(\"xpath\",'//*[@class=\"mw-content-container\"]//*[@id=\"content\"]//*[@id=\"bodyContent\"]//*[@id=\"mw-content-text\"]//*[@class=\"mw-parser-output\"]/h3//*[@class=\"mw-headline\"]/a')\n",
    "\n",
    "towns = browser.find_elements(\"xpath\",'//*[@class=\"mw-content-container\"]//*[@id=\"content\"]//*[@id=\"bodyContent\"]//*[@id=\"mw-content-text\"]//*[@class=\"mw-parser-output\"]/ul/li/a')\n",
    "\n",
    "cityList=[]\n",
    "for city in cities:\n",
    "    cityList.append(city.get_attribute(\"title\"))\n",
    "\n",
    "townList=[]\n",
    "for town in towns:\n",
    "    theList=[]\n",
    "    townList.append(town.get_attribute(\"title\"))\n",
    "\n",
    "cityList,townList"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-26T09:44:25.346016Z",
     "start_time": "2023-09-26T09:44:18.100357Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
